{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GOOGLE EDUCATION APP CLASSIFICATION \n",
    "\n",
    "1. Import necessary files <br/>\n",
    "2. Read the csv file <br/>\n",
    "3. List the various fields in our dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(124, 21)\n"
     ]
    }
   ],
   "source": [
    "#Read the csv file into dataframe df\n",
    "df = pd.read_csv(\"train1.csv\")\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "appname                  object\n",
      "updated                  object\n",
      "file_size                object\n",
      "download                 object\n",
      "version                  object\n",
      "compatibility            object\n",
      "price                    object\n",
      "rating_value            float64\n",
      "star_total               object\n",
      "editors_choice           object\n",
      "offered_by               object\n",
      "description              object\n",
      "Language Learning         int64\n",
      "Computer Engineering      int64\n",
      "General Learning          int64\n",
      "Exam Preparation          int64\n",
      "Maths                     int64\n",
      "Art                       int64\n",
      "other engineering         int64\n",
      "Educational Gaming        int64\n",
      "misc                      int64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "#List the fields in our dataframe\n",
    "print(df.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hence we have a dataset consistly of 124 samples. Each sample contains 21 fields. <br/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Separate the comment field data and outcome labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    Learn Spanish, French, German, Italian, Russia...\n",
      "1    Speak a new language with confidence. Learn Sp...\n",
      "2    Start speaking a new language on day one! Try ...\n",
      "3    This app contains Implementation (full working...\n",
      "4    Learn on the go with the Coursera App for Andr...\n",
      "Name: description, dtype: object\n"
     ]
    }
   ],
   "source": [
    "comment = df['description']\n",
    "print(comment.head())\n",
    "comment = comment.as_matrix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Language Learning  Computer Engineering  General Learning  \\\n",
      "0                  1                     0                 0   \n",
      "1                  1                     0                 0   \n",
      "2                  1                     0                 0   \n",
      "3                  0                     1                 0   \n",
      "4                  1                     1                 1   \n",
      "\n",
      "   Exam Preparation  Maths  Art  other engineering  Educational Gaming  misc  \n",
      "0                 0      0    0                  0                   0     0  \n",
      "1                 0      0    0                  0                   0     0  \n",
      "2                 0      0    0                  0                   0     0  \n",
      "3                 0      0    0                  0                   0     0  \n",
      "4                 0      0    1                  1                   0     0  \n"
     ]
    }
   ],
   "source": [
    "label = df[['Language Learning', 'Computer Engineering' , 'General Learning' , 'Exam Preparation' , 'Maths' , 'Art', 'other engineering', 'Educational Gaming', 'misc']]\n",
    "print(label.head())\n",
    "label = label.as_matrix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Only for testing dataset for Nan values\n",
    "# count= 0\n",
    "# for ix in range(label.shape[0]):\n",
    "#     if(label[ix][8]!=0. and label[ix][8]!=1.):\n",
    "#         print(ix)\n",
    "#         print (comment[ix])\n",
    "#         count+=1\n",
    "#         print(label[ix])\n",
    "# print(count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let us find out the frequency of occurence of multilabelled data \n",
    "- ct1 counts samples having atleast one label\n",
    "- ct2 counts samples having 2 or more than 2 labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "124\n",
      "27\n"
     ]
    }
   ],
   "source": [
    "ct1,ct2 = 0,0\n",
    "for i in range(label.shape[0]):\n",
    "    ct = np.count_nonzero(label[i])\n",
    "    if ct :\n",
    "        ct1 = ct1+1\n",
    "    if ct>1 :\n",
    "        ct2 = ct2+1\n",
    "print(ct1)\n",
    "print(ct2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Visualisations\n",
    "### Let us analyse the no. of comments having lengths varying from 0 to 1200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average length of comment: 1426.919\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "x = [len(comment[i]) for i in range(comment.shape[0])]\n",
    "\n",
    "print('average length of comment: {:.3f}'.format(sum(x)/len(x)) )\n",
    "bins = [1,200,400,600,800,1000,1200]\n",
    "plt.hist(x, bins=bins)\n",
    "plt.xlabel('Length of comments')\n",
    "plt.ylabel('Number of comments')       \n",
    "plt.axis([0, 1200, 0, 20])\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Number of comments classified as toxic,severe_toxic,....etc depending on their lengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "y = np.zeros(label.shape)\n",
    "for ix in range(comment.shape[0]):\n",
    "    l = len(comment[ix])\n",
    "    if label[ix][0] :\n",
    "        y[ix][0] = l\n",
    "    if label[ix][1] :\n",
    "        y[ix][1] = l\n",
    "    if label[ix][2] :\n",
    "        y[ix][2] = l\n",
    "    if label[ix][3] :\n",
    "        y[ix][3] = l\n",
    "    if label[ix][4] :\n",
    "        y[ix][4] = l\n",
    "    if label[ix][5] :\n",
    "        y[ix][5] = l\n",
    "\n",
    "labelsplt = ['Language Learning', 'Computer Engineering' , 'General Learnng' , 'Exam Preparation' , 'Maths' , 'Art', 'other engineering', 'Educational Gaming', 'misc']\n",
    "color = ['red','green','blue','yellow','orange','chartreuse','black','magenta','purple']        \n",
    "plt.hist(y,bins = bins,label = labelsplt,color = color)\n",
    "plt.axis([0, 1500, 0, 8])\n",
    "plt.xlabel('Length of comments')\n",
    "plt.ylabel('Number of comments') \n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating a separate variable for app description (comments) and labels (classifiers)\n",
    "comments = []\n",
    "labels = []\n",
    "\n",
    "for ix in range(comment.shape[0]):\n",
    "    comments.append(comment[ix])\n",
    "    labels.append(label[ix])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = np.asarray(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 0 0 0 0 0 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "print (labels[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "124\n"
     ]
    }
   ],
   "source": [
    "print(len(comments))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing \n",
    "Preprocessing involved the following steps, but these will be performed in a slightly different manner:\n",
    "- Removing Punctuations and other special characters\n",
    "- Splitting the comments into individual words\n",
    "- Removing Stop Words\n",
    "- Stemming and Lemmatising\n",
    "- Applying Count Vectoriser\n",
    "- Splitting dataset into Training and Testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing a string containing all punctuations to be removed\n",
    "The string library contains punctuation characters. This is imported and all numbers are appended to this string. Also, we can notice that our comment_text field contains strings such as won't, didn't, etc which contain apostrophe character('). To prevent these words from being converted to wont/didnt, the character ' represented as \\' in escape sequence notation is replaced by empty character in the punctuation string. <br/>\n",
    "\n",
    "**maketrans()** returns a translation table that maps each character in the punctuation_edit into the character at the same position in the outtab string i.e. it replaces every character in the removal list with a space, since outtab contains a string with spaces."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "!\"#$%&'()*+,-./:;<=>?@[\\]^_`{|}~\n",
      "!\"#$%&()*+,-./:;<=>?@[\\]^_`{|}~0123456789\n"
     ]
    }
   ],
   "source": [
    "import string\n",
    "print(string.punctuation)\n",
    "punctuation_edit = string.punctuation.replace('\\'','') +\"0123456789\"\n",
    "print (punctuation_edit)\n",
    "outtab = \"                                         \"\n",
    "trantab = str.maketrans(punctuation_edit, outtab)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Updating the list of stop words\n",
    "**Stop words** are those words that are frequently used in both written and verbal communication and thereby do not have either a positive/negative impact on our statement.E.g. is, this, us,etc. <br/>\n",
    "Single letter words if existing or created due to any preprocessing step do not convey any useful meaning and hence can be directly removed. Hence letters from b to z, will be added to the list of stop words imported directly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from stop_words import get_stop_words\n",
    "stop_words = get_stop_words('english')\n",
    "stop_words.append('')\n",
    "\n",
    "for x in range(ord('b'), ord('z')+1):\n",
    "    stop_words.append(chr(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['a', 'about', 'above', 'after', 'again', 'against', 'all', 'am', 'an', 'and', 'any', 'are', \"aren't\", 'as', 'at', 'be', 'because', 'been', 'before', 'being', 'below', 'between', 'both', 'but', 'by', \"can't\", 'cannot', 'could', \"couldn't\", 'did', \"didn't\", 'do', 'does', \"doesn't\", 'doing', \"don't\", 'down', 'during', 'each', 'few', 'for', 'from', 'further', 'had', \"hadn't\", 'has', \"hasn't\", 'have', \"haven't\", 'having', 'he', \"he'd\", \"he'll\", \"he's\", 'her', 'here', \"here's\", 'hers', 'herself', 'him', 'himself', 'his', 'how', \"how's\", 'i', \"i'd\", \"i'll\", \"i'm\", \"i've\", 'if', 'in', 'into', 'is', \"isn't\", 'it', \"it's\", 'its', 'itself', \"let's\", 'me', 'more', 'most', \"mustn't\", 'my', 'myself', 'no', 'nor', 'not', 'of', 'off', 'on', 'once', 'only', 'or', 'other', 'ought', 'our', 'ours', 'ourselves', 'out', 'over', 'own', 'same', \"shan't\", 'she', \"she'd\", \"she'll\", \"she's\", 'should', \"shouldn't\", 'so', 'some', 'such', 'than', 'that', \"that's\", 'the', 'their', 'theirs', 'them', 'themselves', 'then', 'there', \"there's\", 'these', 'they', \"they'd\", \"they'll\", \"they're\", \"they've\", 'this', 'those', 'through', 'to', 'too', 'under', 'until', 'up', 'very', 'was', \"wasn't\", 'we', \"we'd\", \"we'll\", \"we're\", \"we've\", 'were', \"weren't\", 'what', \"what's\", 'when', \"when's\", 'where', \"where's\", 'which', 'while', 'who', \"who's\", 'whom', 'why', \"why's\", 'with', \"won't\", 'would', \"wouldn't\", 'you', \"you'd\", \"you'll\", \"you're\", \"you've\", 'your', 'yours', 'yourself', 'yourselves', '', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z']\n"
     ]
    }
   ],
   "source": [
    "print (stop_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stemming and Lemmatizing\n",
    "**Stemming** is the process of converting inflected/derived words to their word stem or the root form. Basically, a large number of similar origin words are converted to the same word.E.g. words like \"stems\", \"stemmer\", \"stemming\", \"stemmed\" as based on \"stem\". This helps in achieving the training process with a better accuracy.<br/>\n",
    "**Lemmatizing** is the process of grouping together the inflected forms of a word so they can be analysed as a single item. This is quite similar to stemming in its working but differs since it depends on correctly identifying the intended part of speech and meaning of a word in a sentence, as well as within the larger context surrounding that sentence, such as neighboring sentences or even an entire document.<br/>\n",
    "The **wordnet library in nltk** will be used for this purpose. Stemmer and Lemmatizer are also imported from nltk.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.stem import PorterStemmer, WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to /Users/nupur/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#create objects for stemmer and lemmatizer\n",
    "lemmatiser = WordNetLemmatizer()\n",
    "stemmer = PorterStemmer()\n",
    "#download words from wordnet library\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We can now, loop once through all the comments applying :\n",
    "- punctuation removal\n",
    "- splitting the words by space\n",
    "- applying stemmer and lemmatizer\n",
    "- recombining the words again for further processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stem_lemmatize(comments):\n",
    "    for i in range(len(comments)):\n",
    "        comments[i] = comments[i].lower().translate(trantab)\n",
    "        l = []\n",
    "        for word in comments[i].split():\n",
    "            l.append(stemmer.stem(lemmatiser.lemmatize(word,pos=\"v\")))\n",
    "        comments[i] = \" \".join(l)\n",
    "\n",
    "stem_lemmatize(comments);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Applying Count Vectorizer\n",
    "Here we can finally convert our comments into a matrix of token counts, which signifies the number of times it occurs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import required library\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "#create object supplying our custom stop words\n",
    "count_vector = CountVectorizer(stop_words=stop_words)\n",
    "#fitting it to converts comments into bag of words format\n",
    "tf = count_vector.fit_transform(comments).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(124, 3095)\n"
     ]
    }
   ],
   "source": [
    "# print(count_vector.get_feature_names())\n",
    "print(tf.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hence from its shape we can imply that after all preprocessing we have a list of 52905 words in total.\n",
    "## Splitting dataset into training and testing\n",
    "- Since the system was going out of memory using train_test_split, I had jumbled all the indexes in the beginning itself. \n",
    "- The shuffle function defined here performs the task of assigning first 2/3rd values to train and remaining 1/3rd values to the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(31, 3095)\n",
      "(93, 3095)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "def shuffle(matrix, target, test_proportion):\n",
    "    ratio = int(matrix.shape[0]/test_proportion)\n",
    "    X_train = matrix[ratio:,:]\n",
    "    X_test =  matrix[:ratio,:]\n",
    "    Y_train = target[ratio:,:]\n",
    "    Y_test =  target[:ratio,:]\n",
    "    return X_train, X_test, Y_train, Y_test\n",
    "\n",
    "# X_train, X_test, Y_train, Y_test = shuffle(tf, labels,5)\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(tf, labels, test_size=0.25, random_state=42)\n",
    "\n",
    "print(X_test.shape)\n",
    "print(X_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementation :\n",
    "### Let us define all the evaluation metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import hamming_loss\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import log_loss\n",
    "\n",
    "def evaluate_score(Y_test,predict): \n",
    "    loss = hamming_loss(Y_test,predict)\n",
    "    print(\"Hamming_loss : {}\".format(loss*100))\n",
    "    accuracy = accuracy_score(Y_test,predict)\n",
    "    print(\"Accuracy : {}\".format(accuracy*100))\n",
    "    try : \n",
    "        loss = log_loss(Y_test,predict)\n",
    "    except :\n",
    "        loss = log_loss(Y_test,predict.toarray())\n",
    "    print(\"Log_loss : {}\".format(loss))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Starting with the First Model -\n",
    "### Problem Transformation Methods :\n",
    "**These include the Binary Relevance, Label Powerset and Classifier Chain methods. Implementations of these methods is available in the scikit-multilearn library. **\n",
    "- I will be implementing the most basic method,which is the **Binary Relevance** method from scratch. It does not take into account the interdependence of labels and basically creates a separate classifier for each of the labels.\n",
    "- Scikit-multilearn library's classifier will also be imported and tested with different classifiers to observe if it gives similar results.\n",
    "\n",
    "### 1. Binary Relevance (BR) Method with MultinomialNB classifiers (from scratch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 0 0 1 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "print (Y_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clf will be the list of the classifiers for all the 6 labels\n",
    "# each classifier is fit with the training data and corresponding classifier\n",
    "clf = []\n",
    "for ix in range(9):\n",
    "    clf.append(MultinomialNB())\n",
    "    clf[ix].fit(X_train,Y_train[:,ix])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(31, 9)\n"
     ]
    }
   ],
   "source": [
    "# predict list contains the predictions, it is transposed later to get the proper shape\n",
    "predict = []\n",
    "for ix in range(9):\n",
    "    predict.append(clf[ix].predict(X_test))\n",
    "\n",
    "predict = np.asarray(np.transpose(predict))\n",
    "print(predict.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hamming_loss : 12.186379928315413\n",
      "Accuracy : 51.61290322580645\n",
      "Log_loss : 8.632300984363441\n"
     ]
    }
   ],
   "source": [
    "# calculate results\n",
    "evaluate_score(Y_test,predict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. BR Method with Multinomial classifier (from scikit-multilearn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BinaryRelevance(classifier=MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True),\n",
       "        require_dense=[False, True])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#create and fit classifier\n",
    "from skmultilearn.problem_transform import BinaryRelevance\n",
    "classifier = BinaryRelevance(classifier = MultinomialNB(), require_dense = [False, True])\n",
    "classifier.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "#predictions\n",
    "predictions = classifier.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hamming_loss : 12.186379928315413\n",
      "Accuracy : 51.61290322580645\n",
      "Log_loss : 8.632300984363441\n"
     ]
    }
   ],
   "source": [
    "#calculate scores\n",
    "evaluate_score(Y_test,predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. BR Method with GausseanNB classifier (from scratch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "#create and fit classifiers\n",
    "clf = []\n",
    "for ix in range(9):\n",
    "    clf.append(GaussianNB())\n",
    "    clf[ix].fit(X_train,Y_train[:,ix])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "#predictions\n",
    "predict = []\n",
    "for ix in range(9):\n",
    "    predict.append(clf[ix].predict(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hamming_loss : 11.11111111111111\n",
      "Accuracy : 29.03225806451613\n",
      "Log_loss : 6.299449825496276\n"
     ]
    }
   ],
   "source": [
    "#calculate scores\n",
    "predict = np.asarray(np.transpose(predict))\n",
    "evaluate_score(Y_test,predict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Classifier chain with MultinomialNB classifier (from scikit-multilearn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ClassifierChain(classifier=MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True),\n",
       "        require_dense=[True, True])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#create and fit classifier\n",
    "from skmultilearn.problem_transform import ClassifierChain\n",
    "classifier = ClassifierChain(MultinomialNB())\n",
    "classifier.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "#predictions\n",
    "predictions = classifier.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hamming_loss : 11.469534050179211\n",
      "Accuracy : 51.61290322580645\n",
      "Log_loss : 8.61542201198394\n"
     ]
    }
   ],
   "source": [
    "#calculate scores\n",
    "evaluate_score(Y_test,predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Label Powerset with MultinomialNB classifier (from scikit-multilearn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create and fit classifier\n",
    "from skmultilearn.problem_transform import LabelPowerset\n",
    "classifier = LabelPowerset(MultinomialNB())\n",
    "classifier.fit(X_train, Y_train)\n",
    "\n",
    "best_classifier = classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 7)\t1\n"
     ]
    }
   ],
   "source": [
    "#predictions\n",
    "predictions = classifier.predict(X_test);\n",
    "print((predictions[0]));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hamming_loss : 9.31899641577061\n",
      "Accuracy : 61.29032258064516\n",
      "Log_loss : 18.998418005893868\n"
     ]
    }
   ],
   "source": [
    "#calculate scores\n",
    "evaluate_score(Y_test,predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adaptation Algorithms\n",
    "### 6. MLkNN  with k=2 (from scikit-multilearn)\n",
    "This is the adapted multi-label version of K Nearest Neighbours. Its implementation is available in the multilearn library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLkNN(ignore_first_neighbours=0, k=5, s=1.0)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#create and fit classifier\n",
    "from skmultilearn.adapt import MLkNN\n",
    "classifier = MLkNN(k=5)\n",
    "classifier.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "#predictions\n",
    "predictions = classifier.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hamming_loss : 11.469534050179211\n",
      "Accuracy : 35.483870967741936\n",
      "Log_loss : 11.344114234571348\n"
     ]
    }
   ],
   "source": [
    "#calculate scores\n",
    "evaluate_score(Y_test,predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. BP-MLL Neural Networks (from scratch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 20)                61920     \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 20)                0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 9)                 189       \n",
      "=================================================================\n",
      "Total params: 62,109\n",
      "Trainable params: 62,109\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#define model architecture\n",
    "model = Sequential()\n",
    "model.add(Dense(20, activation='relu', input_dim = X_train.shape[1]))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Dense(9, activation='softmax'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "#compile model with all parameters set\n",
    "model.compile(optimizer='rmsprop',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "93/93 [==============================] - 0s 3ms/step - loss: 3.0336 - acc: 0.0968\n",
      "Epoch 2/10\n",
      "93/93 [==============================] - 0s 155us/step - loss: 2.5842 - acc: 0.2151\n",
      "Epoch 3/10\n",
      "93/93 [==============================] - 0s 173us/step - loss: 2.3269 - acc: 0.3333\n",
      "Epoch 4/10\n",
      "93/93 [==============================] - 0s 159us/step - loss: 2.1902 - acc: 0.4086\n",
      "Epoch 5/10\n",
      "93/93 [==============================] - 0s 149us/step - loss: 2.0639 - acc: 0.5161\n",
      "Epoch 6/10\n",
      "93/93 [==============================] - 0s 163us/step - loss: 1.9539 - acc: 0.5699\n",
      "Epoch 7/10\n",
      "93/93 [==============================] - 0s 153us/step - loss: 1.8550 - acc: 0.6022\n",
      "Epoch 8/10\n",
      "93/93 [==============================] - 0s 152us/step - loss: 1.7409 - acc: 0.6344\n",
      "Epoch 9/10\n",
      "93/93 [==============================] - 0s 164us/step - loss: 1.6689 - acc: 0.6667\n",
      "Epoch 10/10\n",
      "93/93 [==============================] - 0s 153us/step - loss: 1.5910 - acc: 0.5914\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x12949cfd0>"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Fit using check pointer\n",
    "from keras.callbacks import ModelCheckpoint  \n",
    "\n",
    "checkpointer = ModelCheckpoint(filepath='saved_models/weights.best.myneural.h5py', \n",
    "                               verbose=1, save_best_only=True)\n",
    "model.fit(X_train, Y_train, epochs=10, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "#predictions\n",
    "predict = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.06707445 0.02892904 0.02753172 0.2577899  0.10376704 0.05747934\n",
      " 0.1100159  0.22885123 0.1185613 ]\n"
     ]
    }
   ],
   "source": [
    "print(predict[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Since the results returned by the model are in the form of probabilities, they have to be explicitly converted to either 0/1 using the round function. This is because the hamming_loss and accuracy_score cannot work on these values directly. However, log loss can compute loss directly without modifying the values.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Log_loss : 2.5379521608833344\n",
      "Hamming_loss : 15.053763440860216\n",
      "Accuracy : 6.451612903225806\n"
     ]
    }
   ],
   "source": [
    "#calculate score\n",
    "loss = log_loss(Y_test,predict)\n",
    "print(\"Log_loss : {}\".format(loss))\n",
    "predict = np.round(predict)\n",
    "loss = hamming_loss(Y_test,predict)\n",
    "print(\"Hamming_loss : {}\".format(loss*100))\n",
    "accuracy = accuracy_score(Y_test,predict)\n",
    "print(\"Accuracy : {}\".format(accuracy*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Let us try improving the BP-MLL model (Refining)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Dropout\n",
    "from keras import optimizers\n",
    "\n",
    "#define parameters for using in param grid\n",
    "nodes = [16, 32] # number of nodes in the hidden layer\n",
    "lrs = [0.001, 0.002, 0.003] # learning rate, default = 0.001\n",
    "epochs = [10,20]\n",
    "batch_size = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(nodes=10,lr=0.001):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(nodes, activation='relu', input_dim = X_train.shape[1]))\n",
    "    model.add(Dropout(0.3))\n",
    "    model.add(Dense(9, activation='softmax'))\n",
    "    opt = optimizers.RMSprop(lr=lr)\n",
    "    model.compile(optimizer=opt,\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "model = KerasClassifier(build_fn=create_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 12 candidates, totalling 36 fits\n",
      "[CV] epochs=10, lr=0.001, nodes=16 ...................................\n",
      "Epoch 1/10\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 2.8460 - acc: 0.1290\n",
      "Epoch 2/10\n",
      "62/62 [==============================] - 0s 162us/step - loss: 2.4791 - acc: 0.3710\n",
      "Epoch 3/10\n",
      "62/62 [==============================] - 0s 167us/step - loss: 2.3532 - acc: 0.3065\n",
      "Epoch 4/10\n",
      "62/62 [==============================] - 0s 147us/step - loss: 2.2362 - acc: 0.4194\n",
      "Epoch 5/10\n",
      "62/62 [==============================] - 0s 207us/step - loss: 2.0936 - acc: 0.4677\n",
      "Epoch 6/10\n",
      "62/62 [==============================] - 0s 165us/step - loss: 1.9815 - acc: 0.5484\n",
      "Epoch 7/10\n",
      "62/62 [==============================] - 0s 185us/step - loss: 1.8781 - acc: 0.5484\n",
      "Epoch 8/10\n",
      "62/62 [==============================] - 0s 184us/step - loss: 1.8107 - acc: 0.5968\n",
      "Epoch 9/10\n",
      "62/62 [==============================] - 0s 196us/step - loss: 1.7002 - acc: 0.6774\n",
      "Epoch 10/10\n",
      "62/62 [==============================] - 0s 203us/step - loss: 1.5785 - acc: 0.7097\n",
      "31/31 [==============================] - 0s 2ms/step\n",
      "62/62 [==============================] - 0s 105us/step\n",
      "[CV] .................... epochs=10, lr=0.001, nodes=16, total=   1.2s\n",
      "[CV] epochs=10, lr=0.001, nodes=16 ...................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    1.2s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 3.1410 - acc: 0.1129\n",
      "Epoch 2/10\n",
      "62/62 [==============================] - 0s 174us/step - loss: 2.7259 - acc: 0.1935\n",
      "Epoch 3/10\n",
      "62/62 [==============================] - 0s 155us/step - loss: 2.5172 - acc: 0.3065\n",
      "Epoch 4/10\n",
      "62/62 [==============================] - 0s 207us/step - loss: 2.3847 - acc: 0.3871\n",
      "Epoch 5/10\n",
      "62/62 [==============================] - 0s 193us/step - loss: 2.3597 - acc: 0.4032\n",
      "Epoch 6/10\n",
      "62/62 [==============================] - 0s 160us/step - loss: 2.2726 - acc: 0.3871\n",
      "Epoch 7/10\n",
      "62/62 [==============================] - 0s 200us/step - loss: 2.1818 - acc: 0.5000\n",
      "Epoch 8/10\n",
      "62/62 [==============================] - 0s 196us/step - loss: 2.0572 - acc: 0.5000\n",
      "Epoch 9/10\n",
      "62/62 [==============================] - 0s 171us/step - loss: 2.0365 - acc: 0.5645\n",
      "Epoch 10/10\n",
      "62/62 [==============================] - 0s 198us/step - loss: 2.0246 - acc: 0.5484\n",
      "31/31 [==============================] - 0s 2ms/step\n",
      "62/62 [==============================] - 0s 127us/step\n",
      "[CV] .................... epochs=10, lr=0.001, nodes=16, total=   0.8s\n",
      "[CV] epochs=10, lr=0.001, nodes=16 ...................................\n",
      "Epoch 1/10\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 2.9382 - acc: 0.1613\n",
      "Epoch 2/10\n",
      "62/62 [==============================] - 0s 163us/step - loss: 2.4622 - acc: 0.4355\n",
      "Epoch 3/10\n",
      "62/62 [==============================] - 0s 165us/step - loss: 2.2263 - acc: 0.4677\n",
      "Epoch 4/10\n",
      "62/62 [==============================] - 0s 196us/step - loss: 2.0699 - acc: 0.5968\n",
      "Epoch 5/10\n",
      "62/62 [==============================] - 0s 208us/step - loss: 1.9398 - acc: 0.5806\n",
      "Epoch 6/10\n",
      "62/62 [==============================] - 0s 157us/step - loss: 1.9315 - acc: 0.5645\n",
      "Epoch 7/10\n",
      "62/62 [==============================] - 0s 168us/step - loss: 1.7775 - acc: 0.6613\n",
      "Epoch 8/10\n",
      "62/62 [==============================] - 0s 209us/step - loss: 1.6353 - acc: 0.7258\n",
      "Epoch 9/10\n",
      "62/62 [==============================] - 0s 199us/step - loss: 1.6565 - acc: 0.7419\n",
      "Epoch 10/10\n",
      "62/62 [==============================] - 0s 159us/step - loss: 1.6757 - acc: 0.7742\n",
      "31/31 [==============================] - 0s 2ms/step\n",
      "62/62 [==============================] - 0s 95us/step\n",
      "[CV] .................... epochs=10, lr=0.001, nodes=16, total=   0.8s\n",
      "[CV] epochs=10, lr=0.001, nodes=32 ...................................\n",
      "Epoch 1/10\n",
      "62/62 [==============================] - 0s 5ms/step - loss: 2.9273 - acc: 0.1452\n",
      "Epoch 2/10\n",
      "62/62 [==============================] - 0s 185us/step - loss: 2.2614 - acc: 0.4677\n",
      "Epoch 3/10\n",
      "62/62 [==============================] - 0s 193us/step - loss: 1.9673 - acc: 0.5645\n",
      "Epoch 4/10\n",
      "62/62 [==============================] - 0s 225us/step - loss: 1.7488 - acc: 0.7258\n",
      "Epoch 5/10\n",
      "62/62 [==============================] - 0s 224us/step - loss: 1.6104 - acc: 0.7097\n",
      "Epoch 6/10\n",
      "62/62 [==============================] - 0s 191us/step - loss: 1.4443 - acc: 0.8065\n",
      "Epoch 7/10\n",
      "62/62 [==============================] - 0s 184us/step - loss: 1.2840 - acc: 0.8065\n",
      "Epoch 8/10\n",
      "62/62 [==============================] - 0s 233us/step - loss: 1.2620 - acc: 0.7581\n",
      "Epoch 9/10\n",
      "62/62 [==============================] - 0s 193us/step - loss: 1.1192 - acc: 0.8226\n",
      "Epoch 10/10\n",
      "62/62 [==============================] - 0s 149us/step - loss: 1.0930 - acc: 0.8226\n",
      "31/31 [==============================] - 0s 3ms/step\n",
      "62/62 [==============================] - 0s 100us/step\n",
      "[CV] .................... epochs=10, lr=0.001, nodes=32, total=   0.8s\n",
      "[CV] epochs=10, lr=0.001, nodes=32 ...................................\n",
      "Epoch 1/10\n",
      "62/62 [==============================] - 0s 5ms/step - loss: 3.0702 - acc: 0.2097\n",
      "Epoch 2/10\n",
      "62/62 [==============================] - 0s 174us/step - loss: 2.4372 - acc: 0.4839\n",
      "Epoch 3/10\n",
      "62/62 [==============================] - 0s 246us/step - loss: 2.2037 - acc: 0.6290\n",
      "Epoch 4/10\n",
      "62/62 [==============================] - 0s 195us/step - loss: 1.9196 - acc: 0.7097\n",
      "Epoch 5/10\n",
      "62/62 [==============================] - 0s 182us/step - loss: 1.8096 - acc: 0.7581\n",
      "Epoch 6/10\n",
      "62/62 [==============================] - 0s 173us/step - loss: 1.6420 - acc: 0.7903\n",
      "Epoch 7/10\n",
      "62/62 [==============================] - 0s 181us/step - loss: 1.5826 - acc: 0.8226\n",
      "Epoch 8/10\n",
      "62/62 [==============================] - 0s 194us/step - loss: 1.5089 - acc: 0.8065\n",
      "Epoch 9/10\n",
      "62/62 [==============================] - 0s 178us/step - loss: 1.4058 - acc: 0.8226\n",
      "Epoch 10/10\n",
      "62/62 [==============================] - 0s 168us/step - loss: 1.4115 - acc: 0.8226\n",
      "31/31 [==============================] - 0s 3ms/step\n",
      "62/62 [==============================] - 0s 98us/step\n",
      "[CV] .................... epochs=10, lr=0.001, nodes=32, total=   1.0s\n",
      "[CV] epochs=10, lr=0.001, nodes=32 ...................................\n",
      "Epoch 1/10\n",
      "62/62 [==============================] - 0s 6ms/step - loss: 3.0561 - acc: 0.0968\n",
      "Epoch 2/10\n",
      "62/62 [==============================] - 0s 191us/step - loss: 2.4149 - acc: 0.4032\n",
      "Epoch 3/10\n",
      "62/62 [==============================] - 0s 191us/step - loss: 2.0710 - acc: 0.5645\n",
      "Epoch 4/10\n",
      "62/62 [==============================] - 0s 190us/step - loss: 1.7784 - acc: 0.7258\n",
      "Epoch 5/10\n",
      "62/62 [==============================] - 0s 274us/step - loss: 1.6378 - acc: 0.7419\n",
      "Epoch 6/10\n",
      "62/62 [==============================] - 0s 263us/step - loss: 1.4825 - acc: 0.8710\n",
      "Epoch 7/10\n",
      "62/62 [==============================] - 0s 211us/step - loss: 1.4494 - acc: 0.8387\n",
      "Epoch 8/10\n",
      "62/62 [==============================] - 0s 199us/step - loss: 1.4159 - acc: 0.7581\n",
      "Epoch 9/10\n",
      "62/62 [==============================] - 0s 218us/step - loss: 1.3027 - acc: 0.9032\n",
      "Epoch 10/10\n",
      "62/62 [==============================] - 0s 222us/step - loss: 1.1927 - acc: 0.8226\n",
      "31/31 [==============================] - 0s 6ms/step\n",
      "62/62 [==============================] - 0s 126us/step\n",
      "[CV] .................... epochs=10, lr=0.001, nodes=32, total=   1.0s\n",
      "[CV] epochs=10, lr=0.002, nodes=16 ...................................\n",
      "Epoch 1/10\n",
      "62/62 [==============================] - 0s 7ms/step - loss: 2.9166 - acc: 0.1452\n",
      "Epoch 2/10\n",
      "62/62 [==============================] - 0s 168us/step - loss: 2.3868 - acc: 0.2742\n",
      "Epoch 3/10\n",
      "62/62 [==============================] - 0s 178us/step - loss: 2.1593 - acc: 0.4677\n",
      "Epoch 4/10\n",
      "62/62 [==============================] - 0s 168us/step - loss: 1.9085 - acc: 0.5968\n",
      "Epoch 5/10\n",
      "62/62 [==============================] - 0s 179us/step - loss: 1.7777 - acc: 0.5806\n",
      "Epoch 6/10\n",
      "62/62 [==============================] - 0s 189us/step - loss: 1.6112 - acc: 0.6935\n",
      "Epoch 7/10\n",
      "62/62 [==============================] - 0s 178us/step - loss: 1.5066 - acc: 0.6774\n",
      "Epoch 8/10\n",
      "62/62 [==============================] - 0s 187us/step - loss: 1.3879 - acc: 0.6935\n",
      "Epoch 9/10\n",
      "62/62 [==============================] - 0s 217us/step - loss: 1.2806 - acc: 0.7419\n",
      "Epoch 10/10\n",
      "62/62 [==============================] - 0s 204us/step - loss: 1.1449 - acc: 0.8387\n",
      "31/31 [==============================] - 0s 4ms/step\n",
      "62/62 [==============================] - 0s 107us/step\n",
      "[CV] .................... epochs=10, lr=0.002, nodes=16, total=   1.2s\n",
      "[CV] epochs=10, lr=0.002, nodes=16 ...................................\n",
      "Epoch 1/10\n",
      "62/62 [==============================] - 0s 6ms/step - loss: 3.0418 - acc: 0.1290\n",
      "Epoch 2/10\n",
      "62/62 [==============================] - 0s 177us/step - loss: 2.4608 - acc: 0.4032\n",
      "Epoch 3/10\n",
      "62/62 [==============================] - 0s 168us/step - loss: 2.0881 - acc: 0.5645\n",
      "Epoch 4/10\n",
      "62/62 [==============================] - 0s 171us/step - loss: 1.9749 - acc: 0.5968\n",
      "Epoch 5/10\n",
      "62/62 [==============================] - 0s 176us/step - loss: 1.8175 - acc: 0.6613\n",
      "Epoch 6/10\n",
      "62/62 [==============================] - 0s 176us/step - loss: 1.8093 - acc: 0.6452\n",
      "Epoch 7/10\n",
      "62/62 [==============================] - 0s 175us/step - loss: 1.7017 - acc: 0.6129\n",
      "Epoch 8/10\n",
      "62/62 [==============================] - 0s 186us/step - loss: 1.6450 - acc: 0.7258\n",
      "Epoch 9/10\n",
      "62/62 [==============================] - 0s 177us/step - loss: 1.4357 - acc: 0.7581\n",
      "Epoch 10/10\n",
      "62/62 [==============================] - 0s 181us/step - loss: 1.5869 - acc: 0.7258\n",
      "31/31 [==============================] - 0s 4ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "62/62 [==============================] - 0s 101us/step\n",
      "[CV] .................... epochs=10, lr=0.002, nodes=16, total=   0.9s\n",
      "[CV] epochs=10, lr=0.002, nodes=16 ...................................\n",
      "Epoch 1/10\n",
      "62/62 [==============================] - 0s 7ms/step - loss: 3.1434 - acc: 0.0806\n",
      "Epoch 2/10\n",
      "62/62 [==============================] - 0s 172us/step - loss: 2.3815 - acc: 0.3710\n",
      "Epoch 3/10\n",
      "62/62 [==============================] - 0s 166us/step - loss: 2.0581 - acc: 0.5161\n",
      "Epoch 4/10\n",
      "62/62 [==============================] - 0s 187us/step - loss: 1.9449 - acc: 0.6452\n",
      "Epoch 5/10\n",
      "62/62 [==============================] - 0s 184us/step - loss: 1.7545 - acc: 0.7419\n",
      "Epoch 6/10\n",
      "62/62 [==============================] - 0s 176us/step - loss: 1.6028 - acc: 0.7258\n",
      "Epoch 7/10\n",
      "62/62 [==============================] - 0s 205us/step - loss: 1.5284 - acc: 0.7097\n",
      "Epoch 8/10\n",
      "62/62 [==============================] - 0s 169us/step - loss: 1.3848 - acc: 0.7742\n",
      "Epoch 9/10\n",
      "62/62 [==============================] - 0s 176us/step - loss: 1.2179 - acc: 0.7903\n",
      "Epoch 10/10\n",
      "62/62 [==============================] - 0s 192us/step - loss: 1.2569 - acc: 0.8226\n",
      "31/31 [==============================] - 0s 5ms/step\n",
      "62/62 [==============================] - 0s 103us/step\n",
      "[CV] .................... epochs=10, lr=0.002, nodes=16, total=   1.0s\n",
      "[CV] epochs=10, lr=0.002, nodes=32 ...................................\n",
      "Epoch 1/10\n",
      "62/62 [==============================] - 1s 8ms/step - loss: 2.9844 - acc: 0.1613\n",
      "Epoch 2/10\n",
      "62/62 [==============================] - 0s 223us/step - loss: 2.0376 - acc: 0.6452\n",
      "Epoch 3/10\n",
      "62/62 [==============================] - 0s 200us/step - loss: 1.5249 - acc: 0.7903\n",
      "Epoch 4/10\n",
      "62/62 [==============================] - 0s 182us/step - loss: 1.3577 - acc: 0.8548\n",
      "Epoch 5/10\n",
      "62/62 [==============================] - 0s 207us/step - loss: 1.0713 - acc: 0.8548\n",
      "Epoch 6/10\n",
      "62/62 [==============================] - 0s 204us/step - loss: 1.0237 - acc: 0.8226\n",
      "Epoch 7/10\n",
      "62/62 [==============================] - 0s 197us/step - loss: 0.9549 - acc: 0.9032\n",
      "Epoch 8/10\n",
      "62/62 [==============================] - 0s 220us/step - loss: 0.9271 - acc: 0.8226\n",
      "Epoch 9/10\n",
      "62/62 [==============================] - 0s 209us/step - loss: 0.8910 - acc: 0.8548\n",
      "Epoch 10/10\n",
      "62/62 [==============================] - 0s 236us/step - loss: 0.8072 - acc: 0.8387\n",
      "31/31 [==============================] - 0s 5ms/step\n",
      "62/62 [==============================] - 0s 99us/step\n",
      "[CV] .................... epochs=10, lr=0.002, nodes=32, total=   1.1s\n",
      "[CV] epochs=10, lr=0.002, nodes=32 ...................................\n",
      "Epoch 1/10\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 3.2639 - acc: 0.0645\n",
      "Epoch 2/10\n",
      "62/62 [==============================] - 0s 173us/step - loss: 2.1662 - acc: 0.6452\n",
      "Epoch 3/10\n",
      "62/62 [==============================] - 0s 195us/step - loss: 1.7286 - acc: 0.7742\n",
      "Epoch 4/10\n",
      "62/62 [==============================] - 0s 177us/step - loss: 1.4590 - acc: 0.7742\n",
      "Epoch 5/10\n",
      "62/62 [==============================] - 0s 206us/step - loss: 1.3460 - acc: 0.8548\n",
      "Epoch 6/10\n",
      "62/62 [==============================] - 0s 242us/step - loss: 1.2843 - acc: 0.8065\n",
      "Epoch 7/10\n",
      "62/62 [==============================] - 0s 224us/step - loss: 1.1493 - acc: 0.8226\n",
      "Epoch 8/10\n",
      "62/62 [==============================] - 0s 221us/step - loss: 1.1285 - acc: 0.8710\n",
      "Epoch 9/10\n",
      "62/62 [==============================] - 0s 194us/step - loss: 1.0250 - acc: 0.8065\n",
      "Epoch 10/10\n",
      "62/62 [==============================] - 0s 183us/step - loss: 0.9430 - acc: 0.8548\n",
      "31/31 [==============================] - 0s 7ms/step\n",
      "62/62 [==============================] - 0s 137us/step\n",
      "[CV] .................... epochs=10, lr=0.002, nodes=32, total=   1.6s\n",
      "[CV] epochs=10, lr=0.002, nodes=32 ...................................\n",
      "Epoch 1/10\n",
      "62/62 [==============================] - 1s 11ms/step - loss: 2.8556 - acc: 0.1613\n",
      "Epoch 2/10\n",
      "62/62 [==============================] - 0s 252us/step - loss: 2.0881 - acc: 0.5806\n",
      "Epoch 3/10\n",
      "62/62 [==============================] - 0s 178us/step - loss: 1.6598 - acc: 0.6935\n",
      "Epoch 4/10\n",
      "62/62 [==============================] - 0s 203us/step - loss: 1.4682 - acc: 0.8548\n",
      "Epoch 5/10\n",
      "62/62 [==============================] - 0s 184us/step - loss: 1.2325 - acc: 0.7581\n",
      "Epoch 6/10\n",
      "62/62 [==============================] - 0s 210us/step - loss: 1.1094 - acc: 0.8548\n",
      "Epoch 7/10\n",
      "62/62 [==============================] - 0s 181us/step - loss: 1.0628 - acc: 0.8387\n",
      "Epoch 8/10\n",
      "62/62 [==============================] - 0s 174us/step - loss: 1.0837 - acc: 0.8710\n",
      "Epoch 9/10\n",
      "62/62 [==============================] - 0s 190us/step - loss: 0.9604 - acc: 0.8387\n",
      "Epoch 10/10\n",
      "62/62 [==============================] - 0s 179us/step - loss: 0.9268 - acc: 0.8710\n",
      "31/31 [==============================] - 0s 8ms/step\n",
      "62/62 [==============================] - 0s 172us/step\n",
      "[CV] .................... epochs=10, lr=0.002, nodes=32, total=   1.5s\n",
      "[CV] epochs=10, lr=0.003, nodes=16 ...................................\n",
      "Epoch 1/10\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 2.9607 - acc: 0.0968\n",
      "Epoch 2/10\n",
      "62/62 [==============================] - 0s 161us/step - loss: 2.1242 - acc: 0.4677\n",
      "Epoch 3/10\n",
      "62/62 [==============================] - 0s 206us/step - loss: 1.7727 - acc: 0.7097\n",
      "Epoch 4/10\n",
      "62/62 [==============================] - 0s 187us/step - loss: 1.5851 - acc: 0.7742\n",
      "Epoch 5/10\n",
      "62/62 [==============================] - 0s 202us/step - loss: 1.2361 - acc: 0.8065\n",
      "Epoch 6/10\n",
      "62/62 [==============================] - 0s 254us/step - loss: 1.2913 - acc: 0.7419\n",
      "Epoch 7/10\n",
      "62/62 [==============================] - 0s 221us/step - loss: 1.1992 - acc: 0.8226\n",
      "Epoch 8/10\n",
      "62/62 [==============================] - 0s 190us/step - loss: 1.1241 - acc: 0.8387\n",
      "Epoch 9/10\n",
      "62/62 [==============================] - 0s 181us/step - loss: 1.0228 - acc: 0.8387\n",
      "Epoch 10/10\n",
      "62/62 [==============================] - 0s 191us/step - loss: 1.0152 - acc: 0.7742\n",
      "31/31 [==============================] - 0s 11ms/step\n",
      "62/62 [==============================] - 0s 106us/step\n",
      "[CV] .................... epochs=10, lr=0.003, nodes=16, total=   1.6s\n",
      "[CV] epochs=10, lr=0.003, nodes=16 ...................................\n",
      "Epoch 1/10\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 2.9058 - acc: 0.2097\n",
      "Epoch 2/10\n",
      "62/62 [==============================] - 0s 175us/step - loss: 2.1034 - acc: 0.5968\n",
      "Epoch 3/10\n",
      "62/62 [==============================] - 0s 190us/step - loss: 1.9320 - acc: 0.7097\n",
      "Epoch 4/10\n",
      "62/62 [==============================] - 0s 204us/step - loss: 1.6903 - acc: 0.6935\n",
      "Epoch 5/10\n",
      "62/62 [==============================] - 0s 198us/step - loss: 1.6026 - acc: 0.7258\n",
      "Epoch 6/10\n",
      "62/62 [==============================] - 0s 214us/step - loss: 1.3345 - acc: 0.7742\n",
      "Epoch 7/10\n",
      "62/62 [==============================] - 0s 210us/step - loss: 1.5812 - acc: 0.7419\n",
      "Epoch 8/10\n",
      "62/62 [==============================] - 0s 230us/step - loss: 1.3525 - acc: 0.8065\n",
      "Epoch 9/10\n",
      "62/62 [==============================] - 0s 205us/step - loss: 1.2764 - acc: 0.8065\n",
      "Epoch 10/10\n",
      "62/62 [==============================] - 0s 155us/step - loss: 1.3139 - acc: 0.8065\n",
      "31/31 [==============================] - 0s 7ms/step\n",
      "62/62 [==============================] - 0s 85us/step\n",
      "[CV] .................... epochs=10, lr=0.003, nodes=16, total=   1.4s\n",
      "[CV] epochs=10, lr=0.003, nodes=16 ...................................\n",
      "Epoch 1/10\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 2.9447 - acc: 0.1129\n",
      "Epoch 2/10\n",
      "62/62 [==============================] - 0s 140us/step - loss: 2.3127 - acc: 0.2903\n",
      "Epoch 3/10\n",
      "62/62 [==============================] - 0s 168us/step - loss: 2.0780 - acc: 0.5000\n",
      "Epoch 4/10\n",
      "62/62 [==============================] - 0s 172us/step - loss: 1.9844 - acc: 0.4516\n",
      "Epoch 5/10\n",
      "62/62 [==============================] - 0s 164us/step - loss: 1.7308 - acc: 0.5645\n",
      "Epoch 6/10\n",
      "62/62 [==============================] - 0s 172us/step - loss: 1.3508 - acc: 0.7097\n",
      "Epoch 7/10\n",
      "62/62 [==============================] - 0s 173us/step - loss: 1.5232 - acc: 0.6290\n",
      "Epoch 8/10\n",
      "62/62 [==============================] - 0s 247us/step - loss: 1.4141 - acc: 0.7419\n",
      "Epoch 9/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "62/62 [==============================] - 0s 253us/step - loss: 1.2315 - acc: 0.8387\n",
      "Epoch 10/10\n",
      "62/62 [==============================] - 0s 166us/step - loss: 1.1730 - acc: 0.8065\n",
      "31/31 [==============================] - 0s 9ms/step\n",
      "62/62 [==============================] - 0s 107us/step\n",
      "[CV] .................... epochs=10, lr=0.003, nodes=16, total=   1.4s\n",
      "[CV] epochs=10, lr=0.003, nodes=32 ...................................\n",
      "Epoch 1/10\n",
      "62/62 [==============================] - 1s 11ms/step - loss: 2.7647 - acc: 0.1774\n",
      "Epoch 2/10\n",
      "62/62 [==============================] - 0s 209us/step - loss: 1.9091 - acc: 0.5645\n",
      "Epoch 3/10\n",
      "62/62 [==============================] - 0s 240us/step - loss: 1.3793 - acc: 0.7581\n",
      "Epoch 4/10\n",
      "62/62 [==============================] - 0s 245us/step - loss: 1.1529 - acc: 0.8548\n",
      "Epoch 5/10\n",
      "62/62 [==============================] - 0s 310us/step - loss: 1.0123 - acc: 0.8226\n",
      "Epoch 6/10\n",
      "62/62 [==============================] - 0s 253us/step - loss: 0.9684 - acc: 0.8226\n",
      "Epoch 7/10\n",
      "62/62 [==============================] - 0s 262us/step - loss: 0.8816 - acc: 0.9194\n",
      "Epoch 8/10\n",
      "62/62 [==============================] - 0s 265us/step - loss: 0.8008 - acc: 0.8387\n",
      "Epoch 9/10\n",
      "62/62 [==============================] - 0s 199us/step - loss: 0.7009 - acc: 0.9032\n",
      "Epoch 10/10\n",
      "62/62 [==============================] - 0s 219us/step - loss: 0.6765 - acc: 0.8548\n",
      "31/31 [==============================] - 0s 10ms/step\n",
      "62/62 [==============================] - 0s 99us/step\n",
      "[CV] .................... epochs=10, lr=0.003, nodes=32, total=   1.5s\n",
      "[CV] epochs=10, lr=0.003, nodes=32 ...................................\n",
      "Epoch 1/10\n",
      "62/62 [==============================] - 1s 11ms/step - loss: 2.9678 - acc: 0.1129\n",
      "Epoch 2/10\n",
      "62/62 [==============================] - 0s 203us/step - loss: 2.1104 - acc: 0.7581\n",
      "Epoch 3/10\n",
      "62/62 [==============================] - 0s 188us/step - loss: 1.5843 - acc: 0.7903\n",
      "Epoch 4/10\n",
      "62/62 [==============================] - 0s 168us/step - loss: 1.3890 - acc: 0.7742\n",
      "Epoch 5/10\n",
      "62/62 [==============================] - 0s 227us/step - loss: 1.1978 - acc: 0.8387\n",
      "Epoch 6/10\n",
      "62/62 [==============================] - 0s 175us/step - loss: 1.1168 - acc: 0.8871\n",
      "Epoch 7/10\n",
      "62/62 [==============================] - 0s 177us/step - loss: 1.0307 - acc: 0.8710\n",
      "Epoch 8/10\n",
      "62/62 [==============================] - 0s 177us/step - loss: 0.9376 - acc: 0.8710\n",
      "Epoch 9/10\n",
      "62/62 [==============================] - 0s 164us/step - loss: 0.9696 - acc: 0.8710\n",
      "Epoch 10/10\n",
      "62/62 [==============================] - 0s 200us/step - loss: 1.1314 - acc: 0.8387\n",
      "31/31 [==============================] - 0s 10ms/step\n",
      "62/62 [==============================] - 0s 87us/step\n",
      "[CV] .................... epochs=10, lr=0.003, nodes=32, total=   1.4s\n",
      "[CV] epochs=10, lr=0.003, nodes=32 ...................................\n",
      "Epoch 1/10\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 3.0795 - acc: 0.1129\n",
      "Epoch 2/10\n",
      "62/62 [==============================] - 0s 185us/step - loss: 2.1533 - acc: 0.5645\n",
      "Epoch 3/10\n",
      "62/62 [==============================] - 0s 197us/step - loss: 1.6596 - acc: 0.7742\n",
      "Epoch 4/10\n",
      "62/62 [==============================] - 0s 237us/step - loss: 1.3834 - acc: 0.8387\n",
      "Epoch 5/10\n",
      "62/62 [==============================] - 0s 205us/step - loss: 1.2561 - acc: 0.8226\n",
      "Epoch 6/10\n",
      "62/62 [==============================] - 0s 203us/step - loss: 1.1330 - acc: 0.8387\n",
      "Epoch 7/10\n",
      "62/62 [==============================] - 0s 215us/step - loss: 1.1003 - acc: 0.8387\n",
      "Epoch 8/10\n",
      "62/62 [==============================] - 0s 218us/step - loss: 1.0289 - acc: 0.8710\n",
      "Epoch 9/10\n",
      "62/62 [==============================] - 0s 199us/step - loss: 1.0119 - acc: 0.8065\n",
      "Epoch 10/10\n",
      "62/62 [==============================] - 0s 202us/step - loss: 0.9705 - acc: 0.8226\n",
      "31/31 [==============================] - 0s 8ms/step\n",
      "62/62 [==============================] - 0s 105us/step\n",
      "[CV] .................... epochs=10, lr=0.003, nodes=32, total=   1.5s\n",
      "[CV] epochs=20, lr=0.001, nodes=16 ...................................\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 1s 11ms/step - loss: 3.0236 - acc: 0.0645\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 0s 175us/step - loss: 2.4984 - acc: 0.2903\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 0s 183us/step - loss: 2.3214 - acc: 0.3387\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 0s 173us/step - loss: 2.2428 - acc: 0.4032\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 0s 211us/step - loss: 2.1101 - acc: 0.4839\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 0s 197us/step - loss: 2.0029 - acc: 0.5806\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 0s 180us/step - loss: 1.9284 - acc: 0.4839\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 0s 174us/step - loss: 1.8584 - acc: 0.5323\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 0s 208us/step - loss: 1.8639 - acc: 0.5323\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 0s 233us/step - loss: 1.7234 - acc: 0.6290\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 0s 172us/step - loss: 1.6461 - acc: 0.6290\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 0s 182us/step - loss: 1.6363 - acc: 0.6129\n",
      "Epoch 13/20\n",
      "62/62 [==============================] - 0s 185us/step - loss: 1.5316 - acc: 0.6290\n",
      "Epoch 14/20\n",
      "62/62 [==============================] - 0s 228us/step - loss: 1.5609 - acc: 0.6774\n",
      "Epoch 15/20\n",
      "62/62 [==============================] - 0s 188us/step - loss: 1.4743 - acc: 0.7742\n",
      "Epoch 16/20\n",
      "62/62 [==============================] - 0s 217us/step - loss: 1.5878 - acc: 0.6774\n",
      "Epoch 17/20\n",
      "62/62 [==============================] - 0s 214us/step - loss: 1.5622 - acc: 0.6613\n",
      "Epoch 18/20\n",
      "62/62 [==============================] - 0s 225us/step - loss: 1.4613 - acc: 0.6613\n",
      "Epoch 19/20\n",
      "62/62 [==============================] - 0s 214us/step - loss: 1.3149 - acc: 0.8065\n",
      "Epoch 20/20\n",
      "62/62 [==============================] - 0s 237us/step - loss: 1.4162 - acc: 0.6452\n",
      "31/31 [==============================] - 0s 11ms/step\n",
      "62/62 [==============================] - 0s 139us/step\n",
      "[CV] .................... epochs=20, lr=0.001, nodes=16, total=   1.6s\n",
      "[CV] epochs=20, lr=0.001, nodes=16 ...................................\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 3.0696 - acc: 0.1613\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 0s 171us/step - loss: 2.5876 - acc: 0.3065\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 0s 176us/step - loss: 2.4055 - acc: 0.5323\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 0s 151us/step - loss: 2.1974 - acc: 0.6613\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 0s 161us/step - loss: 2.0526 - acc: 0.6613\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 0s 157us/step - loss: 2.0154 - acc: 0.6452\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 0s 143us/step - loss: 1.9858 - acc: 0.7097\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 0s 171us/step - loss: 1.8800 - acc: 0.7258\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 0s 189us/step - loss: 1.7366 - acc: 0.7097\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 0s 150us/step - loss: 1.7627 - acc: 0.7742\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 0s 209us/step - loss: 1.5818 - acc: 0.8387\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 0s 154us/step - loss: 1.5515 - acc: 0.7903\n",
      "Epoch 13/20\n",
      "62/62 [==============================] - 0s 173us/step - loss: 1.5757 - acc: 0.8226\n",
      "Epoch 14/20\n",
      "62/62 [==============================] - 0s 166us/step - loss: 1.5388 - acc: 0.7581\n",
      "Epoch 15/20\n",
      "62/62 [==============================] - 0s 164us/step - loss: 1.4816 - acc: 0.7903\n",
      "Epoch 16/20\n",
      "62/62 [==============================] - 0s 173us/step - loss: 1.3845 - acc: 0.8710\n",
      "Epoch 17/20\n",
      "62/62 [==============================] - 0s 214us/step - loss: 1.4115 - acc: 0.8226\n",
      "Epoch 18/20\n",
      "62/62 [==============================] - 0s 288us/step - loss: 1.3473 - acc: 0.8226\n",
      "Epoch 19/20\n",
      "62/62 [==============================] - 0s 207us/step - loss: 1.2947 - acc: 0.8226\n",
      "Epoch 20/20\n",
      "62/62 [==============================] - 0s 221us/step - loss: 1.2372 - acc: 0.8548\n",
      "31/31 [==============================] - 0s 10ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "62/62 [==============================] - 0s 93us/step\n",
      "[CV] .................... epochs=20, lr=0.001, nodes=16, total=   1.8s\n",
      "[CV] epochs=20, lr=0.001, nodes=16 ...................................\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 1s 12ms/step - loss: 3.0638 - acc: 0.0323\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 0s 173us/step - loss: 2.7109 - acc: 0.2258\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 0s 202us/step - loss: 2.5046 - acc: 0.4677\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 0s 183us/step - loss: 2.3711 - acc: 0.4516\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 0s 167us/step - loss: 2.2497 - acc: 0.5000\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 0s 229us/step - loss: 2.1223 - acc: 0.5645\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 0s 170us/step - loss: 2.0045 - acc: 0.6290\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 0s 240us/step - loss: 1.9655 - acc: 0.6290\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 0s 178us/step - loss: 1.9551 - acc: 0.7097\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 0s 226us/step - loss: 1.7894 - acc: 0.7903\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 0s 171us/step - loss: 1.7307 - acc: 0.6935\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 0s 175us/step - loss: 1.7218 - acc: 0.6452\n",
      "Epoch 13/20\n",
      "62/62 [==============================] - 0s 188us/step - loss: 1.6634 - acc: 0.6613\n",
      "Epoch 14/20\n",
      "62/62 [==============================] - 0s 193us/step - loss: 1.4889 - acc: 0.7419\n",
      "Epoch 15/20\n",
      "62/62 [==============================] - 0s 227us/step - loss: 1.5519 - acc: 0.7903\n",
      "Epoch 16/20\n",
      "62/62 [==============================] - 0s 197us/step - loss: 1.4317 - acc: 0.7742\n",
      "Epoch 17/20\n",
      "62/62 [==============================] - 0s 198us/step - loss: 1.5750 - acc: 0.7258\n",
      "Epoch 18/20\n",
      "62/62 [==============================] - 0s 213us/step - loss: 1.4931 - acc: 0.7903\n",
      "Epoch 19/20\n",
      "62/62 [==============================] - 0s 193us/step - loss: 1.4678 - acc: 0.7581\n",
      "Epoch 20/20\n",
      "62/62 [==============================] - 0s 182us/step - loss: 1.3253 - acc: 0.8226\n",
      "31/31 [==============================] - 0s 9ms/step\n",
      "62/62 [==============================] - 0s 94us/step\n",
      "[CV] .................... epochs=20, lr=0.001, nodes=16, total=   1.6s\n",
      "[CV] epochs=20, lr=0.001, nodes=32 ...................................\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 1s 12ms/step - loss: 3.0611 - acc: 0.0806\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 0s 225us/step - loss: 2.3913 - acc: 0.4032\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 0s 220us/step - loss: 2.1315 - acc: 0.5323\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 0s 264us/step - loss: 1.9140 - acc: 0.6452\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 0s 235us/step - loss: 1.7457 - acc: 0.8065\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 0s 262us/step - loss: 1.5785 - acc: 0.7097\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 0s 236us/step - loss: 1.4398 - acc: 0.8710\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 0s 212us/step - loss: 1.4237 - acc: 0.8226\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 0s 242us/step - loss: 1.3101 - acc: 0.8387\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 0s 235us/step - loss: 1.2563 - acc: 0.8387\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 0s 229us/step - loss: 1.0978 - acc: 0.8548\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 0s 269us/step - loss: 1.0935 - acc: 0.8871\n",
      "Epoch 13/20\n",
      "62/62 [==============================] - 0s 215us/step - loss: 1.0992 - acc: 0.8548\n",
      "Epoch 14/20\n",
      "62/62 [==============================] - 0s 247us/step - loss: 1.0140 - acc: 0.8710\n",
      "Epoch 15/20\n",
      "62/62 [==============================] - 0s 202us/step - loss: 1.0135 - acc: 0.8387\n",
      "Epoch 16/20\n",
      "62/62 [==============================] - 0s 231us/step - loss: 0.9793 - acc: 0.8548\n",
      "Epoch 17/20\n",
      "62/62 [==============================] - 0s 227us/step - loss: 0.9303 - acc: 0.8871\n",
      "Epoch 18/20\n",
      "62/62 [==============================] - 0s 209us/step - loss: 0.8826 - acc: 0.8871\n",
      "Epoch 19/20\n",
      "62/62 [==============================] - 0s 274us/step - loss: 0.8584 - acc: 0.8387\n",
      "Epoch 20/20\n",
      "62/62 [==============================] - 0s 202us/step - loss: 0.8304 - acc: 0.8710\n",
      "31/31 [==============================] - 0s 10ms/step\n",
      "62/62 [==============================] - 0s 94us/step\n",
      "[CV] .................... epochs=20, lr=0.001, nodes=32, total=   1.7s\n",
      "[CV] epochs=20, lr=0.001, nodes=32 ...................................\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 1s 12ms/step - loss: 3.0773 - acc: 0.0323\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 0s 208us/step - loss: 2.5295 - acc: 0.2903\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 0s 207us/step - loss: 2.1559 - acc: 0.5484\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 0s 207us/step - loss: 2.0226 - acc: 0.5806\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 0s 194us/step - loss: 1.8595 - acc: 0.6774\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 0s 186us/step - loss: 1.7587 - acc: 0.7742\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 0s 186us/step - loss: 1.6218 - acc: 0.8387\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 0s 194us/step - loss: 1.5235 - acc: 0.8226\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 0s 185us/step - loss: 1.3925 - acc: 0.8710\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 0s 196us/step - loss: 1.3543 - acc: 0.8871\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 0s 166us/step - loss: 1.3015 - acc: 0.8871\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 0s 171us/step - loss: 1.1883 - acc: 0.8871\n",
      "Epoch 13/20\n",
      "62/62 [==============================] - 0s 175us/step - loss: 1.2266 - acc: 0.8710\n",
      "Epoch 14/20\n",
      "62/62 [==============================] - 0s 184us/step - loss: 1.0929 - acc: 0.8387\n",
      "Epoch 15/20\n",
      "62/62 [==============================] - 0s 190us/step - loss: 1.1212 - acc: 0.9194\n",
      "Epoch 16/20\n",
      "62/62 [==============================] - 0s 253us/step - loss: 1.0473 - acc: 0.9194\n",
      "Epoch 17/20\n",
      "62/62 [==============================] - 0s 200us/step - loss: 1.0923 - acc: 0.8548\n",
      "Epoch 18/20\n",
      "62/62 [==============================] - 0s 209us/step - loss: 1.0554 - acc: 0.8871\n",
      "Epoch 19/20\n",
      "62/62 [==============================] - 0s 192us/step - loss: 0.9776 - acc: 0.8226\n",
      "Epoch 20/20\n",
      "62/62 [==============================] - 0s 187us/step - loss: 1.0057 - acc: 0.8710\n",
      "31/31 [==============================] - 0s 10ms/step\n",
      "62/62 [==============================] - 0s 115us/step\n",
      "[CV] .................... epochs=20, lr=0.001, nodes=32, total=   1.6s\n",
      "[CV] epochs=20, lr=0.001, nodes=32 ...................................\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 1s 14ms/step - loss: 3.0424 - acc: 0.1290\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 0s 301us/step - loss: 2.4181 - acc: 0.4839\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 0s 207us/step - loss: 2.0864 - acc: 0.6774\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 0s 228us/step - loss: 1.9549 - acc: 0.6613\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 0s 213us/step - loss: 1.7715 - acc: 0.7903\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 0s 281us/step - loss: 1.6533 - acc: 0.7903\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 0s 255us/step - loss: 1.6359 - acc: 0.7742\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 0s 235us/step - loss: 1.4314 - acc: 0.8387\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 0s 230us/step - loss: 1.3538 - acc: 0.7903\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 0s 269us/step - loss: 1.3172 - acc: 0.8387\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 0s 293us/step - loss: 1.2121 - acc: 0.8548\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 0s 230us/step - loss: 1.0841 - acc: 0.8710\n",
      "Epoch 13/20\n",
      "62/62 [==============================] - 0s 226us/step - loss: 1.1583 - acc: 0.8548\n",
      "Epoch 14/20\n",
      "62/62 [==============================] - 0s 257us/step - loss: 1.1490 - acc: 0.8387\n",
      "Epoch 15/20\n",
      "62/62 [==============================] - 0s 247us/step - loss: 1.0692 - acc: 0.8871\n",
      "Epoch 16/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "62/62 [==============================] - 0s 300us/step - loss: 1.0236 - acc: 0.9194\n",
      "Epoch 17/20\n",
      "62/62 [==============================] - 0s 279us/step - loss: 0.9782 - acc: 0.8548\n",
      "Epoch 18/20\n",
      "62/62 [==============================] - 0s 217us/step - loss: 1.0061 - acc: 0.8548\n",
      "Epoch 19/20\n",
      "62/62 [==============================] - 0s 224us/step - loss: 0.9581 - acc: 0.8387\n",
      "Epoch 20/20\n",
      "62/62 [==============================] - 0s 251us/step - loss: 1.0055 - acc: 0.8065\n",
      "31/31 [==============================] - 0s 13ms/step\n",
      "62/62 [==============================] - 0s 175us/step\n",
      "[CV] .................... epochs=20, lr=0.001, nodes=32, total=   1.9s\n",
      "[CV] epochs=20, lr=0.002, nodes=16 ...................................\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 1s 14ms/step - loss: 2.8171 - acc: 0.1613\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 0s 185us/step - loss: 2.1704 - acc: 0.4355\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 0s 205us/step - loss: 1.8330 - acc: 0.5806\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 0s 220us/step - loss: 1.5728 - acc: 0.7097\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 0s 260us/step - loss: 1.4861 - acc: 0.6935\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 0s 215us/step - loss: 1.3070 - acc: 0.7419\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 0s 229us/step - loss: 1.1683 - acc: 0.8226\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 0s 206us/step - loss: 1.2704 - acc: 0.7903\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 0s 221us/step - loss: 1.0735 - acc: 0.8548\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 0s 240us/step - loss: 1.0317 - acc: 0.7419\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 0s 217us/step - loss: 1.0015 - acc: 0.7903\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 0s 191us/step - loss: 1.0268 - acc: 0.8065\n",
      "Epoch 13/20\n",
      "62/62 [==============================] - 0s 228us/step - loss: 0.9963 - acc: 0.8387\n",
      "Epoch 14/20\n",
      "62/62 [==============================] - 0s 189us/step - loss: 0.9578 - acc: 0.8387\n",
      "Epoch 15/20\n",
      "62/62 [==============================] - 0s 238us/step - loss: 0.8228 - acc: 0.8548\n",
      "Epoch 16/20\n",
      "62/62 [==============================] - 0s 257us/step - loss: 0.9748 - acc: 0.7581\n",
      "Epoch 17/20\n",
      "62/62 [==============================] - 0s 231us/step - loss: 0.8785 - acc: 0.8226\n",
      "Epoch 18/20\n",
      "62/62 [==============================] - 0s 201us/step - loss: 0.7263 - acc: 0.8710\n",
      "Epoch 19/20\n",
      "62/62 [==============================] - 0s 237us/step - loss: 0.9084 - acc: 0.8548\n",
      "Epoch 20/20\n",
      "62/62 [==============================] - 0s 193us/step - loss: 0.7783 - acc: 0.8387\n",
      "31/31 [==============================] - 0s 11ms/step\n",
      "62/62 [==============================] - 0s 99us/step\n",
      "[CV] .................... epochs=20, lr=0.002, nodes=16, total=   1.9s\n",
      "[CV] epochs=20, lr=0.002, nodes=16 ...................................\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 1s 14ms/step - loss: 3.0430 - acc: 0.1452\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 0s 208us/step - loss: 2.4771 - acc: 0.4355\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 0s 198us/step - loss: 2.2627 - acc: 0.4677\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 0s 190us/step - loss: 2.1171 - acc: 0.5806\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 0s 193us/step - loss: 2.1159 - acc: 0.5484\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 0s 223us/step - loss: 1.9878 - acc: 0.4677\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 0s 191us/step - loss: 1.7984 - acc: 0.6452\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 0s 178us/step - loss: 1.6879 - acc: 0.6935\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 0s 237us/step - loss: 1.8285 - acc: 0.5484\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 0s 254us/step - loss: 1.6720 - acc: 0.6613\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 0s 189us/step - loss: 1.6917 - acc: 0.6452\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 0s 200us/step - loss: 1.6946 - acc: 0.6452\n",
      "Epoch 13/20\n",
      "62/62 [==============================] - 0s 210us/step - loss: 1.4349 - acc: 0.8226\n",
      "Epoch 14/20\n",
      "62/62 [==============================] - 0s 256us/step - loss: 1.4398 - acc: 0.8226\n",
      "Epoch 15/20\n",
      "62/62 [==============================] - 0s 184us/step - loss: 1.4756 - acc: 0.6774\n",
      "Epoch 16/20\n",
      "62/62 [==============================] - 0s 200us/step - loss: 1.2904 - acc: 0.9032\n",
      "Epoch 17/20\n",
      "62/62 [==============================] - 0s 202us/step - loss: 1.3078 - acc: 0.8226\n",
      "Epoch 18/20\n",
      "62/62 [==============================] - 0s 239us/step - loss: 1.3613 - acc: 0.7581\n",
      "Epoch 19/20\n",
      "62/62 [==============================] - 0s 197us/step - loss: 1.2378 - acc: 0.7419\n",
      "Epoch 20/20\n",
      "62/62 [==============================] - 0s 202us/step - loss: 1.1658 - acc: 0.8387\n",
      "31/31 [==============================] - 0s 11ms/step\n",
      "62/62 [==============================] - 0s 107us/step\n",
      "[CV] .................... epochs=20, lr=0.002, nodes=16, total=   1.9s\n",
      "[CV] epochs=20, lr=0.002, nodes=16 ...................................\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 1s 17ms/step - loss: 2.9558 - acc: 0.1774\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 0s 178us/step - loss: 2.2327 - acc: 0.5645\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 0s 195us/step - loss: 2.0793 - acc: 0.6613\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 0s 195us/step - loss: 1.8488 - acc: 0.6774\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 0s 195us/step - loss: 1.6821 - acc: 0.6935\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 0s 239us/step - loss: 1.4765 - acc: 0.7419\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 0s 222us/step - loss: 1.5018 - acc: 0.6935\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 0s 217us/step - loss: 1.3108 - acc: 0.7742\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 0s 204us/step - loss: 1.2863 - acc: 0.7097\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 0s 225us/step - loss: 1.2232 - acc: 0.7258\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 0s 195us/step - loss: 1.2492 - acc: 0.7097\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 0s 220us/step - loss: 1.2314 - acc: 0.7742\n",
      "Epoch 13/20\n",
      "62/62 [==============================] - 0s 195us/step - loss: 1.2164 - acc: 0.7258\n",
      "Epoch 14/20\n",
      "62/62 [==============================] - 0s 188us/step - loss: 1.1362 - acc: 0.7581\n",
      "Epoch 15/20\n",
      "62/62 [==============================] - 0s 243us/step - loss: 1.2025 - acc: 0.8226\n",
      "Epoch 16/20\n",
      "62/62 [==============================] - 0s 238us/step - loss: 1.1690 - acc: 0.7742\n",
      "Epoch 17/20\n",
      "62/62 [==============================] - 0s 223us/step - loss: 1.0757 - acc: 0.8065\n",
      "Epoch 18/20\n",
      "62/62 [==============================] - 0s 199us/step - loss: 1.0327 - acc: 0.8226\n",
      "Epoch 19/20\n",
      "62/62 [==============================] - 0s 189us/step - loss: 1.1237 - acc: 0.7419\n",
      "Epoch 20/20\n",
      "62/62 [==============================] - 0s 245us/step - loss: 1.0472 - acc: 0.7581\n",
      "31/31 [==============================] - 0s 14ms/step\n",
      "62/62 [==============================] - 0s 125us/step\n",
      "[CV] .................... epochs=20, lr=0.002, nodes=16, total=   2.3s\n",
      "[CV] epochs=20, lr=0.002, nodes=32 ...................................\n",
      "Epoch 1/20\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-64-0222770f62cf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mparam_grid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnodes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnodes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlrs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mgrid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGridSearchCV\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam_grid\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mrefit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mgrid_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgrid\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.pyenv/versions/3.6.4/lib/python3.6/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    637\u001b[0m                                   error_score=self.error_score)\n\u001b[1;32m    638\u001b[0m           for parameters, (train, test) in product(candidate_params,\n\u001b[0;32m--> 639\u001b[0;31m                                                    cv.split(X, y, groups)))\n\u001b[0m\u001b[1;32m    640\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    641\u001b[0m         \u001b[0;31m# if one choose to see train score, \"out\" will contain train score info\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.6.4/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m    777\u001b[0m             \u001b[0;31m# was dispatched. In particular this covers the edge\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    778\u001b[0m             \u001b[0;31m# case of Parallel used with an exhausted iterator.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 779\u001b[0;31m             \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    780\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    781\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.6.4/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    623\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    624\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 625\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    626\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    627\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.6.4/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    586\u001b[0m         \u001b[0mdispatch_timestamp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    587\u001b[0m         \u001b[0mcb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBatchCompletionCallBack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdispatch_timestamp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 588\u001b[0;31m         \u001b[0mjob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    589\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    590\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.6.4/lib/python3.6/site-packages/sklearn/externals/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    109\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m         \u001b[0;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 111\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    112\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.6.4/lib/python3.6/site-packages/sklearn/externals/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    330\u001b[0m         \u001b[0;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    331\u001b[0m         \u001b[0;31m# arguments in memory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 332\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    333\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    334\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.6.4/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 131\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.6.4/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 131\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.6.4/lib/python3.6/site-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36m_fit_and_score\u001b[0;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, error_score)\u001b[0m\n\u001b[1;32m    456\u001b[0m             \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    457\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 458\u001b[0;31m             \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    459\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    460\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.6.4/lib/python3.6/site-packages/keras/wrappers/scikit_learn.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, sample_weight, **kwargs)\u001b[0m\n\u001b[1;32m    207\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0msample_weight\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    208\u001b[0m             \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'sample_weight'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 209\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mKerasClassifier\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    210\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    211\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.6.4/lib/python3.6/site-packages/keras/wrappers/scikit_learn.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, **kwargs)\u001b[0m\n\u001b[1;32m    149\u001b[0m         \u001b[0mfit_args\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    150\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 151\u001b[0;31m         \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    152\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    153\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mhistory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.6.4/lib/python3.6/site-packages/keras/models.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m    961\u001b[0m                               \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    962\u001b[0m                               \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 963\u001b[0;31m                               validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m    964\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    965\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[0;32m~/.pyenv/versions/3.6.4/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1703\u001b[0m                               \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1704\u001b[0m                               \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1705\u001b[0;31m                               validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1706\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1707\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[0;32m~/.pyenv/versions/3.6.4/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_fit_loop\u001b[0;34m(self, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m   1233\u001b[0m                         \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1234\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1235\u001b[0;31m                     \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1236\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1237\u001b[0m                         \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.6.4/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2474\u001b[0m             \u001b[0mfeed_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2475\u001b[0m         \u001b[0mfetches\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdates_op\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetches\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2476\u001b[0;31m         \u001b[0msession\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2477\u001b[0m         updated = session.run(fetches=fetches, feed_dict=feed_dict,\n\u001b[1;32m   2478\u001b[0m                               **self.session_kwargs)\n",
      "\u001b[0;32m~/.pyenv/versions/3.6.4/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36mget_session\u001b[0;34m()\u001b[0m\n\u001b[1;32m    190\u001b[0m                 \u001b[0;31m# not already marked as initialized.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    191\u001b[0m                 is_initialized = session.run(\n\u001b[0;32m--> 192\u001b[0;31m                     [tf.is_variable_initialized(v) for v in candidate_vars])\n\u001b[0m\u001b[1;32m    193\u001b[0m                 \u001b[0muninitialized_vars\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    194\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mflag\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_initialized\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcandidate_vars\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.6.4/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    903\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    904\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 905\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    906\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    907\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.6.4/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1138\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1139\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1140\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1141\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1142\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.6.4/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1319\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1320\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1321\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1322\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1323\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.6.4/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1325\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1326\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1327\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1328\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1329\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.6.4/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1308\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_run_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1309\u001b[0m       \u001b[0;31m# Ensure any changes to the graph are reflected in the runtime.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1310\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1311\u001b[0m       return self._call_tf_sessionrun(\n\u001b[1;32m   1312\u001b[0m           options, feed_dict, fetch_list, target_list, run_metadata)\n",
      "\u001b[0;32m~/.pyenv/versions/3.6.4/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_extend_graph\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1356\u001b[0m           \u001b[0;32mwith\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_exception_on_not_ok_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1357\u001b[0m             tf_session.TF_ExtendGraph(self._session,\n\u001b[0;32m-> 1358\u001b[0;31m                                       graph_def.SerializeToString(), status)\n\u001b[0m\u001b[1;32m   1359\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_opened\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1360\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#start fitting process\n",
    "param_grid = dict(epochs=epochs,nodes=nodes, lr=lrs)\n",
    "grid = GridSearchCV(estimator=model, param_grid=param_grid, n_jobs=1,refit=True,verbose=2)\n",
    "grid_result = grid.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(grid_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Best estimator : {}'.format (grid.best_estimator_))\n",
    "print('Best score : {}'.format(grid.best_score_))\n",
    "print('Best params : {}'.format(grid.best_params_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(grid.cv_results_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#predictions\n",
    "predictions = grid.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#predictions\n",
    "predict = grid.predict_proba(X_test)\n",
    "print(predict.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculate score\n",
    "loss = log_loss(Y_test,predict)\n",
    "print(\"Log_loss : {}\".format(loss))\n",
    "predict = np.round(predict)\n",
    "loss = hamming_loss(Y_test,predict)\n",
    "print(\"Hamming_loss : {}\".format(loss*100))\n",
    "accuracy = accuracy_score(Y_test,predict)\n",
    "print(\"Accuracy : {}\".format(accuracy*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Working through our model's predictions on new data \n",
    "We have 4 example files, let us see what are the predictions on these examples -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Description:\n",
      "This application helps to practice drawing images with multi colors and write letters and numbers, this app makes you develop interest in painting and creative thinking.\n",
      "\n",
      "Key Features of this Application\n",
      "\n",
      " This app design makes more attractive with kids\n",
      " Magic Slate drawing and writing board with multicolor\n",
      " A digital slate where you can write, draw and clear\n",
      " It's a free app and an off-line app\n",
      " Kids can learn drawing or writing alphabets and numbers\n",
      " Save your kids drawings in your mobile\n",
      " Kids can begin their study with this amazing application\n",
      " Multiple brush sizes are available to choose\n",
      " Share and print your kid's artwork with family and friends\n",
      " Eraser available to make correction\n",
      " Multicolored pallet available to choose and draw painting\n",
      "\n",
      "Don't keep \"Magic Slate\" app a secret! We grow with your support, keep sharing :)\n",
      "\n",
      "Please don't leave negative feedback! Instead, please contact us @ ng.labs108@gmail.com and we'll do our best to solve your issues.\n",
      "\n",
      "Category: Maths and Exam Preparation\n",
      "\n",
      "Description\n",
      "This program is designed for those who want to learn interesting mathematical tricks to speed up the calculating. These tricks will help solve part of the mathematical problems and tasks much faster than classical. Will also be helpful to those who want to hone basics such as the multiplication table\n",
      "\n",
      "Math Tricks Competitive Exam, Vedic Math Tricks, Fast Math Tricks\n",
      "\n",
      "Math Tricks & Shortcuts for Competitive Exam app is a preparatory app on mathematics for various competitive examinations, like, SSC, UPSC, CPO, LIC, GIC and UTI among others.\n",
      "The aim of this app is not only to acquaint the students with various types of problems given in these examinations and how to solve them, but also to teach the students effective ways to tackle each of the problems faster and more effectively.\n",
      "You can also find MCQ on Math tricks.\n",
      "App comes with many functionality like speed test, bookmark, result check etc.\n",
      "\n",
      "maths tricks\n",
      "mental math tricks\n",
      "maths shortcuts\n",
      "mental maths tricks\n",
      "multiplication tricks\n",
      "tricks of maths\n",
      "maths tricks for kids\n",
      "maths short tricks\n",
      "short tricks of maths\n",
      "math short tricks\n",
      "math tricks for kids\n",
      "maths tricks for fast calculation\n",
      "easy maths tricks\n",
      "short tricks for maths\n",
      "quick math tricks\n",
      "tricks in maths\n",
      "simple math tricks\n",
      "maths tricks in hindi\n",
      "shortcuts in maths\n",
      "arithmetic shortcuts\n",
      "quicker math tricks\n",
      "maths shortcut tricks\n",
      "shortcut math\n",
      "tricks for maths\n",
      "short cut math\n",
      "speed maths tricks\n",
      "funny maths tricks\n",
      "easy multiplication\n",
      "math shortcut tricks\n",
      "quicker mathematics\n",
      "shortcut tricks for maths\n",
      "multiplication shortcuts\n",
      "shortcut math tricks\n",
      "fast math tricks\n",
      "maths calculation tricks\n",
      "mathematics tricks of calculation\n",
      "math shortcuts and tricks\n",
      "shortcuts of maths\n",
      "maths short tricks in hindi\n",
      "math shortcut\n",
      "amazing math tricks\n",
      "best math tricks\n",
      "shortcut tricks of maths\n",
      "maths easy tricks\n",
      "arithmetic tricks\n",
      "some maths tricks\n",
      "quicker maths tricks\n",
      "math number tricks\n",
      "tricks for mental math\n",
      "fast maths tricks\n",
      "short math tricks\n",
      "maths magics\n",
      "funny math tricks\n",
      "interesting maths tricks\n",
      "mental arithmetic tricks\n",
      "arithmetic shortcuts and tricks\n",
      "tricks to solve maths\n",
      "short cut tricks of mathematics\n",
      "maths multiplication tricks\n",
      "maths number tricks\n",
      "mathes tricks\n",
      "short tricks in maths\n",
      "magical maths\n",
      "short tricks to solve math problems\n",
      "short tricks of math in hindi\n",
      "shortcut method for multiplication\n",
      "tricks for multiplication\n",
      "fast multiplication tricks\n",
      "shortcut methods for maths\n",
      "maths solving tricks\n",
      "maths simple tricks\n",
      "math short trick in hindi\n",
      "fast calculation tricks\n",
      "short tricks of maths for competitive exam\n",
      "maths shortcut tricks for competitive exam\n",
      "shortcut methods for multiplication\n",
      "shortcut math calculation\n",
      "easy tricks of maths\n",
      "multiplication tricks for large numbers\n",
      "math easy tricks\n",
      "short tricks for maths in hindi\n",
      "maths shortcut methods\n",
      "mental calculation tricks\n",
      "mental calculation\n",
      "math short trick book\n",
      "easy multiplication tricks\n",
      "shortcut tips for maths\n",
      "maths funny tricks\n",
      "easy maths tricks for kids\n",
      "maths calculation shortcuts\n",
      "short cut methods in maths\n",
      "\n",
      "Math Tricks Workout has been meticulously designed not just to share the mathematical tricks but to give you an amazing workout to help you master calculation using the left to right approach. Most of the techniques shared in this app are based on Vedic math tricks that help in mental calculations.\n",
      "\n",
      "This App is designed for those who want to learn mathematical tricks to speed up the calculation.Tricks which are given in Math Tricks app will help to solve mathematical tasks much faster and easily.\n",
      "Description:\n",
      "Learn Spanish, English, German, Portuguese, Korean, French, Hindi, Russian, Turkish, Chinese, Arabic, Italian and Japanese by reading text side by side!\n",
      "\n",
      "Language learning is fun and free with Beelinguapp!\n",
      "\n",
      "Learn a new language with Beelinguapp, the app that lets you read and listen to stories in different languages side by side. Read text and hear audio in the language you are learning, and read the same text in your language to use as a reference.\n",
      "\n",
      "Learn at your own pace with this fun and free language learning app. If you are familiar with language learning audio books, you will love Beelinguapp's innovative method to learn a new language.\n",
      "\n",
      "Ditch the flashcards and pick what languages you want to learn by reading your favorite children's stories, short stories, novels and more side by side. From Spanish to German and more, Beelinguapp teaches you through fun and familiar text.\n",
      "\n",
      "Beelinguapp is fun and easy to use for anyone that wants to learn a new language. Use your native language as a guide and start learning today!\n",
      "\n",
      "Beelinguapp Features:\n",
      "\n",
      "Language Learning Made Easy\n",
      " Learn a new language by reading different stories in a language of your choosing! \n",
      " Beelinguapp gives you the option to read the story in YOUR language to reference what a word or phrase means.\n",
      "\n",
      "Audio Book Reader\n",
      " Spanish, German, French and more languages on easy to listen audio books.\n",
      " Audio book in any language can be listened to even if your phone is sleeping.\n",
      " Learn languages by following the reader of the audio book with a karaoke style animation to know exactly what they are saying.\n",
      " Spanish audio books combined with English, French audio books combined with German  the choice and what language audio book you want to read is yours!\n",
      "\n",
      "Great Stories in Different Languages\n",
      " Side by side readings of your favorite fairy tale stories, novels and more.\n",
      " Learn languages at your own pace and choose only the stories you want to read.\n",
      " Languages, genre and learning level can be sorted make learning languages easy.\n",
      "\n",
      "Learn Different Languages including:\n",
      " English \n",
      " German\n",
      " Spanish\n",
      " Portuguese\n",
      " French\n",
      " Hindi\n",
      " Korean\n",
      " Russian\n",
      " Chinese\n",
      " Arabic\n",
      " Italian\n",
      " Japanese\n",
      " Turkish\n",
      "\n",
      "Learn new languages by reading different stories side by side with Beelinguapp! No memorization and no flashcards needed. Learn languages at your own pace by reading your favorite stories on Beelinguapp!\n",
      "\n",
      "Download Beelinguapp now and start learning languages for free!\n"
     ]
    }
   ],
   "source": [
    "examples = [];\n",
    "files = [ 'MagicSlate.txt', 'MathsTricks.txt' , 'LangAudioBooks.txt'];\n",
    "for file in files: \n",
    "    f = open('examples/'+file,'r')\n",
    "    text = f.read();\n",
    "    print(text);\n",
    "    examples.append(text);\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "stem_lemmatize(examples);\n",
    "tf2 = count_vector.transform(examples).toarray();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 3095)\n"
     ]
    }
   ],
   "source": [
    "print(tf2.shape);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0 0 0 0 1 0 0 0]\n",
      " [0 0 0 0 1 0 0 1 0]\n",
      " [1 0 0 0 0 0 0 0 0]]\n"
     ]
    }
   ],
   "source": [
    "result = best_classifier.predict(tf2).toarray();\n",
    "print(result);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MagicSlate.txt Predicted Categories:Art\n",
      "MathsTricks.txt Predicted Categories:MathsEducational Gaming\n",
      "LangAudioBooks.txt Predicted Categories:Language Learning\n"
     ]
    }
   ],
   "source": [
    "labelsplt = ['Language Learning', 'Computer Engineering' , 'General Learnng' , 'Exam Preparation' , 'Maths' , 'Art', 'other engineering', 'Educational Gaming', 'misc']\n",
    "for i in range(3):\n",
    "    predicted_labels=files[i] + \" Predicted Categories:\";\n",
    "    for x in range(len(labelsplt)):\n",
    "        if result[i][x]==1:\n",
    "            predicted_labels+= labelsplt[x] + \" , \";\n",
    "    print(predicted_labels);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Free Form Visualisation \n",
    "# We will finalise this part after selecting the models that we want to keep!\n",
    "Let us have a plot showing the **hamming-loss** and **log-loss** of different models, which we selected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import matplotlib.cm as cm\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = ['BR-MultNB','BR-GausNB','BR-SVC','CC-MultNB','LP-MultNB','BP-MLL-ini','BP-MLL-fin']\n",
    "y = [3.27,20.74,4.26,3.56,3.17,13.96,15.158]\n",
    "colors = itertools.cycle(['b', 'g', 'r', 'c', 'm', 'y', 'k'])\n",
    "plt.ylabel('Hamming-Loss')\n",
    "plt.xlabel('Model-details')\n",
    "plt.xticks(rotation=90)\n",
    "for i in range(len(y)):\n",
    "    plt.bar(x[i], y[i], color=next(colors))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = ['BR-MultNB','BR-GausNB','BR-SVC','CC-MultNB','LP-MultNB','BP-MLL-ini','BP-MLL-fin']\n",
    "y = [1.92,1.422,0.46,1.5,1.47,0.36,0.35]\n",
    "colors = itertools.cycle(['b', 'g', 'r', 'c', 'm', 'y', 'k'])\n",
    "plt.ylabel('Log-Loss')\n",
    "plt.xlabel('Model-details')\n",
    "plt.xticks(rotation=90)\n",
    "for i in range(len(y)):\n",
    "    plt.bar(x[i], y[i], color=next(colors))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- While showing among the best problem transformation method models, hamming-loss was considered (this is because for BP-MLL neural network we had to round the final results to get the hamming-loss because of the output being multivalued probabilities)\n",
    "- But while chosing among the best Adaptation Algorithm model, log loss was preferred."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
