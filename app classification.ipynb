{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MACHINE LEARNING CAPSTONE PROJECT:  \n",
    "### GOOGLE EDUCATION APP CLASSIFICATION \n",
    "\n",
    "1. Import necessary files <br/>\n",
    "2. Read the csv file <br/>\n",
    "3. List the various fields in our dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(123, 21)\n"
     ]
    }
   ],
   "source": [
    "#Read the csv file into dataframe df\n",
    "df = pd.read_csv(\"train1.csv\")\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "appname                  object\n",
      "updated\\n                object\n",
      "file_size\\n              object\n",
      "download\\n               object\n",
      "version\\n                object\n",
      "compatibility            object\n",
      "price\\n                  object\n",
      "rating_value\\n          float64\n",
      "star_total\\n             object\n",
      "editors_choice\\n         object\n",
      "offered_by\\n             object\n",
      "description\\n            object\n",
      "Language Learning\\n      object\n",
      "Computer Engineering    float64\n",
      "General Learnng\\n       float64\n",
      "Exam Preparation\\n      float64\n",
      "Maths\\n                 float64\n",
      "Art\\n                   float64\n",
      "other engineering\\n     float64\n",
      "Educational Gaming      float64\n",
      "misc\\n                  float64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "#List the fields in our dataframe\n",
    "print(df.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hence we have a sufficiently large dataset consistly of 95851 samples. Each sample contains 8 fields. <br/>\n",
    "**It was observed that running train_test_split on the heavy preprocessed dataframe sometimes resulted in system going out of memory. Hence to avoid such cases, one extra line of code was added. The df.reindex code will shuffle the indices initially, so that later splitting dataset into training and testing will give fairer results.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# below line causes shuffling of indices, to avoid using train_test_split later\n",
    "df = df.reindex(np.random.permutation(df.index))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Separate the comment field data and outcome labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learn on the go with the Coursera App for Android. Access more than 1,000 courses and Specializations developed by 140+ of the best colleges and universities in the world, and advance your career or continue your education by mastering subjects from Python programming and data science to photography and music.\n",
      "Learn from top instructors in an engaging learning experience:\n",
      "• Browse 1000+ courses in a variety of subject areas, from math, to music, to medicine\n",
      "• Stream lecture videos online any time, or download for offline viewing\n",
      "• Transition seamlessly between web and app learning, with coursework, quizzes and projects saved across both platforms\n",
      "• Learn in dozens of languages, including Chinese, Spanish, Portuguese, French, and Russian\n",
      "• Earn Course and Specialization Certificates and share your success with employers, colleagues, and friends\n",
      "Advance your career or continue your education in subjects like:\n",
      "• Computer Science: Programming, Mobile and Web Development\n",
      "• Data Science: Machine Learning, Statistics, Probability and Data\n",
      "• Business: Accounting, Marketing and Entrepreneurship\n",
      "• Sciences: Robotics, Chemistry, Nutrition, and Medicine\n",
      "• Art, including Design, Photography, Music, and Creative Writing\n",
      "...and hundreds more!\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "comment = df['description\\n']\n",
    "print(comment[4])\n",
    "comment = comment.as_matrix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Language Learning\\n  Computer Engineering  General Learnng\\n  \\\n",
      "54                    1                   1.0                0.0   \n",
      "48                    0                   1.0                0.0   \n",
      "101                   0                   0.0                0.0   \n",
      "106                   0                   0.0                0.0   \n",
      "113                   1                   0.0                0.0   \n",
      "\n",
      "     Exam Preparation\\n  Maths\\n  Art\\n  other engineering\\n  \\\n",
      "54                  0.0      0.0    0.0                  0.0   \n",
      "48                  0.0      0.0    0.0                  0.0   \n",
      "101                 0.0      0.0    0.0                  0.0   \n",
      "106                 0.0      0.0    0.0                  0.0   \n",
      "113                 0.0      0.0    0.0                  0.0   \n",
      "\n",
      "     Educational Gaming  misc\\n  \n",
      "54                  0.0     0.0  \n",
      "48                  0.0     0.0  \n",
      "101                 1.0     0.0  \n",
      "106                 1.0     0.0  \n",
      "113                 0.0     0.0  \n"
     ]
    }
   ],
   "source": [
    "label = df[['Language Learning\\n', 'Computer Engineering' , 'General Learnng\\n' , 'Exam Preparation\\n' , 'Maths\\n' , 'Art\\n', 'other engineering\\n', 'Educational Gaming', 'misc\\n']]\n",
    "print(label.head())\n",
    "label = label.as_matrix()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let us find out the frequency of occurence of multilabelled data \n",
    "- ct1 counts samples having atleast one label\n",
    "- ct2 counts samples having 2 or more than 2 labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "123\n",
      "104\n"
     ]
    }
   ],
   "source": [
    "ct1,ct2 = 0,0\n",
    "for i in range(label.shape[0]):\n",
    "    ct = np.count_nonzero(label[i])\n",
    "    if ct :\n",
    "        ct1 = ct1+1\n",
    "    if ct>1 :\n",
    "        ct2 = ct2+1\n",
    "print(ct1)\n",
    "print(ct2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Visualisations\n",
    "### Let us analyse the no. of comments having lengths varying from 0 to 1200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average length of comment: 1409.415\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "x = [len(comment[i]) for i in range(comment.shape[0])]\n",
    "\n",
    "print('average length of comment: {:.3f}'.format(sum(x)/len(x)) )\n",
    "bins = [1,200,400,600,800,1000,1200]\n",
    "plt.hist(x, bins=bins)\n",
    "plt.xlabel('Length of comments')\n",
    "plt.ylabel('Number of comments')       \n",
    "plt.axis([0, 1200, 0, 20])\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Number of comments classified as toxic,severe_toxic,....etc depending on their lengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "y = np.zeros(label.shape)\n",
    "for ix in range(comment.shape[0]):\n",
    "    l = len(comment[ix])\n",
    "    if label[ix][0] :\n",
    "        y[ix][0] = l\n",
    "    if label[ix][1] :\n",
    "        y[ix][1] = l\n",
    "    if label[ix][2] :\n",
    "        y[ix][2] = l\n",
    "    if label[ix][3] :\n",
    "        y[ix][3] = l\n",
    "    if label[ix][4] :\n",
    "        y[ix][4] = l\n",
    "    if label[ix][5] :\n",
    "        y[ix][5] = l\n",
    "\n",
    "labelsplt = ['Language Learning', 'Computer Engineering' , 'General Learnng' , 'Exam Preparation' , 'Maths' , 'Art', 'other engineering', 'Educational Gaming', 'misc']\n",
    "color = ['red','green','blue','yellow','orange','chartreuse','black','magenta','purple']        \n",
    "plt.hist(y,bins = bins,label = labelsplt,color = color)\n",
    "plt.axis([0, 1500, 0, 40])\n",
    "plt.xlabel('Length of comments')\n",
    "plt.ylabel('Number of comments') \n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove excessive length comments\n",
    "Some very large length comments can be seen, in our dataset. These pose serious problems like adding excessively more words to the training dataset, causing training time to increase and accuracy to decrease!<br/>\n",
    "Hence, a threshold of 400 characters will be created and only comments which have length smaller than 400 will be used further."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "comments = []\n",
    "labels = []\n",
    "\n",
    "for ix in range(comment.shape[0]):\n",
    "    if len(comment[ix])<=400:\n",
    "        comments.append(comment[ix])\n",
    "        labels.append(label[ix])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = np.asarray(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n"
     ]
    }
   ],
   "source": [
    "print(len(comments))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hence, after removing comments longer than 400 characters, we are still left with more than 69000 comments, which seems enough for training purposes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing \n",
    "Preprocessing involved the following steps, but these will be performed in a slightly different manner:\n",
    "- Removing Punctuations and other special characters\n",
    "- Splitting the comments into individual words\n",
    "- Removing Stop Words\n",
    "- Stemming and Lemmatising\n",
    "- Applying Count Vectoriser\n",
    "- Splitting dataset into Training and Testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing a string containing all punctuations to be removed\n",
    "The string library contains punctuation characters. This is imported and all numbers are appended to this string. Also, we can notice that our comment_text field contains strings such as won't, didn't, etc which contain apostrophe character('). To prevent these words from being converted to wont/didnt, the character ' represented as \\' in escape sequence notation is replaced by empty character in the punctuation string. <br/>\n",
    "\n",
    "**maketrans()** returns a translation table that maps each character in the punctuation_edit into the character at the same position in the outtab string i.e. it replaces every character in the removal list with a space, since outtab contains a string with spaces."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "!\"#$%&'()*+,-./:;<=>?@[\\]^_`{|}~\n",
      "!\"#$%&()*+,-./:;<=>?@[\\]^_`{|}~0123456789\n"
     ]
    }
   ],
   "source": [
    "import string\n",
    "print(string.punctuation)\n",
    "punctuation_edit = string.punctuation.replace('\\'','') +\"0123456789\"\n",
    "print (punctuation_edit)\n",
    "outtab = \"                                         \"\n",
    "trantab = str.maketrans(punctuation_edit, outtab)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Updating the list of stop words\n",
    "**Stop words** are those words that are frequently used in both written and verbal communication and thereby do not have either a positive/negative impact on our statement.E.g. is, this, us,etc. <br/>\n",
    "Single letter words if existing or created due to any preprocessing step do not convey any useful meaning and hence can be directly removed. Hence letters from b to z, will be added to the list of stop words imported directly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from stop_words import get_stop_words\n",
    "stop_words = get_stop_words('english')\n",
    "stop_words.append('')\n",
    "\n",
    "for x in range(ord('b'), ord('z')+1):\n",
    "    stop_words.append(chr(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['a', 'about', 'above', 'after', 'again', 'against', 'all', 'am', 'an', 'and', 'any', 'are', \"aren't\", 'as', 'at', 'be', 'because', 'been', 'before', 'being', 'below', 'between', 'both', 'but', 'by', \"can't\", 'cannot', 'could', \"couldn't\", 'did', \"didn't\", 'do', 'does', \"doesn't\", 'doing', \"don't\", 'down', 'during', 'each', 'few', 'for', 'from', 'further', 'had', \"hadn't\", 'has', \"hasn't\", 'have', \"haven't\", 'having', 'he', \"he'd\", \"he'll\", \"he's\", 'her', 'here', \"here's\", 'hers', 'herself', 'him', 'himself', 'his', 'how', \"how's\", 'i', \"i'd\", \"i'll\", \"i'm\", \"i've\", 'if', 'in', 'into', 'is', \"isn't\", 'it', \"it's\", 'its', 'itself', \"let's\", 'me', 'more', 'most', \"mustn't\", 'my', 'myself', 'no', 'nor', 'not', 'of', 'off', 'on', 'once', 'only', 'or', 'other', 'ought', 'our', 'ours', 'ourselves', 'out', 'over', 'own', 'same', \"shan't\", 'she', \"she'd\", \"she'll\", \"she's\", 'should', \"shouldn't\", 'so', 'some', 'such', 'than', 'that', \"that's\", 'the', 'their', 'theirs', 'them', 'themselves', 'then', 'there', \"there's\", 'these', 'they', \"they'd\", \"they'll\", \"they're\", \"they've\", 'this', 'those', 'through', 'to', 'too', 'under', 'until', 'up', 'very', 'was', \"wasn't\", 'we', \"we'd\", \"we'll\", \"we're\", \"we've\", 'were', \"weren't\", 'what', \"what's\", 'when', \"when's\", 'where', \"where's\", 'which', 'while', 'who', \"who's\", 'whom', 'why', \"why's\", 'with', \"won't\", 'would', \"wouldn't\", 'you', \"you'd\", \"you'll\", \"you're\", \"you've\", 'your', 'yours', 'yourself', 'yourselves', '', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z']\n"
     ]
    }
   ],
   "source": [
    "print (stop_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stemming and Lemmatizing\n",
    "**Stemming** is the process of converting inflected/derived words to their word stem or the root form. Basically, a large number of similar origin words are converted to the same word.E.g. words like \"stems\", \"stemmer\", \"stemming\", \"stemmed\" as based on \"stem\". This helps in achieving the training process with a better accuracy.<br/>\n",
    "**Lemmatizing** is the process of grouping together the inflected forms of a word so they can be analysed as a single item. This is quite similar to stemming in its working but differs since it depends on correctly identifying the intended part of speech and meaning of a word in a sentence, as well as within the larger context surrounding that sentence, such as neighboring sentences or even an entire document.<br/>\n",
    "The **wordnet library in nltk** will be used for this purpose. Stemmer and Lemmatizer are also imported from nltk.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.stem import PorterStemmer, WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to /Users/paavini/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#create objects for stemmer and lemmatizer\n",
    "lemmatiser = WordNetLemmatizer()\n",
    "stemmer = PorterStemmer()\n",
    "#download words from wordnet library\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We can now, loop once through all the comments applying :\n",
    "- punctuation removal\n",
    "- splitting the words by space\n",
    "- applying stemmer and lemmatizer\n",
    "- recombining the words again for further processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(comments)):\n",
    "    comments[i] = comments[i].lower().translate(trantab)\n",
    "    l = []\n",
    "    for word in comments[i].split():\n",
    "        l.append(stemmer.stem(lemmatiser.lemmatize(word,pos=\"v\")))\n",
    "    comments[i] = \" \".join(l)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Applying Count Vectorizer\n",
    "Here we can finally convert our comments into a matrix of token counts, which signifies the number of times it occurs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import required library\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "#create object supplying our custom stop words\n",
    "count_vector = CountVectorizer(stop_words=stop_words)\n",
    "#fitting it to converts comments into bag of words format\n",
    "tf = count_vector.fit_transform(comments).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6, 138)\n"
     ]
    }
   ],
   "source": [
    "# print(count_vector.get_feature_names())\n",
    "print(tf.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hence from its shape we can imply that after all preprocessing we have a list of 52905 words in total.\n",
    "## Splitting dataset into training and testing\n",
    "- Since the system was going out of memory using train_test_split, I had jumbled all the indexes in the beginning itself. \n",
    "- The shuffle function defined here performs the task of assigning first 2/3rd values to train and remaining 1/3rd values to the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 138)\n",
      "(4, 138)\n"
     ]
    }
   ],
   "source": [
    "def shuffle(matrix, target, test_proportion):\n",
    "    ratio = int(matrix.shape[0]/test_proportion)\n",
    "    X_train = matrix[ratio:,:]\n",
    "    X_test =  matrix[:ratio,:]\n",
    "    Y_train = target[ratio:,:]\n",
    "    Y_test =  target[:ratio,:]\n",
    "    return X_train, X_test, Y_train, Y_test\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = shuffle(tf, labels,3)\n",
    "\n",
    "print(X_test.shape)\n",
    "print(X_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementation :\n",
    "### Let us define all the evaluation metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import hamming_loss\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import log_loss\n",
    "\n",
    "def evaluate_score(Y_test,predict): \n",
    "    loss = hamming_loss(Y_test,predict)\n",
    "    print(\"Hamming_loss : {}\".format(loss*100))\n",
    "    accuracy = accuracy_score(Y_test,predict)\n",
    "    print(\"Accuracy : {}\".format(accuracy*100))\n",
    "    try : \n",
    "        loss = log_loss(Y_test,predict)\n",
    "    except :\n",
    "        loss = log_loss(Y_test,predict.toarray())\n",
    "    print(\"Log_loss : {}\".format(loss))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Starting with the First Model -\n",
    "### Problem Transformation Methods :\n",
    "**These include the Binary Relevance, Label Powerset and Classifier Chain methods. Implementations of these methods is available in the scikit-multilearn library. **\n",
    "- I will be implementing the most basic method,which is the **Binary Relevance** method from scratch. It does not take into account the interdependence of labels and basically creates a separate classifier for each of the labels.\n",
    "- Scikit-multilearn library's classifier will also be imported and tested with different classifiers to observe if it gives similar results.\n",
    "\n",
    "### 1. Binary Relevance (BR) Method with MultinomialNB classifiers (from scratch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/Cellar/python3/3.6.3/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/sklearn/naive_bayes.py:461: RuntimeWarning: divide by zero encountered in log\n",
      "  self.class_log_prior_ = (np.log(self.class_count_) -\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Unknown label type: (array([0.0, 1.0, 0.0, 0.0], dtype=object),)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-26-d37d2f737e55>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mix\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m6\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mMultinomialNB\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mclf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mix\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mY_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mix\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/Cellar/python3/3.6.3/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/sklearn/naive_bayes.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    581\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    582\u001b[0m         \u001b[0mlabelbin\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLabelBinarizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 583\u001b[0;31m         \u001b[0mY\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlabelbin\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    584\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclasses_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlabelbin\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclasses_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    585\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/Cellar/python3/3.6.3/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/sklearn/preprocessing/label.py\u001b[0m in \u001b[0;36mfit_transform\u001b[0;34m(self, y)\u001b[0m\n\u001b[1;32m    305\u001b[0m             \u001b[0mShape\u001b[0m \u001b[0mwill\u001b[0m \u001b[0mbe\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mn_samples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mbinary\u001b[0m \u001b[0mproblems\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    306\u001b[0m         \"\"\"\n\u001b[0;32m--> 307\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    308\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    309\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/Cellar/python3/3.6.3/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/sklearn/preprocessing/label.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, y)\u001b[0m\n\u001b[1;32m    282\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    283\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msparse_input_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0missparse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 284\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclasses_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0munique_labels\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    285\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    286\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/Cellar/python3/3.6.3/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/sklearn/utils/multiclass.py\u001b[0m in \u001b[0;36munique_labels\u001b[0;34m(*ys)\u001b[0m\n\u001b[1;32m     95\u001b[0m     \u001b[0m_unique_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_FN_UNIQUE_LABELS\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0m_unique_labels\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 97\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Unknown label type: %s\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mrepr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mys\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     98\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m     \u001b[0mys_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_iterable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_unique_labels\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0my\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mys\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Unknown label type: (array([0.0, 1.0, 0.0, 0.0], dtype=object),)"
     ]
    }
   ],
   "source": [
    "# clf will be the list of the classifiers for all the 6 labels\n",
    "# each classifier is fit with the training data and corresponding classifier\n",
    "clf = []\n",
    "for ix in range(6):\n",
    "    clf.append(MultinomialNB())\n",
    "    clf[ix].fit(X_train,Y_train[:,ix])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(23209, 6)\n"
     ]
    }
   ],
   "source": [
    "# predict list contains the predictions, it is transposed later to get the proper shape\n",
    "predict = []\n",
    "for ix in range(6):\n",
    "    predict.append(clf[ix].predict(X_test))\n",
    "\n",
    "predict = np.asarray(np.transpose(predict))\n",
    "print(predict.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hamming_loss : 3.2796185387852415\n",
      "Accuracy : 88.29764315567236\n",
      "Log_loss : 1.9296193554647956\n"
     ]
    }
   ],
   "source": [
    "# calculate results\n",
    "evaluate_score(Y_test,predict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. BR Method with SVM classifier (from scikit-multilearn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BinaryRelevance(classifier=SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='rbf',\n",
       "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=False),\n",
       "        require_dense=[False, True])"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#create and fit classifier\n",
    "from skmultilearn.problem_transform import BinaryRelevance\n",
    "from sklearn.svm import SVC\n",
    "classifier = BinaryRelevance(classifier = SVC(), require_dense = [False, True])\n",
    "classifier.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#predictions\n",
    "predictions = classifier.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hamming_loss : 4.26702285033105\n",
      "Accuracy : 88.276099788875\n",
      "Log_loss : 0.4616701016298293\n"
     ]
    }
   ],
   "source": [
    "#calculate scores\n",
    "evaluate_score(Y_test,predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. BR Method with Multinomial classifier (from scikit-multilearn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BinaryRelevance(classifier=MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True),\n",
       "        require_dense=[False, True])"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#create and fit classifier\n",
    "classifier = BinaryRelevance(classifier = MultinomialNB(), require_dense = [False, True])\n",
    "classifier.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#predictions\n",
    "predictions = classifier.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hamming_loss : 3.2796185387852415\n",
      "Accuracy : 88.29764315567236\n",
      "Log_loss : 1.9296193554647956\n"
     ]
    }
   ],
   "source": [
    "#calculate scores\n",
    "evaluate_score(Y_test,predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. BR Method with GausseanNB classifier (from scratch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "#create and fit classifiers\n",
    "clf = []\n",
    "for ix in range(6):\n",
    "    clf.append(GaussianNB())\n",
    "    clf[ix].fit(X_train,Y_train[:,ix])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#predictions\n",
    "predict = []\n",
    "for ix in range(6):\n",
    "    predict.append(clf[ix].predict(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hamming_loss : 20.746262225860658\n",
      "Accuracy : 52.199577750010775\n",
      "Log_loss : 1.4227365989183884\n"
     ]
    }
   ],
   "source": [
    "#calculate scores\n",
    "predict = np.asarray(np.transpose(predict))\n",
    "evaluate_score(Y_test,predict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Classifier chain with MultinomialNB classifier (from scikit-multilearn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ClassifierChain(classifier=MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True),\n",
       "        require_dense=[True, True])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#create and fit classifier\n",
    "from skmultilearn.problem_transform import ClassifierChain\n",
    "classifier = ClassifierChain(MultinomialNB())\n",
    "classifier.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#predictions\n",
    "predictions = classifier.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hamming_loss : 3.5647090927370133\n",
      "Accuracy : 88.25886509543712\n",
      "Log_loss : 1.506849253150214\n"
     ]
    }
   ],
   "source": [
    "#calculate scores\n",
    "evaluate_score(Y_test,predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Label Powerset with MultinomialNB classifier (from scikit-multilearn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LabelPowerset(classifier=MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True),\n",
       "       require_dense=[True, True])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#create and fit classifier\n",
    "from skmultilearn.problem_transform import LabelPowerset\n",
    "classifier = LabelPowerset(MultinomialNB())\n",
    "classifier.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#predictions\n",
    "predictions = classifier.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hamming_loss : 3.1726198170250046\n",
      "Accuracy : 88.80606661209013\n",
      "Log_loss : 1.4765486777963348\n"
     ]
    }
   ],
   "source": [
    "#calculate scores\n",
    "evaluate_score(Y_test,predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adaptation Algorithms\n",
    "### 7. MLkNN  with k=2 (from scikit-multilearn)\n",
    "This is the adapted multi-label version of K Nearest Neighbours. Its implementation is available in the multilearn library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#create and fit classifier\n",
    "from skmultilearn.adapt import MLkNN\n",
    "classifier = MLkNN(k=2)\n",
    "classifier.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#predictions\n",
    "predictions = classifier.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#calculate scores\n",
    "evaluate_score(Y_test,predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8. BP-MLL Neural Networks (from scratch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 4)                 211956    \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 4)                 0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 6)                 30        \n",
      "=================================================================\n",
      "Total params: 211,986\n",
      "Trainable params: 211,986\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#define model architecture\n",
    "model = Sequential()\n",
    "model.add(Dense(4, activation='relu', input_dim = X_train.shape[1]))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Dense(6, activation='softmax'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#compile model with all parameters set\n",
    "model.compile(optimizer='rmsprop',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "46418/46418 [==============================] - 60s 1ms/step - loss: 0.3684 - acc: 0.9419\n",
      "Epoch 2/10\n",
      "46418/46418 [==============================] - 60s 1ms/step - loss: 0.3489 - acc: 0.9901\n",
      "Epoch 3/10\n",
      "46418/46418 [==============================] - 62s 1ms/step - loss: 0.3449 - acc: 0.9906\n",
      "Epoch 4/10\n",
      "46418/46418 [==============================] - 59s 1ms/step - loss: 0.3425 - acc: 0.9888: 0s - loss: 0.3424 - acc: 0.98\n",
      "Epoch 5/10\n",
      "46418/46418 [==============================] - 59s 1ms/step - loss: 0.3424 - acc: 0.9876\n",
      "Epoch 6/10\n",
      "46418/46418 [==============================] - 58s 1ms/step - loss: 0.3424 - acc: 0.9879\n",
      "Epoch 7/10\n",
      "46418/46418 [==============================] - 57s 1ms/step - loss: 0.3414 - acc: 0.9868\n",
      "Epoch 8/10\n",
      "46418/46418 [==============================] - 60s 1ms/step - loss: 0.3404 - acc: 0.9851\n",
      "Epoch 9/10\n",
      "46418/46418 [==============================] - 61s 1ms/step - loss: 0.3402 - acc: 0.9846\n",
      "Epoch 10/10\n",
      "46418/46418 [==============================] - 61s 1ms/step - loss: 0.3395 - acc: 0.9825\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x210b649470>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Fit using check pointer\n",
    "from keras.callbacks import ModelCheckpoint  \n",
    "\n",
    "checkpointer = ModelCheckpoint(filepath='saved_models/weights.best.myneural.h5py', \n",
    "                               verbose=1, save_best_only=True)\n",
    "model.fit(X_train, Y_train, epochs=10, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#predictions\n",
    "predict = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  6.69890046e-01   9.70017936e-05   1.44642159e-01   1.16227047e-05\n",
      "   1.78119496e-01   7.23966770e-03]\n"
     ]
    }
   ],
   "source": [
    "print(predict[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Since the results returned by the model are in the form of probabilities, they have to be explicitly converted to either 0/1 using the round function. This is because the hamming_loss and accuracy_score cannot work on these values directly. However, log loss can compute loss directly without modifying the values.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Log_loss : 0.36017768848519677\n",
      "Hamming_loss : 13.960101684691285\n",
      "Accuracy : 29.52302985910638\n"
     ]
    }
   ],
   "source": [
    "#calculate score\n",
    "loss = log_loss(Y_test,predict)\n",
    "print(\"Log_loss : {}\".format(loss))\n",
    "predict = np.round(predict)\n",
    "loss = hamming_loss(Y_test,predict)\n",
    "print(\"Hamming_loss : {}\".format(loss*100))\n",
    "accuracy = accuracy_score(Y_test,predict)\n",
    "print(\"Accuracy : {}\".format(accuracy*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Let us try improving the BP-MLL model (Refining)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Dropout\n",
    "from keras import optimizers\n",
    "\n",
    "#define parameters for using in param grid\n",
    "nodes = [16, 32, 64] # number of nodes in the hidden layer\n",
    "lrs = [0.001, 0.002, 0.003] # learning rate, default = 0.001\n",
    "epochs = [10,20,30]\n",
    "batch_size = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_model(nodes=10,lr=0.001):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(nodes, activation='relu', input_dim = X_train.shape[1]))\n",
    "    model.add(Dropout(0.3))\n",
    "    model.add(Dense(6, activation='softmax'))\n",
    "    opt = optimizers.RMSprop(lr=lr)\n",
    "    model.compile(optimizer=opt,\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "model = KerasClassifier(build_fn=create_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 27 candidates, totalling 81 fits\n",
      "[CV] epochs=10, lr=0.001, nodes=16 ...................................\n",
      "Epoch 1/10\n",
      "30945/30945 [==============================] - 39s 1ms/step - loss: 0.3682 - acc: 0.9536\n",
      "Epoch 2/10\n",
      "30945/30945 [==============================] - 27s 878us/step - loss: 0.3440 - acc: 0.9794\n",
      "Epoch 3/10\n",
      "30945/30945 [==============================] - 25s 820us/step - loss: 0.3379 - acc: 0.9786\n",
      "Epoch 4/10\n",
      "30945/30945 [==============================] - 26s 837us/step - loss: 0.3324 - acc: 0.9745\n",
      "Epoch 5/10\n",
      "30945/30945 [==============================] - 26s 832us/step - loss: 0.3280 - acc: 0.9718\n",
      "Epoch 6/10\n",
      "30945/30945 [==============================] - 26s 842us/step - loss: 0.3249 - acc: 0.9688\n",
      "Epoch 7/10\n",
      "30945/30945 [==============================] - 27s 878us/step - loss: 0.3227 - acc: 0.9654\n",
      "Epoch 8/10\n",
      "30945/30945 [==============================] - 26s 838us/step - loss: 0.3202 - acc: 0.9647\n",
      "Epoch 9/10\n",
      "30945/30945 [==============================] - 26s 843us/step - loss: 0.3190 - acc: 0.9596\n",
      "Epoch 10/10\n",
      "30945/30945 [==============================] - 27s 858us/step - loss: 0.3157 - acc: 0.9602\n",
      "15473/15473 [==============================] - 14s 882us/step\n",
      "30945/30945 [==============================] - 25s 812us/step\n",
      "[CV] .................... epochs=10, lr=0.001, nodes=16, total= 5.5min\n",
      "[CV] epochs=10, lr=0.001, nodes=16 ...................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:  5.9min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "30945/30945 [==============================] - 33s 1ms/step - loss: 0.3783 - acc: 0.9584\n",
      "Epoch 2/10\n",
      "30945/30945 [==============================] - 22s 715us/step - loss: 0.3515 - acc: 0.9802\n",
      "Epoch 3/10\n",
      "30945/30945 [==============================] - 22s 706us/step - loss: 0.3447 - acc: 0.9793\n",
      "Epoch 4/10\n",
      "30945/30945 [==============================] - 23s 731us/step - loss: 0.3407 - acc: 0.9788\n",
      "Epoch 5/10\n",
      "30945/30945 [==============================] - 23s 733us/step - loss: 0.3373 - acc: 0.9770\n",
      "Epoch 6/10\n",
      "30945/30945 [==============================] - 22s 726us/step - loss: 0.3342 - acc: 0.9748\n",
      "Epoch 7/10\n",
      "30945/30945 [==============================] - 22s 713us/step - loss: 0.3312 - acc: 0.9697\n",
      "Epoch 8/10\n",
      "30945/30945 [==============================] - 22s 695us/step - loss: 0.3303 - acc: 0.9648\n",
      "Epoch 9/10\n",
      "30945/30945 [==============================] - 22s 702us/step - loss: 0.3280 - acc: 0.9621\n",
      "Epoch 10/10\n",
      "30945/30945 [==============================] - 22s 712us/step - loss: 0.3268 - acc: 0.9588\n",
      "15473/15473 [==============================] - 11s 720us/step\n",
      "30945/30945 [==============================] - 20s 657us/step\n",
      "[CV] .................... epochs=10, lr=0.001, nodes=16, total= 4.6min\n",
      "[CV] epochs=10, lr=0.001, nodes=16 ...................................\n",
      "Epoch 1/10\n",
      "30946/30946 [==============================] - 35s 1ms/step - loss: 0.3705 - acc: 0.8698\n",
      "Epoch 2/10\n",
      "30946/30946 [==============================] - 22s 718us/step - loss: 0.3464 - acc: 0.9863\n",
      "Epoch 3/10\n",
      "30946/30946 [==============================] - 22s 703us/step - loss: 0.3407 - acc: 0.9855\n",
      "Epoch 4/10\n",
      "30946/30946 [==============================] - 22s 707us/step - loss: 0.3358 - acc: 0.9822\n",
      "Epoch 5/10\n",
      "30946/30946 [==============================] - 21s 680us/step - loss: 0.3315 - acc: 0.9808\n",
      "Epoch 6/10\n",
      "30946/30946 [==============================] - 21s 684us/step - loss: 0.3276 - acc: 0.9772\n",
      "Epoch 7/10\n",
      "30946/30946 [==============================] - 21s 678us/step - loss: 0.3268 - acc: 0.9731\n",
      "Epoch 8/10\n",
      "30946/30946 [==============================] - 23s 742us/step - loss: 0.3239 - acc: 0.9692\n",
      "Epoch 9/10\n",
      "30946/30946 [==============================] - 22s 720us/step - loss: 0.3239 - acc: 0.9666\n",
      "Epoch 10/10\n",
      "30946/30946 [==============================] - 23s 735us/step - loss: 0.3200 - acc: 0.9641\n",
      "15472/15472 [==============================] - 11s 726us/step\n",
      "30946/30946 [==============================] - 20s 648us/step\n",
      "[CV] .................... epochs=10, lr=0.001, nodes=16, total= 4.6min\n",
      "[CV] epochs=10, lr=0.001, nodes=32 ...................................\n",
      "Epoch 1/10\n",
      "30945/30945 [==============================] - 50s 2ms/step - loss: 0.3620 - acc: 0.9808\n",
      "Epoch 2/10\n",
      "30945/30945 [==============================] - 38s 1ms/step - loss: 0.3390 - acc: 0.9796\n",
      "Epoch 3/10\n",
      "30945/30945 [==============================] - 36s 1ms/step - loss: 0.3307 - acc: 0.9748\n",
      "Epoch 4/10\n",
      "30945/30945 [==============================] - 35s 1ms/step - loss: 0.3259 - acc: 0.9741\n",
      "Epoch 5/10\n",
      "30945/30945 [==============================] - 37s 1ms/step - loss: 0.3214 - acc: 0.9715\n",
      "Epoch 6/10\n",
      "30945/30945 [==============================] - 36s 1ms/step - loss: 0.3169 - acc: 0.9686\n",
      "Epoch 7/10\n",
      "30945/30945 [==============================] - 35s 1ms/step - loss: 0.3139 - acc: 0.9637\n",
      "Epoch 8/10\n",
      "30945/30945 [==============================] - 37s 1ms/step - loss: 0.3112 - acc: 0.9610\n",
      "Epoch 9/10\n",
      "30945/30945 [==============================] - 37s 1ms/step - loss: 0.3077 - acc: 0.9581\n",
      "Epoch 10/10\n",
      "30945/30945 [==============================] - 37s 1ms/step - loss: 0.3059 - acc: 0.9556\n",
      "15473/15473 [==============================] - 14s 918us/step\n",
      "30945/30945 [==============================] - 26s 836us/step\n",
      "[CV] .................... epochs=10, lr=0.001, nodes=32, total= 7.1min\n",
      "[CV] epochs=10, lr=0.001, nodes=32 ...................................\n",
      "Epoch 1/10\n",
      "30945/30945 [==============================] - 48s 2ms/step - loss: 0.3743 - acc: 0.9775\n",
      "Epoch 2/10\n",
      "30945/30945 [==============================] - 37s 1ms/step - loss: 0.3518 - acc: 0.9829\n",
      "Epoch 3/10\n",
      "30945/30945 [==============================] - 36s 1ms/step - loss: 0.3443 - acc: 0.9796\n",
      "Epoch 4/10\n",
      "30945/30945 [==============================] - 37s 1ms/step - loss: 0.3386 - acc: 0.9766\n",
      "Epoch 5/10\n",
      "30945/30945 [==============================] - 37s 1ms/step - loss: 0.3343 - acc: 0.9740\n",
      "Epoch 6/10\n",
      "30945/30945 [==============================] - 37s 1ms/step - loss: 0.3309 - acc: 0.9720\n",
      "Epoch 7/10\n",
      "30945/30945 [==============================] - 37s 1ms/step - loss: 0.3280 - acc: 0.9694\n",
      "Epoch 8/10\n",
      "30945/30945 [==============================] - 37s 1ms/step - loss: 0.3261 - acc: 0.9677\n",
      "Epoch 9/10\n",
      "30945/30945 [==============================] - 37s 1ms/step - loss: 0.3237 - acc: 0.9626\n",
      "Epoch 10/10\n",
      "30945/30945 [==============================] - 37s 1ms/step - loss: 0.3212 - acc: 0.9587\n",
      "15473/15473 [==============================] - 14s 932us/step\n",
      "30945/30945 [==============================] - 27s 861us/step\n",
      "[CV] .................... epochs=10, lr=0.001, nodes=32, total= 7.2min\n",
      "[CV] epochs=10, lr=0.001, nodes=32 ...................................\n",
      "Epoch 1/10\n",
      "30946/30946 [==============================] - 44s 1ms/step - loss: 0.3608 - acc: 0.9766\n",
      "Epoch 2/10\n",
      "30946/30946 [==============================] - 36s 1ms/step - loss: 0.3390 - acc: 0.9807\n",
      "Epoch 3/10\n",
      "30946/30946 [==============================] - 35s 1ms/step - loss: 0.3311 - acc: 0.9780\n",
      "Epoch 4/10\n",
      "30946/30946 [==============================] - 34s 1ms/step - loss: 0.3269 - acc: 0.9726\n",
      "Epoch 5/10\n",
      "30946/30946 [==============================] - 38s 1ms/step - loss: 0.3224 - acc: 0.9702\n",
      "Epoch 6/10\n",
      "30946/30946 [==============================] - 38s 1ms/step - loss: 0.3198 - acc: 0.9676\n",
      "Epoch 7/10\n",
      "30946/30946 [==============================] - 38s 1ms/step - loss: 0.3156 - acc: 0.9659\n",
      "Epoch 8/10\n",
      "30946/30946 [==============================] - 38s 1ms/step - loss: 0.3120 - acc: 0.9646\n",
      "Epoch 9/10\n",
      "30946/30946 [==============================] - 38s 1ms/step - loss: 0.3094 - acc: 0.9592\n",
      "Epoch 10/10\n",
      "30946/30946 [==============================] - 38s 1ms/step - loss: 0.3088 - acc: 0.9571\n",
      "15472/15472 [==============================] - 14s 935us/step\n",
      "30946/30946 [==============================] - 26s 855us/step\n",
      "[CV] .................... epochs=10, lr=0.001, nodes=32, total= 7.1min\n",
      "[CV] epochs=10, lr=0.001, nodes=64 ...................................\n",
      "Epoch 1/10\n",
      "30945/30945 [==============================] - 73s 2ms/step - loss: 0.3561 - acc: 0.9807\n",
      "Epoch 2/10\n",
      "30945/30945 [==============================] - 61s 2ms/step - loss: 0.3341 - acc: 0.9778\n",
      "Epoch 3/10\n",
      "30945/30945 [==============================] - 61s 2ms/step - loss: 0.3249 - acc: 0.9749\n",
      "Epoch 4/10\n",
      "30945/30945 [==============================] - 61s 2ms/step - loss: 0.3188 - acc: 0.9719\n",
      "Epoch 5/10\n",
      "30945/30945 [==============================] - 59s 2ms/step - loss: 0.3143 - acc: 0.9656\n",
      "Epoch 6/10\n",
      "30945/30945 [==============================] - 57s 2ms/step - loss: 0.3086 - acc: 0.9597\n",
      "Epoch 7/10\n",
      "30945/30945 [==============================] - 56s 2ms/step - loss: 0.3055 - acc: 0.9588\n",
      "Epoch 8/10\n",
      "30945/30945 [==============================] - 56s 2ms/step - loss: 0.3015 - acc: 0.9559\n",
      "Epoch 9/10\n",
      "30945/30945 [==============================] - 55s 2ms/step - loss: 0.2992 - acc: 0.9491\n",
      "Epoch 10/10\n",
      "30945/30945 [==============================] - 56s 2ms/step - loss: 0.2956 - acc: 0.9456\n",
      "15473/15473 [==============================] - 14s 906us/step\n",
      "30945/30945 [==============================] - 24s 769us/step\n",
      "[CV] .................... epochs=10, lr=0.001, nodes=64, total=10.7min\n",
      "[CV] epochs=10, lr=0.001, nodes=64 ...................................\n",
      "Epoch 1/10\n",
      "30945/30945 [==============================] - 63s 2ms/step - loss: 0.3643 - acc: 0.9838\n",
      "Epoch 2/10\n",
      "30945/30945 [==============================] - 53s 2ms/step - loss: 0.3427 - acc: 0.9774\n",
      "Epoch 3/10\n",
      "30945/30945 [==============================] - 53s 2ms/step - loss: 0.3337 - acc: 0.9737\n",
      "Epoch 4/10\n",
      "30945/30945 [==============================] - 53s 2ms/step - loss: 0.3264 - acc: 0.9703\n",
      "Epoch 5/10\n",
      "30945/30945 [==============================] - 53s 2ms/step - loss: 0.3204 - acc: 0.9655\n",
      "Epoch 6/10\n",
      "30945/30945 [==============================] - 53s 2ms/step - loss: 0.3175 - acc: 0.9599\n",
      "Epoch 7/10\n",
      "30945/30945 [==============================] - 52s 2ms/step - loss: 0.3131 - acc: 0.9585\n",
      "Epoch 8/10\n",
      "30945/30945 [==============================] - 52s 2ms/step - loss: 0.3099 - acc: 0.9515\n",
      "Epoch 9/10\n",
      "30945/30945 [==============================] - 53s 2ms/step - loss: 0.3073 - acc: 0.9495\n",
      "Epoch 10/10\n",
      "30945/30945 [==============================] - 54s 2ms/step - loss: 0.3056 - acc: 0.9434\n",
      "15473/15473 [==============================] - 13s 853us/step\n",
      "30945/30945 [==============================] - 24s 776us/step\n",
      "[CV] .................... epochs=10, lr=0.001, nodes=64, total= 9.8min\n",
      "[CV] epochs=10, lr=0.001, nodes=64 ...................................\n",
      "Epoch 1/10\n",
      "30946/30946 [==============================] - 62s 2ms/step - loss: 0.3546 - acc: 0.9802\n",
      "Epoch 2/10\n",
      "30946/30946 [==============================] - 53s 2ms/step - loss: 0.3317 - acc: 0.9786\n",
      "Epoch 3/10\n",
      "30946/30946 [==============================] - 52s 2ms/step - loss: 0.3230 - acc: 0.9737\n",
      "Epoch 4/10\n",
      "30946/30946 [==============================] - 53s 2ms/step - loss: 0.3166 - acc: 0.9714\n",
      "Epoch 5/10\n",
      "30946/30946 [==============================] - 54s 2ms/step - loss: 0.3120 - acc: 0.9684\n",
      "Epoch 6/10\n",
      "30946/30946 [==============================] - 54s 2ms/step - loss: 0.3084 - acc: 0.9609\n",
      "Epoch 7/10\n",
      "30946/30946 [==============================] - 53s 2ms/step - loss: 0.3045 - acc: 0.9566\n",
      "Epoch 8/10\n",
      "30946/30946 [==============================] - 53s 2ms/step - loss: 0.3018 - acc: 0.9511\n",
      "Epoch 9/10\n",
      "30946/30946 [==============================] - 54s 2ms/step - loss: 0.2986 - acc: 0.9489\n",
      "Epoch 10/10\n",
      "30946/30946 [==============================] - 50s 2ms/step - loss: 0.2965 - acc: 0.9439\n",
      "15472/15472 [==============================] - 13s 848us/step\n",
      "30946/30946 [==============================] - 26s 830us/step\n",
      "[CV] .................... epochs=10, lr=0.001, nodes=64, total= 9.8min\n",
      "[CV] epochs=10, lr=0.002, nodes=16 ...................................\n",
      "Epoch 1/10\n",
      "30945/30945 [==============================] - 34s 1ms/step - loss: 0.3601 - acc: 0.9709\n",
      "Epoch 2/10\n",
      "30945/30945 [==============================] - 23s 742us/step - loss: 0.3402 - acc: 0.9831\n",
      "Epoch 3/10\n",
      "30945/30945 [==============================] - 23s 738us/step - loss: 0.3344 - acc: 0.9774\n",
      "Epoch 4/10\n",
      "30945/30945 [==============================] - 23s 745us/step - loss: 0.3306 - acc: 0.9756\n",
      "Epoch 5/10\n",
      "30945/30945 [==============================] - 23s 735us/step - loss: 0.3290 - acc: 0.9693\n",
      "Epoch 6/10\n",
      "30945/30945 [==============================] - 23s 731us/step - loss: 0.3258 - acc: 0.9688\n",
      "Epoch 7/10\n",
      "30945/30945 [==============================] - 22s 726us/step - loss: 0.3224 - acc: 0.9659\n",
      "Epoch 8/10\n",
      "30945/30945 [==============================] - 23s 731us/step - loss: 0.3201 - acc: 0.9626\n",
      "Epoch 9/10\n",
      "30945/30945 [==============================] - 22s 711us/step - loss: 0.3189 - acc: 0.9584\n",
      "Epoch 10/10\n",
      "30945/30945 [==============================] - 23s 738us/step - loss: 0.3169 - acc: 0.9568\n",
      "15473/15473 [==============================] - 12s 798us/step\n",
      "30945/30945 [==============================] - 22s 714us/step\n",
      "[CV] .................... epochs=10, lr=0.002, nodes=16, total= 4.7min\n",
      "[CV] epochs=10, lr=0.002, nodes=16 ...................................\n",
      "Epoch 1/10\n",
      "30945/30945 [==============================] - 34s 1ms/step - loss: 0.3694 - acc: 0.9723\n",
      "Epoch 2/10\n",
      "30945/30945 [==============================] - 22s 716us/step - loss: 0.3500 - acc: 0.9833\n",
      "Epoch 3/10\n",
      "30945/30945 [==============================] - 22s 712us/step - loss: 0.3439 - acc: 0.9797\n",
      "Epoch 4/10\n",
      "30945/30945 [==============================] - 22s 710us/step - loss: 0.3407 - acc: 0.9738\n",
      "Epoch 5/10\n",
      "30945/30945 [==============================] - 22s 710us/step - loss: 0.3354 - acc: 0.9691\n",
      "Epoch 6/10\n",
      "30945/30945 [==============================] - 22s 712us/step - loss: 0.3329 - acc: 0.9694\n",
      "Epoch 7/10\n",
      "30945/30945 [==============================] - 22s 712us/step - loss: 0.3292 - acc: 0.9608\n",
      "Epoch 8/10\n",
      "30945/30945 [==============================] - 22s 717us/step - loss: 0.3286 - acc: 0.9598\n",
      "Epoch 9/10\n",
      "30945/30945 [==============================] - 22s 716us/step - loss: 0.3275 - acc: 0.9554\n",
      "Epoch 10/10\n",
      "30945/30945 [==============================] - 22s 723us/step - loss: 0.3248 - acc: 0.9513\n",
      "15473/15473 [==============================] - 12s 796us/step\n",
      "30945/30945 [==============================] - 22s 721us/step\n",
      "[CV] .................... epochs=10, lr=0.002, nodes=16, total= 4.6min\n",
      "[CV] epochs=10, lr=0.002, nodes=16 ...................................\n",
      "Epoch 1/10\n",
      "30946/30946 [==============================] - 35s 1ms/step - loss: 0.3582 - acc: 0.9780\n",
      "Epoch 2/10\n",
      "30946/30946 [==============================] - 23s 739us/step - loss: 0.3391 - acc: 0.9829\n",
      "Epoch 3/10\n",
      "30946/30946 [==============================] - 22s 723us/step - loss: 0.3343 - acc: 0.9771\n",
      "Epoch 4/10\n",
      "30946/30946 [==============================] - 22s 720us/step - loss: 0.3311 - acc: 0.9725\n",
      "Epoch 5/10\n",
      "30946/30946 [==============================] - 22s 718us/step - loss: 0.3278 - acc: 0.9690\n",
      "Epoch 6/10\n",
      "30946/30946 [==============================] - 22s 719us/step - loss: 0.3245 - acc: 0.9660\n",
      "Epoch 7/10\n",
      "30946/30946 [==============================] - 22s 720us/step - loss: 0.3220 - acc: 0.9642\n",
      "Epoch 8/10\n",
      "30946/30946 [==============================] - 22s 722us/step - loss: 0.3193 - acc: 0.9606\n",
      "Epoch 9/10\n",
      "30946/30946 [==============================] - 22s 712us/step - loss: 0.3176 - acc: 0.9598\n",
      "Epoch 10/10\n",
      "30946/30946 [==============================] - 22s 722us/step - loss: 0.3147 - acc: 0.9576\n",
      "15472/15472 [==============================] - 12s 793us/step\n",
      "30946/30946 [==============================] - 22s 723us/step\n",
      "[CV] .................... epochs=10, lr=0.002, nodes=16, total= 4.7min\n",
      "[CV] epochs=10, lr=0.002, nodes=32 ...................................\n",
      "Epoch 1/10\n",
      "30945/30945 [==============================] - 48s 2ms/step - loss: 0.3539 - acc: 0.9795\n",
      "Epoch 2/10\n",
      "30945/30945 [==============================] - 36s 1ms/step - loss: 0.3353 - acc: 0.9778\n",
      "Epoch 3/10\n",
      "30945/30945 [==============================] - 37s 1ms/step - loss: 0.3276 - acc: 0.9752\n",
      "Epoch 4/10\n",
      "30945/30945 [==============================] - 37s 1ms/step - loss: 0.3207 - acc: 0.9723\n",
      "Epoch 5/10\n",
      "30945/30945 [==============================] - 38s 1ms/step - loss: 0.3176 - acc: 0.9687\n",
      "Epoch 6/10\n",
      "30945/30945 [==============================] - 37s 1ms/step - loss: 0.3130 - acc: 0.9643\n",
      "Epoch 7/10\n",
      "30945/30945 [==============================] - 37s 1ms/step - loss: 0.3112 - acc: 0.9614\n",
      "Epoch 8/10\n",
      "30945/30945 [==============================] - 38s 1ms/step - loss: 0.3082 - acc: 0.9553\n",
      "Epoch 9/10\n",
      "30945/30945 [==============================] - 37s 1ms/step - loss: 0.3045 - acc: 0.9519\n",
      "Epoch 10/10\n",
      "30945/30945 [==============================] - 37s 1ms/step - loss: 0.3018 - acc: 0.9487\n",
      "15473/15473 [==============================] - 12s 800us/step\n",
      "30945/30945 [==============================] - 22s 713us/step\n",
      "[CV] .................... epochs=10, lr=0.002, nodes=32, total= 7.1min\n",
      "[CV] epochs=10, lr=0.002, nodes=32 ...................................\n",
      "Epoch 1/10\n",
      "30945/30945 [==============================] - 46s 1ms/step - loss: 0.3632 - acc: 0.9803\n",
      "Epoch 2/10\n",
      "30945/30945 [==============================] - 33s 1ms/step - loss: 0.3445 - acc: 0.9795\n",
      "Epoch 3/10\n",
      "30945/30945 [==============================] - 34s 1ms/step - loss: 0.3367 - acc: 0.9724\n",
      "Epoch 4/10\n",
      "30945/30945 [==============================] - 34s 1ms/step - loss: 0.3307 - acc: 0.9690\n",
      "Epoch 5/10\n",
      "30945/30945 [==============================] - 34s 1ms/step - loss: 0.3288 - acc: 0.9625\n",
      "Epoch 6/10\n",
      "30945/30945 [==============================] - 34s 1ms/step - loss: 0.3243 - acc: 0.9632\n",
      "Epoch 7/10\n",
      "30945/30945 [==============================] - 34s 1ms/step - loss: 0.3197 - acc: 0.9583\n",
      "Epoch 8/10\n",
      "30945/30945 [==============================] - 34s 1ms/step - loss: 0.3204 - acc: 0.9520\n",
      "Epoch 9/10\n",
      "30945/30945 [==============================] - 33s 1ms/step - loss: 0.3159 - acc: 0.9495\n",
      "Epoch 10/10\n",
      "30945/30945 [==============================] - 34s 1ms/step - loss: 0.3138 - acc: 0.9470\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15473/15473 [==============================] - 13s 852us/step\n",
      "30945/30945 [==============================] - 24s 770us/step\n",
      "[CV] .................... epochs=10, lr=0.002, nodes=32, total= 6.6min\n",
      "[CV] epochs=10, lr=0.002, nodes=32 ...................................\n",
      "Epoch 1/10\n",
      "30946/30946 [==============================] - 45s 1ms/step - loss: 0.3548 - acc: 0.9814\n",
      "Epoch 2/10\n",
      "30946/30946 [==============================] - 34s 1ms/step - loss: 0.3352 - acc: 0.9780\n",
      "Epoch 3/10\n",
      "30946/30946 [==============================] - 34s 1ms/step - loss: 0.3259 - acc: 0.9722\n",
      "Epoch 4/10\n",
      "30946/30946 [==============================] - 34s 1ms/step - loss: 0.3205 - acc: 0.9696\n",
      "Epoch 5/10\n",
      "30946/30946 [==============================] - 34s 1ms/step - loss: 0.3160 - acc: 0.9651\n",
      "Epoch 6/10\n",
      "30946/30946 [==============================] - 34s 1ms/step - loss: 0.3119 - acc: 0.9607\n",
      "Epoch 7/10\n",
      "30946/30946 [==============================] - 33s 1ms/step - loss: 0.3099 - acc: 0.9561\n",
      "Epoch 8/10\n",
      "30946/30946 [==============================] - 34s 1ms/step - loss: 0.3047 - acc: 0.9522\n",
      "Epoch 9/10\n",
      "30946/30946 [==============================] - 34s 1ms/step - loss: 0.3058 - acc: 0.9479\n",
      "Epoch 10/10\n",
      "30946/30946 [==============================] - 34s 1ms/step - loss: 0.3041 - acc: 0.9500\n",
      "15472/15472 [==============================] - 13s 851us/step\n",
      "30946/30946 [==============================] - 24s 776us/step\n",
      "[CV] .................... epochs=10, lr=0.002, nodes=32, total= 6.6min\n",
      "[CV] epochs=10, lr=0.002, nodes=64 ...................................\n",
      "Epoch 1/10\n",
      "30945/30945 [==============================] - 67s 2ms/step - loss: 0.3499 - acc: 0.9750\n",
      "Epoch 2/10\n",
      "30945/30945 [==============================] - 58s 2ms/step - loss: 0.3300 - acc: 0.9731\n",
      "Epoch 3/10\n",
      "30945/30945 [==============================] - 58s 2ms/step - loss: 0.3217 - acc: 0.9677\n",
      "Epoch 4/10\n",
      "30945/30945 [==============================] - 58s 2ms/step - loss: 0.3148 - acc: 0.9635\n",
      "Epoch 5/10\n",
      "30945/30945 [==============================] - 56s 2ms/step - loss: 0.3100 - acc: 0.9568\n",
      "Epoch 6/10\n",
      "30945/30945 [==============================] - 57s 2ms/step - loss: 0.3064 - acc: 0.9474\n",
      "Epoch 7/10\n",
      "30945/30945 [==============================] - 57s 2ms/step - loss: 0.3021 - acc: 0.9409\n",
      "Epoch 8/10\n",
      "30945/30945 [==============================] - 58s 2ms/step - loss: 0.3010 - acc: 0.9378\n",
      "Epoch 9/10\n",
      "30945/30945 [==============================] - 57s 2ms/step - loss: 0.3002 - acc: 0.9291\n",
      "Epoch 10/10\n",
      "30945/30945 [==============================] - 58s 2ms/step - loss: 0.2972 - acc: 0.9269\n",
      "15473/15473 [==============================] - 14s 873us/step\n",
      "30945/30945 [==============================] - 24s 787us/step\n",
      "[CV] .................... epochs=10, lr=0.002, nodes=64, total=10.5min\n",
      "[CV] epochs=10, lr=0.002, nodes=64 ...................................\n",
      "Epoch 1/10\n",
      "30945/30945 [==============================] - 65s 2ms/step - loss: 0.3631 - acc: 0.9803\n",
      "Epoch 2/10\n",
      "30945/30945 [==============================] - 55s 2ms/step - loss: 0.3417 - acc: 0.9754\n",
      "Epoch 3/10\n",
      "30945/30945 [==============================] - 53s 2ms/step - loss: 0.3341 - acc: 0.9694\n",
      "Epoch 4/10\n",
      "30945/30945 [==============================] - 54s 2ms/step - loss: 0.3273 - acc: 0.9643\n",
      "Epoch 5/10\n",
      "30945/30945 [==============================] - 54s 2ms/step - loss: 0.3216 - acc: 0.9594\n",
      "Epoch 6/10\n",
      "30945/30945 [==============================] - 55s 2ms/step - loss: 0.3171 - acc: 0.9568\n",
      "Epoch 7/10\n",
      "30945/30945 [==============================] - 54s 2ms/step - loss: 0.3137 - acc: 0.9479\n",
      "Epoch 8/10\n",
      "30945/30945 [==============================] - 55s 2ms/step - loss: 0.3091 - acc: 0.9446\n",
      "Epoch 9/10\n",
      "30945/30945 [==============================] - 54s 2ms/step - loss: 0.3080 - acc: 0.9408\n",
      "Epoch 10/10\n",
      "30945/30945 [==============================] - 54s 2ms/step - loss: 0.3070 - acc: 0.9382\n",
      "15473/15473 [==============================] - 14s 909us/step\n",
      "30945/30945 [==============================] - 26s 826us/step\n",
      "[CV] .................... epochs=10, lr=0.002, nodes=64, total=10.0min\n",
      "[CV] epochs=10, lr=0.002, nodes=64 ...................................\n",
      "Epoch 1/10\n",
      "30946/30946 [==============================] - 65s 2ms/step - loss: 0.3508 - acc: 0.9796\n",
      "Epoch 2/10\n",
      "30946/30946 [==============================] - 55s 2ms/step - loss: 0.3297 - acc: 0.9765\n",
      "Epoch 3/10\n",
      "30946/30946 [==============================] - 53s 2ms/step - loss: 0.3221 - acc: 0.9693\n",
      "Epoch 4/10\n",
      "30946/30946 [==============================] - 54s 2ms/step - loss: 0.3160 - acc: 0.9637\n",
      "Epoch 5/10\n",
      "30946/30946 [==============================] - 54s 2ms/step - loss: 0.3109 - acc: 0.9568\n",
      "Epoch 6/10\n",
      "30946/30946 [==============================] - 53s 2ms/step - loss: 0.3077 - acc: 0.9508\n",
      "Epoch 7/10\n",
      "30946/30946 [==============================] - 53s 2ms/step - loss: 0.3049 - acc: 0.9450\n",
      "Epoch 8/10\n",
      "30946/30946 [==============================] - 54s 2ms/step - loss: 0.3030 - acc: 0.9413\n",
      "Epoch 9/10\n",
      "30946/30946 [==============================] - 54s 2ms/step - loss: 0.2981 - acc: 0.9332\n",
      "Epoch 10/10\n",
      "30946/30946 [==============================] - 54s 2ms/step - loss: 0.2986 - acc: 0.9289\n",
      "15472/15472 [==============================] - 14s 917us/step\n",
      "30946/30946 [==============================] - 24s 765us/step\n",
      "[CV] .................... epochs=10, lr=0.002, nodes=64, total= 9.9min\n",
      "[CV] epochs=10, lr=0.003, nodes=16 ...................................\n",
      "Epoch 1/10\n",
      "30945/30945 [==============================] - 35s 1ms/step - loss: 0.3543 - acc: 0.9575\n",
      "Epoch 2/10\n",
      "30945/30945 [==============================] - 23s 743us/step - loss: 0.3372 - acc: 0.9789\n",
      "Epoch 3/10\n",
      "30945/30945 [==============================] - 23s 732us/step - loss: 0.3319 - acc: 0.9771\n",
      "Epoch 4/10\n",
      "30945/30945 [==============================] - 23s 733us/step - loss: 0.3288 - acc: 0.9730\n",
      "Epoch 5/10\n",
      "30945/30945 [==============================] - 23s 732us/step - loss: 0.3250 - acc: 0.9677\n",
      "Epoch 6/10\n",
      "30945/30945 [==============================] - 22s 707us/step - loss: 0.3217 - acc: 0.9682\n",
      "Epoch 7/10\n",
      "30945/30945 [==============================] - 22s 724us/step - loss: 0.3197 - acc: 0.9630\n",
      "Epoch 8/10\n",
      "30945/30945 [==============================] - 23s 734us/step - loss: 0.3182 - acc: 0.9570\n",
      "Epoch 9/10\n",
      "30945/30945 [==============================] - 23s 733us/step - loss: 0.3164 - acc: 0.9526\n",
      "Epoch 10/10\n",
      "30945/30945 [==============================] - 23s 734us/step - loss: 0.3177 - acc: 0.9496\n",
      "15473/15473 [==============================] - 12s 792us/step\n",
      "30945/30945 [==============================] - 23s 730us/step\n",
      "[CV] .................... epochs=10, lr=0.003, nodes=16, total= 4.7min\n",
      "[CV] epochs=10, lr=0.003, nodes=16 ...................................\n",
      "Epoch 1/10\n",
      "30945/30945 [==============================] - 31s 1ms/step - loss: 0.3635 - acc: 0.9752\n",
      "Epoch 2/10\n",
      "30945/30945 [==============================] - 19s 608us/step - loss: 0.3477 - acc: 0.9794\n",
      "Epoch 3/10\n",
      "30945/30945 [==============================] - 19s 610us/step - loss: 0.3434 - acc: 0.9747\n",
      "Epoch 4/10\n",
      "30945/30945 [==============================] - 19s 604us/step - loss: 0.3400 - acc: 0.9707\n",
      "Epoch 5/10\n",
      "30945/30945 [==============================] - 18s 585us/step - loss: 0.3377 - acc: 0.9707\n",
      "Epoch 6/10\n",
      "30945/30945 [==============================] - 19s 608us/step - loss: 0.3339 - acc: 0.9617\n",
      "Epoch 7/10\n",
      "30945/30945 [==============================] - 19s 598us/step - loss: 0.3309 - acc: 0.9575\n",
      "Epoch 8/10\n",
      "30945/30945 [==============================] - 19s 609us/step - loss: 0.3303 - acc: 0.9576\n",
      "Epoch 9/10\n",
      "30945/30945 [==============================] - 19s 600us/step - loss: 0.3297 - acc: 0.9534\n",
      "Epoch 10/10\n",
      "30945/30945 [==============================] - 19s 612us/step - loss: 0.3277 - acc: 0.9475\n",
      "15473/15473 [==============================] - 11s 689us/step\n",
      "30945/30945 [==============================] - 19s 607us/step\n",
      "[CV] .................... epochs=10, lr=0.003, nodes=16, total= 4.0min\n",
      "[CV] epochs=10, lr=0.003, nodes=16 ...................................\n",
      "Epoch 1/10\n",
      "30946/30946 [==============================] - 31s 1ms/step - loss: 0.3553 - acc: 0.9826\n",
      "Epoch 2/10\n",
      "30946/30946 [==============================] - 19s 618us/step - loss: 0.3363 - acc: 0.9818\n",
      "Epoch 3/10\n",
      "30946/30946 [==============================] - 19s 623us/step - loss: 0.3281 - acc: 0.9751\n",
      "Epoch 4/10\n",
      "30946/30946 [==============================] - 19s 622us/step - loss: 0.3245 - acc: 0.9675\n",
      "Epoch 5/10\n",
      "30946/30946 [==============================] - 19s 627us/step - loss: 0.3230 - acc: 0.9649\n",
      "Epoch 6/10\n",
      "30946/30946 [==============================] - 19s 619us/step - loss: 0.3188 - acc: 0.9581\n",
      "Epoch 7/10\n",
      "30946/30946 [==============================] - 20s 632us/step - loss: 0.3160 - acc: 0.9534\n",
      "Epoch 8/10\n",
      "30946/30946 [==============================] - 19s 621us/step - loss: 0.3147 - acc: 0.9505\n",
      "Epoch 9/10\n",
      "30946/30946 [==============================] - 20s 637us/step - loss: 0.3142 - acc: 0.9454\n",
      "Epoch 10/10\n",
      "30946/30946 [==============================] - 20s 635us/step - loss: 0.3123 - acc: 0.9435\n",
      "15472/15472 [==============================] - 11s 692us/step\n",
      "30946/30946 [==============================] - 19s 612us/step\n",
      "[CV] .................... epochs=10, lr=0.003, nodes=16, total= 4.2min\n",
      "[CV] epochs=10, lr=0.003, nodes=32 ...................................\n",
      "Epoch 1/10\n",
      "30945/30945 [==============================] - 42s 1ms/step - loss: 0.3524 - acc: 0.9763\n",
      "Epoch 2/10\n",
      "30945/30945 [==============================] - 31s 1ms/step - loss: 0.3349 - acc: 0.9775\n",
      "Epoch 3/10\n",
      "30945/30945 [==============================] - 31s 1ms/step - loss: 0.3278 - acc: 0.9733\n",
      "Epoch 4/10\n",
      "30945/30945 [==============================] - 32s 1ms/step - loss: 0.3229 - acc: 0.9684\n",
      "Epoch 5/10\n",
      "30945/30945 [==============================] - 31s 1ms/step - loss: 0.3201 - acc: 0.9621\n",
      "Epoch 6/10\n",
      "30945/30945 [==============================] - 31s 1ms/step - loss: 0.3146 - acc: 0.9584\n",
      "Epoch 7/10\n",
      "30945/30945 [==============================] - 31s 1ms/step - loss: 0.3112 - acc: 0.9537\n",
      "Epoch 8/10\n",
      "30945/30945 [==============================] - 31s 1ms/step - loss: 0.3088 - acc: 0.9480\n",
      "Epoch 9/10\n",
      "30945/30945 [==============================] - 32s 1ms/step - loss: 0.3088 - acc: 0.9463\n",
      "Epoch 10/10\n",
      "30945/30945 [==============================] - 32s 1ms/step - loss: 0.3069 - acc: 0.9414\n",
      "15473/15473 [==============================] - 13s 863us/step\n",
      "30945/30945 [==============================] - 24s 777us/step\n",
      "[CV] .................... epochs=10, lr=0.003, nodes=32, total= 6.2min\n",
      "[CV] epochs=10, lr=0.003, nodes=32 ...................................\n",
      "Epoch 1/10\n",
      "30945/30945 [==============================] - 45s 1ms/step - loss: 0.3633 - acc: 0.9725\n",
      "Epoch 2/10\n",
      "30945/30945 [==============================] - 34s 1ms/step - loss: 0.3441 - acc: 0.9799\n",
      "Epoch 3/10\n",
      "30945/30945 [==============================] - 34s 1ms/step - loss: 0.3371 - acc: 0.9718\n",
      "Epoch 4/10\n",
      "30945/30945 [==============================] - 34s 1ms/step - loss: 0.3308 - acc: 0.9659\n",
      "Epoch 5/10\n",
      "30945/30945 [==============================] - 34s 1ms/step - loss: 0.3280 - acc: 0.9571\n",
      "Epoch 6/10\n",
      "30945/30945 [==============================] - 35s 1ms/step - loss: 0.3259 - acc: 0.9502\n",
      "Epoch 7/10\n",
      "30945/30945 [==============================] - 34s 1ms/step - loss: 0.3234 - acc: 0.9452\n",
      "Epoch 8/10\n",
      "30945/30945 [==============================] - 33s 1ms/step - loss: 0.3215 - acc: 0.9444\n",
      "Epoch 9/10\n",
      "30945/30945 [==============================] - 35s 1ms/step - loss: 0.3199 - acc: 0.9354\n",
      "Epoch 10/10\n",
      "30945/30945 [==============================] - 34s 1ms/step - loss: 0.3191 - acc: 0.9344\n",
      "15473/15473 [==============================] - 13s 855us/step\n",
      "30945/30945 [==============================] - 24s 764us/step\n",
      "[CV] .................... epochs=10, lr=0.003, nodes=32, total= 6.6min\n",
      "[CV] epochs=10, lr=0.003, nodes=32 ...................................\n",
      "Epoch 1/10\n",
      "30946/30946 [==============================] - 45s 1ms/step - loss: 0.3513 - acc: 0.9797\n",
      "Epoch 2/10\n",
      "30946/30946 [==============================] - 34s 1ms/step - loss: 0.3349 - acc: 0.9799\n",
      "Epoch 3/10\n",
      "30946/30946 [==============================] - 33s 1ms/step - loss: 0.3254 - acc: 0.9713\n",
      "Epoch 4/10\n",
      "30946/30946 [==============================] - 33s 1ms/step - loss: 0.3198 - acc: 0.9646\n",
      "Epoch 5/10\n",
      "30946/30946 [==============================] - 33s 1ms/step - loss: 0.3155 - acc: 0.9591\n",
      "Epoch 6/10\n",
      "30946/30946 [==============================] - 33s 1ms/step - loss: 0.3125 - acc: 0.9549\n",
      "Epoch 7/10\n",
      "30946/30946 [==============================] - 33s 1ms/step - loss: 0.3106 - acc: 0.9427\n",
      "Epoch 8/10\n",
      "30946/30946 [==============================] - 33s 1ms/step - loss: 0.3087 - acc: 0.9396\n",
      "Epoch 9/10\n",
      "30946/30946 [==============================] - 34s 1ms/step - loss: 0.3074 - acc: 0.9336\n",
      "Epoch 10/10\n",
      "30946/30946 [==============================] - 34s 1ms/step - loss: 0.3075 - acc: 0.9259\n",
      "15472/15472 [==============================] - 13s 863us/step\n",
      "30946/30946 [==============================] - 24s 777us/step\n",
      "[CV] .................... epochs=10, lr=0.003, nodes=32, total= 6.5min\n",
      "[CV] epochs=10, lr=0.003, nodes=64 ...................................\n",
      "Epoch 1/10\n",
      "30945/30945 [==============================] - 65s 2ms/step - loss: 0.3491 - acc: 0.9751\n",
      "Epoch 2/10\n",
      "30945/30945 [==============================] - 55s 2ms/step - loss: 0.3304 - acc: 0.9719\n",
      "Epoch 3/10\n",
      "30945/30945 [==============================] - 55s 2ms/step - loss: 0.3219 - acc: 0.9677\n",
      "Epoch 4/10\n",
      "30945/30945 [==============================] - 56s 2ms/step - loss: 0.3147 - acc: 0.9589\n",
      "Epoch 5/10\n",
      "30945/30945 [==============================] - 54s 2ms/step - loss: 0.3111 - acc: 0.9520\n",
      "Epoch 6/10\n",
      "30945/30945 [==============================] - 55s 2ms/step - loss: 0.3078 - acc: 0.9498\n",
      "Epoch 7/10\n",
      "30945/30945 [==============================] - 55s 2ms/step - loss: 0.3061 - acc: 0.9427\n",
      "Epoch 8/10\n",
      "30945/30945 [==============================] - 55s 2ms/step - loss: 0.3074 - acc: 0.9406\n",
      "Epoch 9/10\n",
      "30945/30945 [==============================] - 55s 2ms/step - loss: 0.3020 - acc: 0.9376\n",
      "Epoch 10/10\n",
      "30945/30945 [==============================] - 55s 2ms/step - loss: 0.3011 - acc: 0.9271\n",
      "15473/15473 [==============================] - 14s 917us/step\n",
      "30945/30945 [==============================] - 26s 845us/step\n",
      "[CV] .................... epochs=10, lr=0.003, nodes=64, total=10.1min\n",
      "[CV] epochs=10, lr=0.003, nodes=64 ...................................\n",
      "Epoch 1/10\n",
      "30945/30945 [==============================] - 66s 2ms/step - loss: 0.3603 - acc: 0.9801\n",
      "Epoch 2/10\n",
      "30945/30945 [==============================] - 56s 2ms/step - loss: 0.3412 - acc: 0.9748\n",
      "Epoch 3/10\n",
      "30945/30945 [==============================] - 51s 2ms/step - loss: 0.3308 - acc: 0.9662\n",
      "Epoch 4/10\n",
      "30945/30945 [==============================] - 51s 2ms/step - loss: 0.3260 - acc: 0.9568\n",
      "Epoch 5/10\n",
      "30945/30945 [==============================] - 51s 2ms/step - loss: 0.3207 - acc: 0.9554\n",
      "Epoch 6/10\n",
      "30945/30945 [==============================] - 52s 2ms/step - loss: 0.3165 - acc: 0.9516\n",
      "Epoch 7/10\n",
      "30945/30945 [==============================] - 53s 2ms/step - loss: 0.3148 - acc: 0.9438\n",
      "Epoch 8/10\n",
      "30945/30945 [==============================] - 56s 2ms/step - loss: 0.3136 - acc: 0.9408\n",
      "Epoch 9/10\n",
      "30945/30945 [==============================] - 56s 2ms/step - loss: 0.3128 - acc: 0.9390\n",
      "Epoch 10/10\n",
      "30945/30945 [==============================] - 56s 2ms/step - loss: 0.3112 - acc: 0.9342\n",
      "15473/15473 [==============================] - 14s 937us/step\n",
      "30945/30945 [==============================] - 26s 846us/step\n",
      "[CV] .................... epochs=10, lr=0.003, nodes=64, total= 9.9min\n",
      "[CV] epochs=10, lr=0.003, nodes=64 ...................................\n",
      "Epoch 1/10\n",
      "30946/30946 [==============================] - 65s 2ms/step - loss: 0.3504 - acc: 0.9786\n",
      "Epoch 2/10\n",
      "30946/30946 [==============================] - 54s 2ms/step - loss: 0.3322 - acc: 0.9749\n",
      "Epoch 3/10\n",
      "30946/30946 [==============================] - 54s 2ms/step - loss: 0.3201 - acc: 0.9655\n",
      "Epoch 4/10\n",
      "30946/30946 [==============================] - 55s 2ms/step - loss: 0.3149 - acc: 0.9567\n",
      "Epoch 5/10\n",
      "30946/30946 [==============================] - 54s 2ms/step - loss: 0.3093 - acc: 0.9545\n",
      "Epoch 6/10\n",
      "30946/30946 [==============================] - 54s 2ms/step - loss: 0.3076 - acc: 0.9505\n",
      "Epoch 7/10\n",
      "30946/30946 [==============================] - 54s 2ms/step - loss: 0.3042 - acc: 0.9391\n",
      "Epoch 8/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30946/30946 [==============================] - 54s 2ms/step - loss: 0.3025 - acc: 0.9366\n",
      "Epoch 9/10\n",
      "30946/30946 [==============================] - 54s 2ms/step - loss: 0.3007 - acc: 0.9303\n",
      "Epoch 10/10\n",
      "30946/30946 [==============================] - 54s 2ms/step - loss: 0.3020 - acc: 0.9212\n",
      "15472/15472 [==============================] - 14s 935us/step\n",
      "30946/30946 [==============================] - 24s 778us/step\n",
      "[CV] .................... epochs=10, lr=0.003, nodes=64, total=10.0min\n",
      "[CV] epochs=20, lr=0.001, nodes=16 ...................................\n",
      "Epoch 1/20\n",
      "30945/30945 [==============================] - 35s 1ms/step - loss: 0.3706 - acc: 0.9596\n",
      "Epoch 2/20\n",
      "30945/30945 [==============================] - 23s 734us/step - loss: 0.3420 - acc: 0.9811\n",
      "Epoch 3/20\n",
      "30945/30945 [==============================] - 22s 700us/step - loss: 0.3362 - acc: 0.9808\n",
      "Epoch 4/20\n",
      "30945/30945 [==============================] - 23s 733us/step - loss: 0.3320 - acc: 0.9792\n",
      "Epoch 5/20\n",
      "30945/30945 [==============================] - 23s 733us/step - loss: 0.3284 - acc: 0.9772\n",
      "Epoch 6/20\n",
      "30945/30945 [==============================] - 23s 739us/step - loss: 0.3237 - acc: 0.9749\n",
      "Epoch 7/20\n",
      "30945/30945 [==============================] - 23s 738us/step - loss: 0.3222 - acc: 0.9709\n",
      "Epoch 8/20\n",
      "30945/30945 [==============================] - 23s 750us/step - loss: 0.3200 - acc: 0.9684\n",
      "Epoch 9/20\n",
      "30945/30945 [==============================] - 23s 747us/step - loss: 0.3179 - acc: 0.9669\n",
      "Epoch 10/20\n",
      "30945/30945 [==============================] - 22s 718us/step - loss: 0.3160 - acc: 0.9606\n",
      "Epoch 11/20\n",
      "30945/30945 [==============================] - 22s 724us/step - loss: 0.3133 - acc: 0.9587\n",
      "Epoch 12/20\n",
      "30945/30945 [==============================] - 23s 728us/step - loss: 0.3125 - acc: 0.9560\n",
      "Epoch 13/20\n",
      "30945/30945 [==============================] - 23s 727us/step - loss: 0.3106 - acc: 0.9552\n",
      "Epoch 14/20\n",
      "30945/30945 [==============================] - 23s 729us/step - loss: 0.3105 - acc: 0.9492\n",
      "Epoch 15/20\n",
      "30945/30945 [==============================] - 23s 729us/step - loss: 0.3086 - acc: 0.9478\n",
      "Epoch 16/20\n",
      "30945/30945 [==============================] - 23s 728us/step - loss: 0.3084 - acc: 0.9427\n",
      "Epoch 17/20\n",
      "30945/30945 [==============================] - 23s 739us/step - loss: 0.3089 - acc: 0.9461\n",
      "Epoch 18/20\n",
      "30945/30945 [==============================] - 22s 724us/step - loss: 0.3062 - acc: 0.9425\n",
      "Epoch 19/20\n",
      "30945/30945 [==============================] - 22s 722us/step - loss: 0.3033 - acc: 0.9362\n",
      "Epoch 20/20\n",
      "30945/30945 [==============================] - 22s 722us/step - loss: 0.3020 - acc: 0.9394\n",
      "15473/15473 [==============================] - 12s 802us/step\n",
      "30945/30945 [==============================] - 23s 737us/step\n",
      "[CV] .................... epochs=20, lr=0.001, nodes=16, total= 8.5min\n",
      "[CV] epochs=20, lr=0.001, nodes=16 ...................................\n",
      "Epoch 1/20\n",
      "30945/30945 [==============================] - 32s 1ms/step - loss: 0.3778 - acc: 0.9414\n",
      "Epoch 2/20\n",
      "30945/30945 [==============================] - 18s 580us/step - loss: 0.3517 - acc: 0.9800\n",
      "Epoch 3/20\n",
      "30945/30945 [==============================] - 19s 601us/step - loss: 0.3457 - acc: 0.9793\n",
      "Epoch 4/20\n",
      "30945/30945 [==============================] - 19s 606us/step - loss: 0.3419 - acc: 0.9802\n",
      "Epoch 5/20\n",
      "30945/30945 [==============================] - 19s 605us/step - loss: 0.3397 - acc: 0.9772\n",
      "Epoch 6/20\n",
      "30945/30945 [==============================] - 19s 608us/step - loss: 0.3374 - acc: 0.9751\n",
      "Epoch 7/20\n",
      "30945/30945 [==============================] - 19s 602us/step - loss: 0.3344 - acc: 0.9729\n",
      "Epoch 8/20\n",
      "30945/30945 [==============================] - 19s 606us/step - loss: 0.3313 - acc: 0.9694\n",
      "Epoch 9/20\n",
      "30945/30945 [==============================] - 19s 605us/step - loss: 0.3293 - acc: 0.9673\n",
      "Epoch 10/20\n",
      "30945/30945 [==============================] - 19s 603us/step - loss: 0.3280 - acc: 0.9665\n",
      "Epoch 11/20\n",
      "30945/30945 [==============================] - 19s 612us/step - loss: 0.3270 - acc: 0.9624\n",
      "Epoch 12/20\n",
      "30945/30945 [==============================] - 19s 612us/step - loss: 0.3251 - acc: 0.9591\n",
      "Epoch 13/20\n",
      "30945/30945 [==============================] - 19s 608us/step - loss: 0.3230 - acc: 0.9547\n",
      "Epoch 14/20\n",
      "30945/30945 [==============================] - 19s 610us/step - loss: 0.3214 - acc: 0.9527\n",
      "Epoch 15/20\n",
      "30945/30945 [==============================] - 19s 612us/step - loss: 0.3203 - acc: 0.9525\n",
      "Epoch 16/20\n",
      "30945/30945 [==============================] - 19s 616us/step - loss: 0.3199 - acc: 0.9492\n",
      "Epoch 17/20\n",
      "30945/30945 [==============================] - 19s 619us/step - loss: 0.3194 - acc: 0.9487\n",
      "Epoch 18/20\n",
      "30945/30945 [==============================] - 19s 620us/step - loss: 0.3184 - acc: 0.9430\n",
      "Epoch 19/20\n",
      "30945/30945 [==============================] - 19s 615us/step - loss: 0.3157 - acc: 0.9447\n",
      "Epoch 20/20\n",
      "30945/30945 [==============================] - 19s 617us/step - loss: 0.3167 - acc: 0.9394\n",
      "15473/15473 [==============================] - 11s 712us/step\n",
      "30945/30945 [==============================] - 19s 616us/step\n",
      "[CV] .................... epochs=20, lr=0.001, nodes=16, total= 7.2min\n",
      "[CV] epochs=20, lr=0.001, nodes=16 ...................................\n",
      "Epoch 1/20\n",
      "30946/30946 [==============================] - 32s 1ms/step - loss: 0.3643 - acc: 0.9891\n",
      "Epoch 2/20\n",
      "30946/30946 [==============================] - 19s 615us/step - loss: 0.3431 - acc: 0.9850\n",
      "Epoch 3/20\n",
      "30946/30946 [==============================] - 19s 604us/step - loss: 0.3377 - acc: 0.9829\n",
      "Epoch 4/20\n",
      "30946/30946 [==============================] - 19s 606us/step - loss: 0.3341 - acc: 0.9783\n",
      "Epoch 5/20\n",
      "30946/30946 [==============================] - 19s 601us/step - loss: 0.3296 - acc: 0.9772\n",
      "Epoch 6/20\n",
      "30946/30946 [==============================] - 19s 608us/step - loss: 0.3285 - acc: 0.9738\n",
      "Epoch 7/20\n",
      "30946/30946 [==============================] - 19s 607us/step - loss: 0.3236 - acc: 0.9717\n",
      "Epoch 8/20\n",
      "30946/30946 [==============================] - 19s 604us/step - loss: 0.3222 - acc: 0.9698\n",
      "Epoch 9/20\n",
      "30946/30946 [==============================] - 19s 601us/step - loss: 0.3192 - acc: 0.9684\n",
      "Epoch 10/20\n",
      "30946/30946 [==============================] - 19s 606us/step - loss: 0.3191 - acc: 0.9673\n",
      "Epoch 11/20\n",
      "30946/30946 [==============================] - 19s 605us/step - loss: 0.3171 - acc: 0.9632\n",
      "Epoch 12/20\n",
      "30946/30946 [==============================] - 19s 609us/step - loss: 0.3138 - acc: 0.9603\n",
      "Epoch 13/20\n",
      "30946/30946 [==============================] - 18s 591us/step - loss: 0.3149 - acc: 0.9626\n",
      "Epoch 14/20\n",
      "30946/30946 [==============================] - 18s 596us/step - loss: 0.3126 - acc: 0.9551\n",
      "Epoch 15/20\n",
      "30946/30946 [==============================] - 19s 604us/step - loss: 0.3119 - acc: 0.9566\n",
      "Epoch 16/20\n",
      "30946/30946 [==============================] - 19s 609us/step - loss: 0.3099 - acc: 0.9542\n",
      "Epoch 17/20\n",
      "30946/30946 [==============================] - 18s 597us/step - loss: 0.3092 - acc: 0.9496\n",
      "Epoch 18/20\n",
      "30946/30946 [==============================] - 18s 582us/step - loss: 0.3087 - acc: 0.9467\n",
      "Epoch 19/20\n",
      "30946/30946 [==============================] - 19s 616us/step - loss: 0.3077 - acc: 0.9408\n",
      "Epoch 20/20\n",
      "30946/30946 [==============================] - 19s 603us/step - loss: 0.3080 - acc: 0.9418\n",
      "15472/15472 [==============================] - 11s 715us/step\n",
      "30946/30946 [==============================] - 19s 618us/step\n",
      "[CV] .................... epochs=20, lr=0.001, nodes=16, total= 7.2min\n",
      "[CV] epochs=20, lr=0.001, nodes=32 ...................................\n",
      "Epoch 1/20\n",
      "30945/30945 [==============================] - 44s 1ms/step - loss: 0.3614 - acc: 0.9747\n",
      "Epoch 2/20\n",
      "30945/30945 [==============================] - 32s 1ms/step - loss: 0.3379 - acc: 0.9800\n",
      "Epoch 3/20\n",
      "30945/30945 [==============================] - 32s 1ms/step - loss: 0.3304 - acc: 0.9764\n",
      "Epoch 4/20\n",
      "30945/30945 [==============================] - 32s 1ms/step - loss: 0.3243 - acc: 0.9743\n",
      "Epoch 5/20\n",
      "30945/30945 [==============================] - 32s 1ms/step - loss: 0.3197 - acc: 0.9721\n",
      "Epoch 6/20\n",
      "30945/30945 [==============================] - 32s 1ms/step - loss: 0.3164 - acc: 0.9699\n",
      "Epoch 7/20\n",
      "30945/30945 [==============================] - 33s 1ms/step - loss: 0.3129 - acc: 0.9663\n",
      "Epoch 8/20\n",
      "30945/30945 [==============================] - 33s 1ms/step - loss: 0.3110 - acc: 0.9641\n",
      "Epoch 9/20\n",
      "30945/30945 [==============================] - 32s 1ms/step - loss: 0.3069 - acc: 0.9635\n",
      "Epoch 10/20\n",
      "30945/30945 [==============================] - 33s 1ms/step - loss: 0.3040 - acc: 0.9585\n",
      "Epoch 11/20\n",
      "30945/30945 [==============================] - 33s 1ms/step - loss: 0.3008 - acc: 0.9570\n",
      "Epoch 12/20\n",
      "30945/30945 [==============================] - 33s 1ms/step - loss: 0.3009 - acc: 0.9533\n",
      "Epoch 13/20\n",
      "30945/30945 [==============================] - 33s 1ms/step - loss: 0.2995 - acc: 0.9514\n",
      "Epoch 14/20\n",
      "30945/30945 [==============================] - 33s 1ms/step - loss: 0.2976 - acc: 0.9474\n",
      "Epoch 15/20\n",
      "30945/30945 [==============================] - 33s 1ms/step - loss: 0.2963 - acc: 0.9437\n",
      "Epoch 16/20\n",
      "30945/30945 [==============================] - 33s 1ms/step - loss: 0.2962 - acc: 0.9406\n",
      "Epoch 17/20\n",
      "30945/30945 [==============================] - 33s 1ms/step - loss: 0.2932 - acc: 0.9392\n",
      "Epoch 18/20\n",
      "30945/30945 [==============================] - 33s 1ms/step - loss: 0.2929 - acc: 0.9384\n",
      "Epoch 19/20\n",
      "30945/30945 [==============================] - 33s 1ms/step - loss: 0.2923 - acc: 0.9351\n",
      "Epoch 20/20\n",
      "30945/30945 [==============================] - 33s 1ms/step - loss: 0.2902 - acc: 0.9287\n",
      "15473/15473 [==============================] - 14s 916us/step\n",
      "30945/30945 [==============================] - 24s 780us/step\n",
      "[CV] .................... epochs=20, lr=0.001, nodes=32, total=11.9min\n",
      "[CV] epochs=20, lr=0.001, nodes=32 ...................................\n",
      "Epoch 1/20\n",
      "30945/30945 [==============================] - 42s 1ms/step - loss: 0.3700 - acc: 0.9682\n",
      "Epoch 2/20\n",
      "30945/30945 [==============================] - 31s 989us/step - loss: 0.3489 - acc: 0.9814\n",
      "Epoch 3/20\n",
      "30945/30945 [==============================] - 31s 991us/step - loss: 0.3422 - acc: 0.9787\n",
      "Epoch 4/20\n",
      "30945/30945 [==============================] - 31s 1ms/step - loss: 0.3350 - acc: 0.9767\n",
      "Epoch 5/20\n",
      "30945/30945 [==============================] - 31s 995us/step - loss: 0.3303 - acc: 0.9709\n",
      "Epoch 6/20\n",
      "30945/30945 [==============================] - 30s 981us/step - loss: 0.3269 - acc: 0.9667\n",
      "Epoch 7/20\n",
      "30945/30945 [==============================] - 31s 998us/step - loss: 0.3234 - acc: 0.9648\n",
      "Epoch 8/20\n",
      "30945/30945 [==============================] - 31s 991us/step - loss: 0.3210 - acc: 0.9608\n",
      "Epoch 9/20\n",
      "30945/30945 [==============================] - 31s 994us/step - loss: 0.3184 - acc: 0.9541\n",
      "Epoch 10/20\n",
      "30945/30945 [==============================] - 31s 1ms/step - loss: 0.3161 - acc: 0.9528\n",
      "Epoch 11/20\n",
      "30945/30945 [==============================] - 31s 999us/step - loss: 0.3166 - acc: 0.9467\n",
      "Epoch 12/20\n",
      "30945/30945 [==============================] - 31s 1ms/step - loss: 0.3121 - acc: 0.9400\n",
      "Epoch 13/20\n",
      "30945/30945 [==============================] - 31s 1ms/step - loss: 0.3131 - acc: 0.9384\n",
      "Epoch 14/20\n",
      "30945/30945 [==============================] - 31s 1ms/step - loss: 0.3089 - acc: 0.9363\n",
      "Epoch 15/20\n",
      "30945/30945 [==============================] - 31s 996us/step - loss: 0.3083 - acc: 0.9273\n",
      "Epoch 16/20\n",
      "30945/30945 [==============================] - 31s 1ms/step - loss: 0.3073 - acc: 0.9307\n",
      "Epoch 17/20\n",
      "30945/30945 [==============================] - 31s 1ms/step - loss: 0.3072 - acc: 0.9251\n",
      "Epoch 18/20\n",
      "30945/30945 [==============================] - 31s 1ms/step - loss: 0.3065 - acc: 0.9267\n",
      "Epoch 19/20\n",
      "30945/30945 [==============================] - 31s 1ms/step - loss: 0.3051 - acc: 0.9224\n",
      "Epoch 20/20\n",
      "30945/30945 [==============================] - 31s 1ms/step - loss: 0.3058 - acc: 0.9233\n",
      "15473/15473 [==============================] - 14s 879us/step\n",
      "30945/30945 [==============================] - 24s 778us/step\n",
      "[CV] .................... epochs=20, lr=0.001, nodes=32, total=11.3min\n",
      "[CV] epochs=20, lr=0.001, nodes=32 ...................................\n",
      "Epoch 1/20\n",
      "30946/30946 [==============================] - 42s 1ms/step - loss: 0.3591 - acc: 0.9844\n",
      "Epoch 2/20\n",
      "30946/30946 [==============================] - 30s 981us/step - loss: 0.3369 - acc: 0.9804\n",
      "Epoch 3/20\n",
      "30946/30946 [==============================] - 30s 962us/step - loss: 0.3284 - acc: 0.9768\n",
      "Epoch 4/20\n",
      "30946/30946 [==============================] - 30s 982us/step - loss: 0.3220 - acc: 0.9723\n",
      "Epoch 5/20\n",
      "30946/30946 [==============================] - 31s 986us/step - loss: 0.3177 - acc: 0.9710\n",
      "Epoch 6/20\n",
      "30946/30946 [==============================] - 31s 1ms/step - loss: 0.3143 - acc: 0.9665\n",
      "Epoch 7/20\n",
      "30946/30946 [==============================] - 31s 1ms/step - loss: 0.3114 - acc: 0.9625\n",
      "Epoch 8/20\n",
      "30946/30946 [==============================] - 31s 1ms/step - loss: 0.3084 - acc: 0.9617\n",
      "Epoch 9/20\n",
      "30946/30946 [==============================] - 32s 1ms/step - loss: 0.3062 - acc: 0.9609\n",
      "Epoch 10/20\n",
      "30946/30946 [==============================] - 31s 1ms/step - loss: 0.3037 - acc: 0.9549\n",
      "Epoch 11/20\n",
      "30946/30946 [==============================] - 31s 1ms/step - loss: 0.3036 - acc: 0.9508\n",
      "Epoch 12/20\n",
      "30946/30946 [==============================] - 31s 1ms/step - loss: 0.3011 - acc: 0.9471\n",
      "Epoch 13/20\n",
      "30946/30946 [==============================] - 31s 1ms/step - loss: 0.3000 - acc: 0.9469\n",
      "Epoch 14/20\n",
      "30946/30946 [==============================] - 31s 1ms/step - loss: 0.2984 - acc: 0.9406\n",
      "Epoch 15/20\n",
      "30946/30946 [==============================] - 31s 995us/step - loss: 0.2976 - acc: 0.9379\n",
      "Epoch 16/20\n",
      "30946/30946 [==============================] - 31s 989us/step - loss: 0.2954 - acc: 0.9354\n",
      "Epoch 17/20\n",
      "30946/30946 [==============================] - 31s 1ms/step - loss: 0.2938 - acc: 0.9320\n",
      "Epoch 18/20\n",
      "30946/30946 [==============================] - 31s 1ms/step - loss: 0.2943 - acc: 0.9239\n",
      "Epoch 19/20\n",
      "30946/30946 [==============================] - 30s 983us/step - loss: 0.2933 - acc: 0.9229\n",
      "Epoch 20/20\n",
      "30946/30946 [==============================] - 31s 999us/step - loss: 0.2913 - acc: 0.9210\n",
      "15472/15472 [==============================] - 13s 870us/step\n",
      "30946/30946 [==============================] - 22s 727us/step\n",
      "[CV] .................... epochs=20, lr=0.001, nodes=32, total=11.3min\n",
      "[CV] epochs=20, lr=0.001, nodes=64 ...................................\n",
      "Epoch 1/20\n",
      "30945/30945 [==============================] - 64s 2ms/step - loss: 0.3551 - acc: 0.9815\n",
      "Epoch 2/20\n",
      "30945/30945 [==============================] - 53s 2ms/step - loss: 0.3340 - acc: 0.9779\n",
      "Epoch 3/20\n",
      "30945/30945 [==============================] - 52s 2ms/step - loss: 0.3239 - acc: 0.9744\n",
      "Epoch 4/20\n",
      "30945/30945 [==============================] - 52s 2ms/step - loss: 0.3175 - acc: 0.9685\n",
      "Epoch 5/20\n",
      "30945/30945 [==============================] - 52s 2ms/step - loss: 0.3115 - acc: 0.9650\n",
      "Epoch 6/20\n",
      "30945/30945 [==============================] - 53s 2ms/step - loss: 0.3062 - acc: 0.9593\n",
      "Epoch 7/20\n",
      "30945/30945 [==============================] - 53s 2ms/step - loss: 0.3024 - acc: 0.9540\n",
      "Epoch 8/20\n",
      "30945/30945 [==============================] - 52s 2ms/step - loss: 0.2992 - acc: 0.9511\n",
      "Epoch 9/20\n",
      "30945/30945 [==============================] - 52s 2ms/step - loss: 0.2976 - acc: 0.9452\n",
      "Epoch 10/20\n",
      "30945/30945 [==============================] - 52s 2ms/step - loss: 0.2955 - acc: 0.9431\n",
      "Epoch 11/20\n",
      "30945/30945 [==============================] - 51s 2ms/step - loss: 0.2924 - acc: 0.9364\n",
      "Epoch 12/20\n",
      "30945/30945 [==============================] - 52s 2ms/step - loss: 0.2917 - acc: 0.9361\n",
      "Epoch 13/20\n",
      "30945/30945 [==============================] - 52s 2ms/step - loss: 0.2905 - acc: 0.9335\n",
      "Epoch 14/20\n",
      "30945/30945 [==============================] - 52s 2ms/step - loss: 0.2885 - acc: 0.9286\n",
      "Epoch 15/20\n",
      "30945/30945 [==============================] - 53s 2ms/step - loss: 0.2874 - acc: 0.9275\n",
      "Epoch 16/20\n",
      "30945/30945 [==============================] - 53s 2ms/step - loss: 0.2870 - acc: 0.9295\n",
      "Epoch 17/20\n",
      "30945/30945 [==============================] - 52s 2ms/step - loss: 0.2866 - acc: 0.9224\n",
      "Epoch 18/20\n",
      "30945/30945 [==============================] - 53s 2ms/step - loss: 0.2875 - acc: 0.9209\n",
      "Epoch 19/20\n",
      "30945/30945 [==============================] - 53s 2ms/step - loss: 0.2852 - acc: 0.9189\n",
      "Epoch 20/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30945/30945 [==============================] - 53s 2ms/step - loss: 0.2851 - acc: 0.9132\n",
      "15473/15473 [==============================] - 14s 890us/step\n",
      "30945/30945 [==============================] - 24s 783us/step\n",
      "[CV] .................... epochs=20, lr=0.001, nodes=64, total=18.5min\n",
      "[CV] epochs=20, lr=0.001, nodes=64 ...................................\n",
      "Epoch 1/20\n",
      "30945/30945 [==============================] - 65s 2ms/step - loss: 0.3652 - acc: 0.9787\n",
      "Epoch 2/20\n",
      "30945/30945 [==============================] - 54s 2ms/step - loss: 0.3437 - acc: 0.9787\n",
      "Epoch 3/20\n",
      "30945/30945 [==============================] - 53s 2ms/step - loss: 0.3337 - acc: 0.9731\n",
      "Epoch 4/20\n",
      "30945/30945 [==============================] - 53s 2ms/step - loss: 0.3279 - acc: 0.9686\n",
      "Epoch 5/20\n",
      "30945/30945 [==============================] - 52s 2ms/step - loss: 0.3227 - acc: 0.9650\n",
      "Epoch 6/20\n",
      "30945/30945 [==============================] - 53s 2ms/step - loss: 0.3197 - acc: 0.9635\n",
      "Epoch 7/20\n",
      "30945/30945 [==============================] - 53s 2ms/step - loss: 0.3140 - acc: 0.9575\n",
      "Epoch 8/20\n",
      "30945/30945 [==============================] - 53s 2ms/step - loss: 0.3124 - acc: 0.9516\n",
      "Epoch 9/20\n",
      "30945/30945 [==============================] - 53s 2ms/step - loss: 0.3095 - acc: 0.9497\n",
      "Epoch 10/20\n",
      "30945/30945 [==============================] - 53s 2ms/step - loss: 0.3070 - acc: 0.9446\n",
      "Epoch 11/20\n",
      "30945/30945 [==============================] - 53s 2ms/step - loss: 0.3059 - acc: 0.9419\n",
      "Epoch 12/20\n",
      "30945/30945 [==============================] - 52s 2ms/step - loss: 0.3029 - acc: 0.9387\n",
      "Epoch 13/20\n",
      "30945/30945 [==============================] - 54s 2ms/step - loss: 0.3012 - acc: 0.9348\n",
      "Epoch 14/20\n",
      "30945/30945 [==============================] - 54s 2ms/step - loss: 0.3024 - acc: 0.9336\n",
      "Epoch 15/20\n",
      "30945/30945 [==============================] - 52s 2ms/step - loss: 0.3002 - acc: 0.9276\n",
      "Epoch 16/20\n",
      "30945/30945 [==============================] - 53s 2ms/step - loss: 0.2979 - acc: 0.9207\n",
      "Epoch 17/20\n",
      "30945/30945 [==============================] - 53s 2ms/step - loss: 0.2977 - acc: 0.9200\n",
      "Epoch 18/20\n",
      "30945/30945 [==============================] - 52s 2ms/step - loss: 0.2955 - acc: 0.9156\n",
      "Epoch 19/20\n",
      "30945/30945 [==============================] - 53s 2ms/step - loss: 0.2949 - acc: 0.9162\n",
      "Epoch 20/20\n",
      "30945/30945 [==============================] - 52s 2ms/step - loss: 0.2945 - acc: 0.9137\n",
      "15473/15473 [==============================] - 14s 894us/step\n",
      "30945/30945 [==============================] - 24s 783us/step\n",
      "[CV] .................... epochs=20, lr=0.001, nodes=64, total=18.6min\n",
      "[CV] epochs=20, lr=0.001, nodes=64 ...................................\n",
      "Epoch 1/20\n",
      "30946/30946 [==============================] - 63s 2ms/step - loss: 0.3544 - acc: 0.9832\n",
      "Epoch 2/20\n",
      "30946/30946 [==============================] - 51s 2ms/step - loss: 0.3329 - acc: 0.9773\n",
      "Epoch 3/20\n",
      "30946/30946 [==============================] - 52s 2ms/step - loss: 0.3235 - acc: 0.9746\n",
      "Epoch 4/20\n",
      "30946/30946 [==============================] - 53s 2ms/step - loss: 0.3165 - acc: 0.9688\n",
      "Epoch 5/20\n",
      "30946/30946 [==============================] - 52s 2ms/step - loss: 0.3110 - acc: 0.9648\n",
      "Epoch 6/20\n",
      "30946/30946 [==============================] - 52s 2ms/step - loss: 0.3081 - acc: 0.9574\n",
      "Epoch 7/20\n",
      "30946/30946 [==============================] - 53s 2ms/step - loss: 0.3044 - acc: 0.9581\n",
      "Epoch 8/20\n",
      "30946/30946 [==============================] - 52s 2ms/step - loss: 0.3010 - acc: 0.9536\n",
      "Epoch 9/20\n",
      "30946/30946 [==============================] - 53s 2ms/step - loss: 0.2991 - acc: 0.9467\n",
      "Epoch 10/20\n",
      "30946/30946 [==============================] - 53s 2ms/step - loss: 0.2968 - acc: 0.9445\n",
      "Epoch 11/20\n",
      "30946/30946 [==============================] - 53s 2ms/step - loss: 0.2942 - acc: 0.9416\n",
      "Epoch 12/20\n",
      "30946/30946 [==============================] - 53s 2ms/step - loss: 0.2920 - acc: 0.9319\n",
      "Epoch 13/20\n",
      "30946/30946 [==============================] - 51s 2ms/step - loss: 0.2897 - acc: 0.9299\n",
      "Epoch 14/20\n",
      "30946/30946 [==============================] - 51s 2ms/step - loss: 0.2903 - acc: 0.9288\n",
      "Epoch 15/20\n",
      "30946/30946 [==============================] - 52s 2ms/step - loss: 0.2871 - acc: 0.9238\n",
      "Epoch 16/20\n",
      "30946/30946 [==============================] - 52s 2ms/step - loss: 0.2884 - acc: 0.9132\n",
      "Epoch 17/20\n",
      "30946/30946 [==============================] - 53s 2ms/step - loss: 0.2858 - acc: 0.9189\n",
      "Epoch 18/20\n",
      "30946/30946 [==============================] - 53s 2ms/step - loss: 0.2864 - acc: 0.9139\n",
      "Epoch 19/20\n",
      "30946/30946 [==============================] - 54s 2ms/step - loss: 0.2858 - acc: 0.9124\n",
      "Epoch 20/20\n",
      "30946/30946 [==============================] - 54s 2ms/step - loss: 0.2856 - acc: 0.9092\n",
      "15472/15472 [==============================] - 14s 893us/step\n",
      "30946/30946 [==============================] - 26s 840us/step\n",
      "[CV] .................... epochs=20, lr=0.001, nodes=64, total=18.4min\n",
      "[CV] epochs=20, lr=0.002, nodes=16 ...................................\n",
      "Epoch 1/20\n",
      "30945/30945 [==============================] - 34s 1ms/step - loss: 0.3594 - acc: 0.9672\n",
      "Epoch 2/20\n",
      "30945/30945 [==============================] - 22s 706us/step - loss: 0.3411 - acc: 0.9851\n",
      "Epoch 3/20\n",
      "30945/30945 [==============================] - 21s 693us/step - loss: 0.3360 - acc: 0.9817\n",
      "Epoch 4/20\n",
      "30945/30945 [==============================] - 22s 698us/step - loss: 0.3308 - acc: 0.9795\n",
      "Epoch 5/20\n",
      "30945/30945 [==============================] - 22s 696us/step - loss: 0.3287 - acc: 0.9748\n",
      "Epoch 6/20\n",
      "30945/30945 [==============================] - 22s 701us/step - loss: 0.3230 - acc: 0.9714\n",
      "Epoch 7/20\n",
      "30945/30945 [==============================] - 22s 698us/step - loss: 0.3230 - acc: 0.9661\n",
      "Epoch 8/20\n",
      "30945/30945 [==============================] - 22s 696us/step - loss: 0.3178 - acc: 0.9609\n",
      "Epoch 9/20\n",
      "30945/30945 [==============================] - 21s 684us/step - loss: 0.3162 - acc: 0.9599\n",
      "Epoch 10/20\n",
      "30945/30945 [==============================] - 22s 695us/step - loss: 0.3172 - acc: 0.9568\n",
      "Epoch 11/20\n",
      "30945/30945 [==============================] - 21s 679us/step - loss: 0.3138 - acc: 0.9507\n",
      "Epoch 12/20\n",
      "30945/30945 [==============================] - 21s 676us/step - loss: 0.3137 - acc: 0.9485\n",
      "Epoch 13/20\n",
      "30945/30945 [==============================] - 21s 682us/step - loss: 0.3117 - acc: 0.9425\n",
      "Epoch 14/20\n",
      "30945/30945 [==============================] - 21s 681us/step - loss: 0.3102 - acc: 0.9409\n",
      "Epoch 15/20\n",
      "30945/30945 [==============================] - 21s 680us/step - loss: 0.3100 - acc: 0.9397\n",
      "Epoch 16/20\n",
      "30945/30945 [==============================] - 21s 687us/step - loss: 0.3108 - acc: 0.9366\n",
      "Epoch 17/20\n",
      "30945/30945 [==============================] - 21s 686us/step - loss: 0.3088 - acc: 0.9373\n",
      "Epoch 18/20\n",
      "30945/30945 [==============================] - 21s 686us/step - loss: 0.3074 - acc: 0.9347\n",
      "Epoch 19/20\n",
      "30945/30945 [==============================] - 21s 691us/step - loss: 0.3052 - acc: 0.9261\n",
      "Epoch 20/20\n",
      "30945/30945 [==============================] - 21s 686us/step - loss: 0.3047 - acc: 0.9297\n",
      "15473/15473 [==============================] - 13s 838us/step\n",
      "30945/30945 [==============================] - 23s 729us/step\n",
      "[CV] .................... epochs=20, lr=0.002, nodes=16, total= 8.1min\n",
      "[CV] epochs=20, lr=0.002, nodes=16 ...................................\n",
      "Epoch 1/20\n",
      "30945/30945 [==============================] - 34s 1ms/step - loss: 0.3672 - acc: 0.9509\n",
      "Epoch 2/20\n",
      "30945/30945 [==============================] - 22s 699us/step - loss: 0.3481 - acc: 0.9826\n",
      "Epoch 3/20\n",
      "30945/30945 [==============================] - 21s 689us/step - loss: 0.3430 - acc: 0.9813\n",
      "Epoch 4/20\n",
      "30945/30945 [==============================] - 21s 665us/step - loss: 0.3405 - acc: 0.9780\n",
      "Epoch 5/20\n",
      "30945/30945 [==============================] - 20s 657us/step - loss: 0.3348 - acc: 0.9734\n",
      "Epoch 6/20\n",
      "30945/30945 [==============================] - 20s 660us/step - loss: 0.3332 - acc: 0.9697\n",
      "Epoch 7/20\n",
      "30945/30945 [==============================] - 21s 670us/step - loss: 0.3309 - acc: 0.9659\n",
      "Epoch 8/20\n",
      "30945/30945 [==============================] - 20s 660us/step - loss: 0.3285 - acc: 0.9650\n",
      "Epoch 9/20\n",
      "30945/30945 [==============================] - 21s 672us/step - loss: 0.3258 - acc: 0.9625\n",
      "Epoch 10/20\n",
      "30945/30945 [==============================] - 21s 684us/step - loss: 0.3252 - acc: 0.9596\n",
      "Epoch 11/20\n",
      "30945/30945 [==============================] - 21s 678us/step - loss: 0.3226 - acc: 0.9575\n",
      "Epoch 12/20\n",
      "30945/30945 [==============================] - 21s 673us/step - loss: 0.3249 - acc: 0.9529\n",
      "Epoch 13/20\n",
      "30945/30945 [==============================] - 20s 656us/step - loss: 0.3212 - acc: 0.9520\n",
      "Epoch 14/20\n",
      "30945/30945 [==============================] - 21s 678us/step - loss: 0.3186 - acc: 0.9450\n",
      "Epoch 15/20\n",
      "30945/30945 [==============================] - 21s 686us/step - loss: 0.3181 - acc: 0.9441\n",
      "Epoch 16/20\n",
      "30945/30945 [==============================] - 21s 682us/step - loss: 0.3164 - acc: 0.9430\n",
      "Epoch 17/20\n",
      "30945/30945 [==============================] - 21s 668us/step - loss: 0.3162 - acc: 0.9379\n",
      "Epoch 18/20\n",
      "30945/30945 [==============================] - 21s 691us/step - loss: 0.3165 - acc: 0.9360\n",
      "Epoch 19/20\n",
      "30945/30945 [==============================] - 21s 688us/step - loss: 0.3164 - acc: 0.9315\n",
      "Epoch 20/20\n",
      "30945/30945 [==============================] - 21s 681us/step - loss: 0.3149 - acc: 0.9350\n",
      "15473/15473 [==============================] - 13s 840us/step\n",
      "30945/30945 [==============================] - 23s 738us/step\n",
      "[CV] .................... epochs=20, lr=0.002, nodes=16, total= 8.0min\n",
      "[CV] epochs=20, lr=0.002, nodes=16 ...................................\n",
      "Epoch 1/20\n",
      "30946/30946 [==============================] - 34s 1ms/step - loss: 0.3571 - acc: 0.9702\n",
      "Epoch 2/20\n",
      "30946/30946 [==============================] - 21s 672us/step - loss: 0.3395 - acc: 0.9835\n",
      "Epoch 3/20\n",
      "30946/30946 [==============================] - 21s 690us/step - loss: 0.3312 - acc: 0.9802\n",
      "Epoch 4/20\n",
      "30946/30946 [==============================] - 21s 680us/step - loss: 0.3277 - acc: 0.9730\n",
      "Epoch 5/20\n",
      "30946/30946 [==============================] - 21s 667us/step - loss: 0.3232 - acc: 0.9709\n",
      "Epoch 6/20\n",
      "30946/30946 [==============================] - 21s 675us/step - loss: 0.3204 - acc: 0.9654\n",
      "Epoch 7/20\n",
      "30946/30946 [==============================] - 21s 681us/step - loss: 0.3185 - acc: 0.9610\n",
      "Epoch 8/20\n",
      "30946/30946 [==============================] - 21s 679us/step - loss: 0.3160 - acc: 0.9565\n",
      "Epoch 9/20\n",
      "30946/30946 [==============================] - 20s 657us/step - loss: 0.3140 - acc: 0.9511\n",
      "Epoch 10/20\n",
      "30946/30946 [==============================] - 21s 679us/step - loss: 0.3129 - acc: 0.9455\n",
      "Epoch 11/20\n",
      "30946/30946 [==============================] - 21s 681us/step - loss: 0.3111 - acc: 0.9455\n",
      "Epoch 12/20\n",
      "30946/30946 [==============================] - 21s 680us/step - loss: 0.3098 - acc: 0.9388\n",
      "Epoch 13/20\n",
      "30946/30946 [==============================] - 21s 684us/step - loss: 0.3106 - acc: 0.9344\n",
      "Epoch 14/20\n",
      "30946/30946 [==============================] - 21s 694us/step - loss: 0.3066 - acc: 0.9299\n",
      "Epoch 15/20\n",
      "30946/30946 [==============================] - 21s 687us/step - loss: 0.3071 - acc: 0.9290\n",
      "Epoch 16/20\n",
      "30946/30946 [==============================] - 21s 685us/step - loss: 0.3052 - acc: 0.9216\n",
      "Epoch 17/20\n",
      "30946/30946 [==============================] - 20s 646us/step - loss: 0.3047 - acc: 0.9182\n",
      "Epoch 18/20\n",
      "30946/30946 [==============================] - 21s 687us/step - loss: 0.3049 - acc: 0.9140\n",
      "Epoch 19/20\n",
      "30946/30946 [==============================] - 21s 685us/step - loss: 0.3036 - acc: 0.9122\n",
      "Epoch 20/20\n",
      "30946/30946 [==============================] - 21s 679us/step - loss: 0.3025 - acc: 0.9049\n",
      "15472/15472 [==============================] - 13s 828us/step\n",
      "30946/30946 [==============================] - 23s 733us/step\n",
      "[CV] .................... epochs=20, lr=0.002, nodes=16, total= 8.0min\n",
      "[CV] epochs=20, lr=0.002, nodes=32 ...................................\n",
      "Epoch 1/20\n",
      "30945/30945 [==============================] - 43s 1ms/step - loss: 0.3528 - acc: 0.9804\n",
      "Epoch 2/20\n",
      "30945/30945 [==============================] - 31s 1ms/step - loss: 0.3365 - acc: 0.9792\n",
      "Epoch 3/20\n",
      "30945/30945 [==============================] - 30s 966us/step - loss: 0.3264 - acc: 0.9744\n",
      "Epoch 4/20\n",
      "30945/30945 [==============================] - 31s 990us/step - loss: 0.3232 - acc: 0.9688\n",
      "Epoch 5/20\n",
      "30945/30945 [==============================] - 30s 985us/step - loss: 0.3184 - acc: 0.9659\n",
      "Epoch 6/20\n",
      "30945/30945 [==============================] - 29s 948us/step - loss: 0.3144 - acc: 0.9604\n",
      "Epoch 7/20\n",
      "30945/30945 [==============================] - 31s 999us/step - loss: 0.3109 - acc: 0.9595\n",
      "Epoch 8/20\n",
      "30945/30945 [==============================] - 31s 993us/step - loss: 0.3077 - acc: 0.9542\n",
      "Epoch 9/20\n",
      "30945/30945 [==============================] - 31s 995us/step - loss: 0.3071 - acc: 0.9518\n",
      "Epoch 10/20\n",
      "30945/30945 [==============================] - 31s 1ms/step - loss: 0.3040 - acc: 0.9461\n",
      "Epoch 11/20\n",
      "30945/30945 [==============================] - 31s 1ms/step - loss: 0.3020 - acc: 0.9487\n",
      "Epoch 12/20\n",
      "30945/30945 [==============================] - 32s 1ms/step - loss: 0.3014 - acc: 0.9375\n",
      "Epoch 13/20\n",
      "30945/30945 [==============================] - 32s 1ms/step - loss: 0.2996 - acc: 0.9397\n",
      "Epoch 14/20\n",
      "30945/30945 [==============================] - 32s 1ms/step - loss: 0.2984 - acc: 0.9368\n",
      "Epoch 15/20\n",
      "30945/30945 [==============================] - 31s 1ms/step - loss: 0.2987 - acc: 0.9311\n",
      "Epoch 16/20\n",
      "30945/30945 [==============================] - 32s 1ms/step - loss: 0.2975 - acc: 0.9299\n",
      "Epoch 17/20\n",
      "30945/30945 [==============================] - 32s 1ms/step - loss: 0.2964 - acc: 0.9249\n",
      "Epoch 18/20\n",
      "30945/30945 [==============================] - 32s 1ms/step - loss: 0.2976 - acc: 0.9211\n",
      "Epoch 19/20\n",
      "30945/30945 [==============================] - 32s 1ms/step - loss: 0.2973 - acc: 0.9191\n",
      "Epoch 20/20\n",
      "30945/30945 [==============================] - 31s 1ms/step - loss: 0.2967 - acc: 0.9159\n",
      "15473/15473 [==============================] - 14s 896us/step\n",
      "30945/30945 [==============================] - 23s 729us/step\n",
      "[CV] .................... epochs=20, lr=0.002, nodes=32, total=11.4min\n",
      "[CV] epochs=20, lr=0.002, nodes=32 ...................................\n",
      "Epoch 1/20\n",
      "30945/30945 [==============================] - 46s 1ms/step - loss: 0.3656 - acc: 0.9688\n",
      "Epoch 2/20\n",
      "30945/30945 [==============================] - 32s 1ms/step - loss: 0.3438 - acc: 0.9777\n",
      "Epoch 3/20\n",
      "30945/30945 [==============================] - 32s 1ms/step - loss: 0.3363 - acc: 0.9764\n",
      "Epoch 4/20\n",
      "30945/30945 [==============================] - 30s 973us/step - loss: 0.3315 - acc: 0.9715\n",
      "Epoch 5/20\n",
      "30945/30945 [==============================] - 31s 1ms/step - loss: 0.3279 - acc: 0.9696\n",
      "Epoch 6/20\n",
      "30945/30945 [==============================] - 31s 1ms/step - loss: 0.3245 - acc: 0.9656\n",
      "Epoch 7/20\n",
      "30945/30945 [==============================] - 31s 1ms/step - loss: 0.3227 - acc: 0.9587\n",
      "Epoch 8/20\n",
      "30945/30945 [==============================] - 31s 1ms/step - loss: 0.3189 - acc: 0.9554\n",
      "Epoch 9/20\n",
      "30945/30945 [==============================] - 31s 1ms/step - loss: 0.3169 - acc: 0.9503\n",
      "Epoch 10/20\n",
      "30945/30945 [==============================] - 31s 1ms/step - loss: 0.3156 - acc: 0.9457\n",
      "Epoch 11/20\n",
      "30945/30945 [==============================] - 31s 999us/step - loss: 0.3128 - acc: 0.9464\n",
      "Epoch 12/20\n",
      "30945/30945 [==============================] - 31s 1ms/step - loss: 0.3105 - acc: 0.9400\n",
      "Epoch 13/20\n",
      "30945/30945 [==============================] - 31s 1ms/step - loss: 0.3126 - acc: 0.9436\n",
      "Epoch 14/20\n",
      "30945/30945 [==============================] - 31s 1ms/step - loss: 0.3083 - acc: 0.9399\n",
      "Epoch 15/20\n",
      "30945/30945 [==============================] - 31s 1ms/step - loss: 0.3093 - acc: 0.9386\n",
      "Epoch 16/20\n",
      "30945/30945 [==============================] - 31s 1ms/step - loss: 0.3081 - acc: 0.9327\n",
      "Epoch 17/20\n",
      "30945/30945 [==============================] - 31s 1ms/step - loss: 0.3082 - acc: 0.9227\n",
      "Epoch 18/20\n",
      "30945/30945 [==============================] - 31s 1ms/step - loss: 0.3078 - acc: 0.9256\n",
      "Epoch 19/20\n",
      "30945/30945 [==============================] - 32s 1ms/step - loss: 0.3070 - acc: 0.9206\n",
      "Epoch 20/20\n",
      "30945/30945 [==============================] - 32s 1ms/step - loss: 0.3073 - acc: 0.9175\n",
      "15473/15473 [==============================] - 14s 889us/step\n",
      "30945/30945 [==============================] - 23s 735us/step\n",
      "[CV] .................... epochs=20, lr=0.002, nodes=32, total=11.5min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] epochs=20, lr=0.002, nodes=32 ...................................\n",
      "Epoch 1/20\n",
      "30946/30946 [==============================] - 46s 1ms/step - loss: 0.3526 - acc: 0.9826\n",
      "Epoch 2/20\n",
      "30946/30946 [==============================] - 32s 1ms/step - loss: 0.3335 - acc: 0.9775\n",
      "Epoch 3/20\n",
      "30946/30946 [==============================] - 31s 990us/step - loss: 0.3248 - acc: 0.9709\n",
      "Epoch 4/20\n",
      "30946/30946 [==============================] - 31s 994us/step - loss: 0.3187 - acc: 0.9674\n",
      "Epoch 5/20\n",
      "30946/30946 [==============================] - 31s 996us/step - loss: 0.3153 - acc: 0.9621\n",
      "Epoch 6/20\n",
      "30946/30946 [==============================] - 31s 1ms/step - loss: 0.3110 - acc: 0.9586\n",
      "Epoch 7/20\n",
      "30946/30946 [==============================] - 31s 1ms/step - loss: 0.3083 - acc: 0.9551\n",
      "Epoch 8/20\n",
      "30946/30946 [==============================] - 29s 951us/step - loss: 0.3062 - acc: 0.9510\n",
      "Epoch 9/20\n",
      "30946/30946 [==============================] - 31s 998us/step - loss: 0.3034 - acc: 0.9460\n",
      "Epoch 10/20\n",
      "30946/30946 [==============================] - 31s 1ms/step - loss: 0.3019 - acc: 0.9436\n",
      "Epoch 11/20\n",
      "30946/30946 [==============================] - 31s 1ms/step - loss: 0.3016 - acc: 0.9416\n",
      "Epoch 12/20\n",
      "30946/30946 [==============================] - 31s 1ms/step - loss: 0.3015 - acc: 0.9366\n",
      "Epoch 13/20\n",
      "30946/30946 [==============================] - 29s 953us/step - loss: 0.2988 - acc: 0.9309\n",
      "Epoch 14/20\n",
      "30946/30946 [==============================] - 31s 1ms/step - loss: 0.2976 - acc: 0.9307\n",
      "Epoch 15/20\n",
      "30946/30946 [==============================] - 31s 1ms/step - loss: 0.2963 - acc: 0.9247\n",
      "Epoch 16/20\n",
      "30946/30946 [==============================] - 31s 1ms/step - loss: 0.2983 - acc: 0.9230\n",
      "Epoch 17/20\n",
      "30946/30946 [==============================] - 30s 964us/step - loss: 0.2968 - acc: 0.9213\n",
      "Epoch 18/20\n",
      "30946/30946 [==============================] - 31s 1ms/step - loss: 0.2947 - acc: 0.9176\n",
      "Epoch 19/20\n",
      "30946/30946 [==============================] - 31s 1ms/step - loss: 0.2955 - acc: 0.9144\n",
      "Epoch 20/20\n",
      "30946/30946 [==============================] - 31s 1ms/step - loss: 0.2964 - acc: 0.9118\n",
      "15472/15472 [==============================] - 14s 891us/step\n",
      "30946/30946 [==============================] - 22s 715us/step\n",
      "[CV] .................... epochs=20, lr=0.002, nodes=32, total=11.3min\n",
      "[CV] epochs=20, lr=0.002, nodes=64 ...................................\n",
      "Epoch 1/20\n",
      "30945/30945 [==============================] - 66s 2ms/step - loss: 0.3503 - acc: 0.9808\n",
      "Epoch 2/20\n",
      "30945/30945 [==============================] - 54s 2ms/step - loss: 0.3307 - acc: 0.9710\n",
      "Epoch 3/20\n",
      "30945/30945 [==============================] - 54s 2ms/step - loss: 0.3183 - acc: 0.9673\n",
      "Epoch 4/20\n",
      "30945/30945 [==============================] - 54s 2ms/step - loss: 0.3126 - acc: 0.9632\n",
      "Epoch 5/20\n",
      "30945/30945 [==============================] - 54s 2ms/step - loss: 0.3076 - acc: 0.9584\n",
      "Epoch 6/20\n",
      "30945/30945 [==============================] - 56s 2ms/step - loss: 0.3030 - acc: 0.9526\n",
      "Epoch 7/20\n",
      "30945/30945 [==============================] - 57s 2ms/step - loss: 0.3022 - acc: 0.9461\n",
      "Epoch 8/20\n",
      "30945/30945 [==============================] - 54s 2ms/step - loss: 0.2989 - acc: 0.9391\n",
      "Epoch 9/20\n",
      "30945/30945 [==============================] - 54s 2ms/step - loss: 0.2962 - acc: 0.9285\n",
      "Epoch 10/20\n",
      "30945/30945 [==============================] - 54s 2ms/step - loss: 0.2947 - acc: 0.9281\n",
      "Epoch 11/20\n",
      "30945/30945 [==============================] - 54s 2ms/step - loss: 0.2943 - acc: 0.9251\n",
      "Epoch 12/20\n",
      "30945/30945 [==============================] - 54s 2ms/step - loss: 0.2941 - acc: 0.9225\n",
      "Epoch 13/20\n",
      "30945/30945 [==============================] - 54s 2ms/step - loss: 0.2941 - acc: 0.9104\n",
      "Epoch 14/20\n",
      "30945/30945 [==============================] - 53s 2ms/step - loss: 0.2932 - acc: 0.9192\n",
      "Epoch 15/20\n",
      "30945/30945 [==============================] - 54s 2ms/step - loss: 0.2920 - acc: 0.9054\n",
      "Epoch 16/20\n",
      "30945/30945 [==============================] - 54s 2ms/step - loss: 0.2942 - acc: 0.9048\n",
      "Epoch 17/20\n",
      "30945/30945 [==============================] - 53s 2ms/step - loss: 0.2938 - acc: 0.9031\n",
      "Epoch 18/20\n",
      "30945/30945 [==============================] - 53s 2ms/step - loss: 0.2954 - acc: 0.8965\n",
      "Epoch 19/20\n",
      "30945/30945 [==============================] - 55s 2ms/step - loss: 0.2935 - acc: 0.8966\n",
      "Epoch 20/20\n",
      "30945/30945 [==============================] - 55s 2ms/step - loss: 0.2947 - acc: 0.8883\n",
      "15473/15473 [==============================] - 15s 990us/step\n",
      "30945/30945 [==============================] - 26s 841us/step\n",
      "[CV] .................... epochs=20, lr=0.002, nodes=64, total=19.1min\n",
      "[CV] epochs=20, lr=0.002, nodes=64 ...................................\n",
      "Epoch 1/20\n",
      "30945/30945 [==============================] - 64s 2ms/step - loss: 0.3619 - acc: 0.9792\n",
      "Epoch 2/20\n",
      "30945/30945 [==============================] - 53s 2ms/step - loss: 0.3417 - acc: 0.9735\n",
      "Epoch 3/20\n",
      "30945/30945 [==============================] - 52s 2ms/step - loss: 0.3320 - acc: 0.9696\n",
      "Epoch 4/20\n",
      "30945/30945 [==============================] - 52s 2ms/step - loss: 0.3245 - acc: 0.9659\n",
      "Epoch 5/20\n",
      "30945/30945 [==============================] - 52s 2ms/step - loss: 0.3203 - acc: 0.9582\n",
      "Epoch 6/20\n",
      "30945/30945 [==============================] - 53s 2ms/step - loss: 0.3147 - acc: 0.9580\n",
      "Epoch 7/20\n",
      "30945/30945 [==============================] - 52s 2ms/step - loss: 0.3127 - acc: 0.9508\n",
      "Epoch 8/20\n",
      "30945/30945 [==============================] - 53s 2ms/step - loss: 0.3089 - acc: 0.9429\n",
      "Epoch 9/20\n",
      "30945/30945 [==============================] - 52s 2ms/step - loss: 0.3069 - acc: 0.9376\n",
      "Epoch 10/20\n",
      "30945/30945 [==============================] - 53s 2ms/step - loss: 0.3068 - acc: 0.9350\n",
      "Epoch 11/20\n",
      "30945/30945 [==============================] - 53s 2ms/step - loss: 0.3058 - acc: 0.9329\n",
      "Epoch 12/20\n",
      "30945/30945 [==============================] - 53s 2ms/step - loss: 0.3046 - acc: 0.9270\n",
      "Epoch 13/20\n",
      "30945/30945 [==============================] - 53s 2ms/step - loss: 0.3044 - acc: 0.9193\n",
      "Epoch 14/20\n",
      "30945/30945 [==============================] - 52s 2ms/step - loss: 0.3036 - acc: 0.9152\n",
      "Epoch 15/20\n",
      "30945/30945 [==============================] - 51s 2ms/step - loss: 0.3032 - acc: 0.9140\n",
      "Epoch 16/20\n",
      "30945/30945 [==============================] - 52s 2ms/step - loss: 0.3036 - acc: 0.9099\n",
      "Epoch 17/20\n",
      "30945/30945 [==============================] - 53s 2ms/step - loss: 0.3060 - acc: 0.8989\n",
      "Epoch 18/20\n",
      "30945/30945 [==============================] - 53s 2ms/step - loss: 0.3024 - acc: 0.9024\n",
      "Epoch 19/20\n",
      "30945/30945 [==============================] - 51s 2ms/step - loss: 0.3062 - acc: 0.8947\n",
      "Epoch 20/20\n",
      "30945/30945 [==============================] - 53s 2ms/step - loss: 0.3020 - acc: 0.8902\n",
      "15473/15473 [==============================] - 14s 906us/step\n",
      "30945/30945 [==============================] - 24s 784us/step\n",
      "[CV] .................... epochs=20, lr=0.002, nodes=64, total=18.4min\n",
      "[CV] epochs=20, lr=0.002, nodes=64 ...................................\n",
      "Epoch 1/20\n",
      "30946/30946 [==============================] - 65s 2ms/step - loss: 0.3505 - acc: 0.9804\n",
      "Epoch 2/20\n",
      "30946/30946 [==============================] - 54s 2ms/step - loss: 0.3302 - acc: 0.9772\n",
      "Epoch 3/20\n",
      "30946/30946 [==============================] - 53s 2ms/step - loss: 0.3214 - acc: 0.9717\n",
      "Epoch 4/20\n",
      "30946/30946 [==============================] - 54s 2ms/step - loss: 0.3159 - acc: 0.9665\n",
      "Epoch 5/20\n",
      "30946/30946 [==============================] - 53s 2ms/step - loss: 0.3130 - acc: 0.9604\n",
      "Epoch 6/20\n",
      "30946/30946 [==============================] - 53s 2ms/step - loss: 0.3072 - acc: 0.9569\n",
      "Epoch 7/20\n",
      "30946/30946 [==============================] - 53s 2ms/step - loss: 0.3025 - acc: 0.9511\n",
      "Epoch 8/20\n",
      "30946/30946 [==============================] - 53s 2ms/step - loss: 0.3008 - acc: 0.9466\n",
      "Epoch 9/20\n",
      "30946/30946 [==============================] - 54s 2ms/step - loss: 0.2992 - acc: 0.9412\n",
      "Epoch 10/20\n",
      "30946/30946 [==============================] - 53s 2ms/step - loss: 0.2965 - acc: 0.9361\n",
      "Epoch 11/20\n",
      "30946/30946 [==============================] - 53s 2ms/step - loss: 0.2962 - acc: 0.9309\n",
      "Epoch 12/20\n",
      "30946/30946 [==============================] - 53s 2ms/step - loss: 0.2947 - acc: 0.9266\n",
      "Epoch 13/20\n",
      "30946/30946 [==============================] - 53s 2ms/step - loss: 0.2929 - acc: 0.9225\n",
      "Epoch 14/20\n",
      "30946/30946 [==============================] - 52s 2ms/step - loss: 0.2917 - acc: 0.9181\n",
      "Epoch 15/20\n",
      "30946/30946 [==============================] - 53s 2ms/step - loss: 0.2920 - acc: 0.9129\n",
      "Epoch 16/20\n",
      "30946/30946 [==============================] - 50s 2ms/step - loss: 0.2927 - acc: 0.9125\n",
      "Epoch 17/20\n",
      "30946/30946 [==============================] - 52s 2ms/step - loss: 0.2923 - acc: 0.9028\n",
      "Epoch 18/20\n",
      "30946/30946 [==============================] - 52s 2ms/step - loss: 0.2917 - acc: 0.9020\n",
      "Epoch 19/20\n",
      "30946/30946 [==============================] - 53s 2ms/step - loss: 0.2927 - acc: 0.8999\n",
      "Epoch 20/20\n",
      "30946/30946 [==============================] - 53s 2ms/step - loss: 0.2910 - acc: 0.8946\n",
      "15472/15472 [==============================] - 14s 901us/step\n",
      "30946/30946 [==============================] - 26s 846us/step\n",
      "[CV] .................... epochs=20, lr=0.002, nodes=64, total=18.6min\n",
      "[CV] epochs=20, lr=0.003, nodes=16 ...................................\n",
      "Epoch 1/20\n",
      "30945/30945 [==============================] - 34s 1ms/step - loss: 0.3534 - acc: 0.9817\n",
      "Epoch 2/20\n",
      "30945/30945 [==============================] - 21s 687us/step - loss: 0.3372 - acc: 0.9798\n",
      "Epoch 3/20\n",
      "30945/30945 [==============================] - 21s 678us/step - loss: 0.3309 - acc: 0.9734\n",
      "Epoch 4/20\n",
      "30945/30945 [==============================] - 21s 674us/step - loss: 0.3255 - acc: 0.9716\n",
      "Epoch 5/20\n",
      "30945/30945 [==============================] - 21s 695us/step - loss: 0.3237 - acc: 0.9637\n",
      "Epoch 6/20\n",
      "30945/30945 [==============================] - 21s 694us/step - loss: 0.3204 - acc: 0.9613\n",
      "Epoch 7/20\n",
      "30945/30945 [==============================] - 21s 680us/step - loss: 0.3178 - acc: 0.9557\n",
      "Epoch 8/20\n",
      "30945/30945 [==============================] - 21s 693us/step - loss: 0.3157 - acc: 0.9505\n",
      "Epoch 9/20\n",
      "30945/30945 [==============================] - 21s 694us/step - loss: 0.3148 - acc: 0.9496\n",
      "Epoch 10/20\n",
      "30945/30945 [==============================] - 21s 688us/step - loss: 0.3136 - acc: 0.9396\n",
      "Epoch 11/20\n",
      "30945/30945 [==============================] - 21s 663us/step - loss: 0.3129 - acc: 0.9343\n",
      "Epoch 12/20\n",
      "30945/30945 [==============================] - 20s 660us/step - loss: 0.3111 - acc: 0.9279\n",
      "Epoch 13/20\n",
      "30945/30945 [==============================] - 20s 660us/step - loss: 0.3107 - acc: 0.9298\n",
      "Epoch 14/20\n",
      "30945/30945 [==============================] - 20s 652us/step - loss: 0.3093 - acc: 0.9271\n",
      "Epoch 15/20\n",
      "30945/30945 [==============================] - 21s 668us/step - loss: 0.3113 - acc: 0.9260\n",
      "Epoch 16/20\n",
      "30945/30945 [==============================] - 20s 662us/step - loss: 0.3103 - acc: 0.9202\n",
      "Epoch 17/20\n",
      "30945/30945 [==============================] - 21s 684us/step - loss: 0.3081 - acc: 0.9163\n",
      "Epoch 18/20\n",
      "30945/30945 [==============================] - 21s 682us/step - loss: 0.3107 - acc: 0.9155\n",
      "Epoch 19/20\n",
      "30945/30945 [==============================] - 21s 672us/step - loss: 0.3118 - acc: 0.9152\n",
      "Epoch 20/20\n",
      "30945/30945 [==============================] - 21s 672us/step - loss: 0.3101 - acc: 0.9093\n",
      "15473/15473 [==============================] - 13s 844us/step\n",
      "30945/30945 [==============================] - 23s 730us/step\n",
      "[CV] .................... epochs=20, lr=0.003, nodes=16, total= 8.0min\n",
      "[CV] epochs=20, lr=0.003, nodes=16 ...................................\n",
      "Epoch 1/20\n",
      "30945/30945 [==============================] - 34s 1ms/step - loss: 0.3641 - acc: 0.9802\n",
      "Epoch 2/20\n",
      "30945/30945 [==============================] - 22s 711us/step - loss: 0.3487 - acc: 0.9794\n",
      "Epoch 3/20\n",
      "30945/30945 [==============================] - 22s 702us/step - loss: 0.3433 - acc: 0.9722\n",
      "Epoch 4/20\n",
      "30945/30945 [==============================] - 22s 706us/step - loss: 0.3376 - acc: 0.9664\n",
      "Epoch 5/20\n",
      "30945/30945 [==============================] - 22s 709us/step - loss: 0.3380 - acc: 0.9650\n",
      "Epoch 6/20\n",
      "30945/30945 [==============================] - 22s 709us/step - loss: 0.3356 - acc: 0.9593\n",
      "Epoch 7/20\n",
      "30945/30945 [==============================] - 22s 708us/step - loss: 0.3316 - acc: 0.9510\n",
      "Epoch 8/20\n",
      "30945/30945 [==============================] - 22s 708us/step - loss: 0.3305 - acc: 0.9474\n",
      "Epoch 9/20\n",
      "30945/30945 [==============================] - 21s 691us/step - loss: 0.3295 - acc: 0.9500\n",
      "Epoch 10/20\n",
      "30945/30945 [==============================] - 21s 685us/step - loss: 0.3283 - acc: 0.9435\n",
      "Epoch 11/20\n",
      "30945/30945 [==============================] - 21s 688us/step - loss: 0.3271 - acc: 0.9394\n",
      "Epoch 12/20\n",
      "30945/30945 [==============================] - 22s 695us/step - loss: 0.3243 - acc: 0.9380\n",
      "Epoch 13/20\n",
      "30945/30945 [==============================] - 22s 696us/step - loss: 0.3233 - acc: 0.9388\n",
      "Epoch 14/20\n",
      "30945/30945 [==============================] - 21s 678us/step - loss: 0.3234 - acc: 0.9340\n",
      "Epoch 15/20\n",
      "30945/30945 [==============================] - 22s 707us/step - loss: 0.3217 - acc: 0.9300\n",
      "Epoch 16/20\n",
      "30945/30945 [==============================] - 22s 702us/step - loss: 0.3224 - acc: 0.9288\n",
      "Epoch 17/20\n",
      "30945/30945 [==============================] - 22s 695us/step - loss: 0.3223 - acc: 0.9208\n",
      "Epoch 18/20\n",
      "30945/30945 [==============================] - 21s 680us/step - loss: 0.3230 - acc: 0.9204\n",
      "Epoch 19/20\n",
      "30945/30945 [==============================] - 22s 709us/step - loss: 0.3205 - acc: 0.9201\n",
      "Epoch 20/20\n",
      "30945/30945 [==============================] - 22s 707us/step - loss: 0.3243 - acc: 0.9182\n",
      "15473/15473 [==============================] - 13s 870us/step\n",
      "30945/30945 [==============================] - 23s 737us/step\n",
      "[CV] .................... epochs=20, lr=0.003, nodes=16, total= 8.2min\n",
      "[CV] epochs=20, lr=0.003, nodes=16 ...................................\n",
      "Epoch 1/20\n",
      "30946/30946 [==============================] - 34s 1ms/step - loss: 0.3552 - acc: 0.9835\n",
      "Epoch 2/20\n",
      "30946/30946 [==============================] - 22s 699us/step - loss: 0.3387 - acc: 0.9815\n",
      "Epoch 3/20\n",
      "30946/30946 [==============================] - 21s 686us/step - loss: 0.3324 - acc: 0.9777\n",
      "Epoch 4/20\n",
      "30946/30946 [==============================] - 21s 686us/step - loss: 0.3275 - acc: 0.9735\n",
      "Epoch 5/20\n",
      "30946/30946 [==============================] - 21s 687us/step - loss: 0.3254 - acc: 0.9686\n",
      "Epoch 6/20\n",
      "30946/30946 [==============================] - 21s 684us/step - loss: 0.3241 - acc: 0.9659\n",
      "Epoch 7/20\n",
      "30946/30946 [==============================] - 21s 679us/step - loss: 0.3196 - acc: 0.9592\n",
      "Epoch 8/20\n",
      "30946/30946 [==============================] - 22s 701us/step - loss: 0.3198 - acc: 0.9534\n",
      "Epoch 9/20\n",
      "30946/30946 [==============================] - 21s 689us/step - loss: 0.3169 - acc: 0.9469\n",
      "Epoch 10/20\n",
      "30946/30946 [==============================] - 21s 688us/step - loss: 0.3169 - acc: 0.9497\n",
      "Epoch 11/20\n",
      "30946/30946 [==============================] - 21s 689us/step - loss: 0.3141 - acc: 0.9455\n",
      "Epoch 12/20\n",
      "30946/30946 [==============================] - 21s 689us/step - loss: 0.3123 - acc: 0.9409\n",
      "Epoch 13/20\n",
      "30946/30946 [==============================] - 21s 689us/step - loss: 0.3147 - acc: 0.9307\n",
      "Epoch 14/20\n",
      "30946/30946 [==============================] - 21s 683us/step - loss: 0.3131 - acc: 0.9316\n",
      "Epoch 15/20\n",
      "30946/30946 [==============================] - 21s 681us/step - loss: 0.3107 - acc: 0.9282\n",
      "Epoch 16/20\n",
      "30946/30946 [==============================] - 21s 679us/step - loss: 0.3119 - acc: 0.9304\n",
      "Epoch 17/20\n",
      "30946/30946 [==============================] - 21s 675us/step - loss: 0.3098 - acc: 0.9249\n",
      "Epoch 18/20\n",
      "30946/30946 [==============================] - 21s 691us/step - loss: 0.3087 - acc: 0.9205\n",
      "Epoch 19/20\n",
      "30946/30946 [==============================] - 21s 689us/step - loss: 0.3105 - acc: 0.9190\n",
      "Epoch 20/20\n",
      "30946/30946 [==============================] - 21s 689us/step - loss: 0.3064 - acc: 0.9067\n",
      "15472/15472 [==============================] - 13s 851us/step\n",
      "30946/30946 [==============================] - 23s 738us/step\n",
      "[CV] .................... epochs=20, lr=0.003, nodes=16, total= 8.1min\n",
      "[CV] epochs=20, lr=0.003, nodes=32 ...................................\n",
      "Epoch 1/20\n",
      "30945/30945 [==============================] - 43s 1ms/step - loss: 0.3514 - acc: 0.9831\n",
      "Epoch 2/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30945/30945 [==============================] - 31s 1ms/step - loss: 0.3359 - acc: 0.9762\n",
      "Epoch 3/20\n",
      "30945/30945 [==============================] - 31s 1ms/step - loss: 0.3267 - acc: 0.9721\n",
      "Epoch 4/20\n",
      "30945/30945 [==============================] - ETA: 0s - loss: 0.3212 - acc: 0.967 - 31s 1ms/step - loss: 0.3217 - acc: 0.9674\n",
      "Epoch 5/20\n",
      "30945/30945 [==============================] - 31s 1ms/step - loss: 0.3176 - acc: 0.9609\n",
      "Epoch 6/20\n",
      "30945/30945 [==============================] - 31s 1ms/step - loss: 0.3143 - acc: 0.9580\n",
      "Epoch 7/20\n",
      "30945/30945 [==============================] - 31s 1ms/step - loss: 0.3125 - acc: 0.9501\n",
      "Epoch 8/20\n",
      "30945/30945 [==============================] - 31s 1ms/step - loss: 0.3081 - acc: 0.9483\n",
      "Epoch 9/20\n",
      "30945/30945 [==============================] - 31s 1ms/step - loss: 0.3064 - acc: 0.9406\n",
      "Epoch 10/20\n",
      "30945/30945 [==============================] - 31s 1ms/step - loss: 0.3067 - acc: 0.9411\n",
      "Epoch 11/20\n",
      "30945/30945 [==============================] - 32s 1ms/step - loss: 0.3052 - acc: 0.9363\n",
      "Epoch 12/20\n",
      "30945/30945 [==============================] - 32s 1ms/step - loss: 0.3056 - acc: 0.9281\n",
      "Epoch 13/20\n",
      "30945/30945 [==============================] - 32s 1ms/step - loss: 0.3050 - acc: 0.9277\n",
      "Epoch 14/20\n",
      "30945/30945 [==============================] - 32s 1ms/step - loss: 0.3028 - acc: 0.9243\n",
      "Epoch 15/20\n",
      "30945/30945 [==============================] - 32s 1ms/step - loss: 0.3017 - acc: 0.9189\n",
      "Epoch 16/20\n",
      "30945/30945 [==============================] - 32s 1ms/step - loss: 0.3015 - acc: 0.9198\n",
      "Epoch 17/20\n",
      "30945/30945 [==============================] - 32s 1ms/step - loss: 0.3017 - acc: 0.9129\n",
      "Epoch 18/20\n",
      "30945/30945 [==============================] - 30s 958us/step - loss: 0.3032 - acc: 0.9100\n",
      "Epoch 19/20\n",
      "30945/30945 [==============================] - 32s 1ms/step - loss: 0.3028 - acc: 0.9031\n",
      "Epoch 20/20\n",
      "30945/30945 [==============================] - 32s 1ms/step - loss: 0.2995 - acc: 0.9008\n",
      "15473/15473 [==============================] - 14s 889us/step\n",
      "30945/30945 [==============================] - 22s 724us/step\n",
      "[CV] .................... epochs=20, lr=0.003, nodes=32, total=11.5min\n",
      "[CV] epochs=20, lr=0.003, nodes=32 ...................................\n",
      "Epoch 1/20\n",
      "30945/30945 [==============================] - 46s 1ms/step - loss: 0.3612 - acc: 0.9805\n",
      "Epoch 2/20\n",
      "30945/30945 [==============================] - 32s 1ms/step - loss: 0.3440 - acc: 0.9782\n",
      "Epoch 3/20\n",
      "30945/30945 [==============================] - 31s 1ms/step - loss: 0.3364 - acc: 0.9723\n",
      "Epoch 4/20\n",
      "30945/30945 [==============================] - 31s 988us/step - loss: 0.3318 - acc: 0.9677\n",
      "Epoch 5/20\n",
      "30945/30945 [==============================] - 31s 1ms/step - loss: 0.3265 - acc: 0.9628\n",
      "Epoch 6/20\n",
      "30945/30945 [==============================] - 31s 1ms/step - loss: 0.3235 - acc: 0.9592\n",
      "Epoch 7/20\n",
      "30945/30945 [==============================] - 31s 1ms/step - loss: 0.3213 - acc: 0.9491\n",
      "Epoch 8/20\n",
      "30945/30945 [==============================] - 31s 1ms/step - loss: 0.3185 - acc: 0.9408\n",
      "Epoch 9/20\n",
      "30945/30945 [==============================] - 31s 1ms/step - loss: 0.3181 - acc: 0.9402\n",
      "Epoch 10/20\n",
      "30945/30945 [==============================] - 31s 1ms/step - loss: 0.3163 - acc: 0.9360\n",
      "Epoch 11/20\n",
      "30945/30945 [==============================] - 31s 1ms/step - loss: 0.3157 - acc: 0.9301\n",
      "Epoch 12/20\n",
      "30945/30945 [==============================] - 31s 1ms/step - loss: 0.3141 - acc: 0.9258\n",
      "Epoch 13/20\n",
      "30945/30945 [==============================] - 31s 1ms/step - loss: 0.3154 - acc: 0.9197\n",
      "Epoch 14/20\n",
      "30945/30945 [==============================] - 31s 1ms/step - loss: 0.3123 - acc: 0.9160\n",
      "Epoch 15/20\n",
      "30945/30945 [==============================] - 31s 1ms/step - loss: 0.3141 - acc: 0.9131\n",
      "Epoch 16/20\n",
      "30945/30945 [==============================] - 31s 1ms/step - loss: 0.3128 - acc: 0.9051\n",
      "Epoch 17/20\n",
      "30945/30945 [==============================] - 31s 1ms/step - loss: 0.3115 - acc: 0.9013\n",
      "Epoch 18/20\n",
      "30945/30945 [==============================] - 31s 1ms/step - loss: 0.3103 - acc: 0.9000\n",
      "Epoch 19/20\n",
      "30945/30945 [==============================] - 27s 868us/step - loss: 0.3139 - acc: 0.8929\n",
      "Epoch 20/20\n",
      "30945/30945 [==============================] - 31s 1ms/step - loss: 0.3120 - acc: 0.8971\n",
      "15473/15473 [==============================] - 14s 905us/step\n",
      "30945/30945 [==============================] - 24s 782us/step\n",
      "[CV] .................... epochs=20, lr=0.003, nodes=32, total=11.4min\n",
      "[CV] epochs=20, lr=0.003, nodes=32 ...................................\n",
      "Epoch 1/20\n",
      "30946/30946 [==============================] - 43s 1ms/step - loss: 0.3532 - acc: 0.9820\n",
      "Epoch 2/20\n",
      "30946/30946 [==============================] - 31s 1ms/step - loss: 0.3339 - acc: 0.9769\n",
      "Epoch 3/20\n",
      "30946/30946 [==============================] - 31s 1ms/step - loss: 0.3254 - acc: 0.9724\n",
      "Epoch 4/20\n",
      "30946/30946 [==============================] - 36s 1ms/step - loss: 0.3198 - acc: 0.9650\n",
      "Epoch 5/20\n",
      "30946/30946 [==============================] - 37s 1ms/step - loss: 0.3150 - acc: 0.9600\n",
      "Epoch 6/20\n",
      "30946/30946 [==============================] - 36s 1ms/step - loss: 0.3115 - acc: 0.9567\n",
      "Epoch 7/20\n",
      "30946/30946 [==============================] - 36s 1ms/step - loss: 0.3130 - acc: 0.9529\n",
      "Epoch 8/20\n",
      "30946/30946 [==============================] - 35s 1ms/step - loss: 0.3099 - acc: 0.9469\n",
      "Epoch 9/20\n",
      "30946/30946 [==============================] - 36s 1ms/step - loss: 0.3082 - acc: 0.9419\n",
      "Epoch 10/20\n",
      "30946/30946 [==============================] - 35s 1ms/step - loss: 0.3077 - acc: 0.9355\n",
      "Epoch 11/20\n",
      "30946/30946 [==============================] - 36s 1ms/step - loss: 0.3043 - acc: 0.9299\n",
      "Epoch 12/20\n",
      "30946/30946 [==============================] - 36s 1ms/step - loss: 0.3032 - acc: 0.9292\n",
      "Epoch 13/20\n",
      "30946/30946 [==============================] - 36s 1ms/step - loss: 0.3041 - acc: 0.9225\n",
      "Epoch 14/20\n",
      "30946/30946 [==============================] - 36s 1ms/step - loss: 0.3039 - acc: 0.9148\n",
      "Epoch 15/20\n",
      "30946/30946 [==============================] - 35s 1ms/step - loss: 0.3034 - acc: 0.9162\n",
      "Epoch 16/20\n",
      "30946/30946 [==============================] - 36s 1ms/step - loss: 0.3026 - acc: 0.9020\n",
      "Epoch 17/20\n",
      "30946/30946 [==============================] - 37s 1ms/step - loss: 0.3026 - acc: 0.9072\n",
      "Epoch 18/20\n",
      "30946/30946 [==============================] - 38s 1ms/step - loss: 0.3009 - acc: 0.9005\n",
      "Epoch 19/20\n",
      "30946/30946 [==============================] - 37s 1ms/step - loss: 0.2988 - acc: 0.8981\n",
      "Epoch 20/20\n",
      "30946/30946 [==============================] - 39s 1ms/step - loss: 0.2978 - acc: 0.8928\n",
      "15472/15472 [==============================] - 17s 1ms/step\n",
      "30946/30946 [==============================] - 25s 804us/step\n",
      "[CV] .................... epochs=20, lr=0.003, nodes=32, total=12.8min\n",
      "[CV] epochs=20, lr=0.003, nodes=64 ...................................\n",
      "Epoch 1/20\n",
      "30945/30945 [==============================] - 75s 2ms/step - loss: 0.3511 - acc: 0.9769\n",
      "Epoch 2/20\n",
      "30945/30945 [==============================] - 62s 2ms/step - loss: 0.3313 - acc: 0.9749\n",
      "Epoch 3/20\n",
      "30945/30945 [==============================] - 61s 2ms/step - loss: 0.3223 - acc: 0.9685\n",
      "Epoch 4/20\n",
      "30945/30945 [==============================] - 62s 2ms/step - loss: 0.3155 - acc: 0.9594\n",
      "Epoch 5/20\n",
      "30945/30945 [==============================] - 63s 2ms/step - loss: 0.3093 - acc: 0.9550\n",
      "Epoch 6/20\n",
      "30945/30945 [==============================] - 61s 2ms/step - loss: 0.3061 - acc: 0.9534\n",
      "Epoch 7/20\n",
      "30945/30945 [==============================] - 62s 2ms/step - loss: 0.3044 - acc: 0.9452\n",
      "Epoch 8/20\n",
      "30945/30945 [==============================] - 62s 2ms/step - loss: 0.3027 - acc: 0.9398\n",
      "Epoch 9/20\n",
      "30945/30945 [==============================] - 61s 2ms/step - loss: 0.3000 - acc: 0.9310: 0s - loss: 0.3001 - \n",
      "Epoch 10/20\n",
      "30945/30945 [==============================] - 61s 2ms/step - loss: 0.2994 - acc: 0.9298\n",
      "Epoch 11/20\n",
      "30945/30945 [==============================] - 62s 2ms/step - loss: 0.3012 - acc: 0.9284\n",
      "Epoch 12/20\n",
      "30945/30945 [==============================] - 62s 2ms/step - loss: 0.3000 - acc: 0.9210\n",
      "Epoch 13/20\n",
      "30945/30945 [==============================] - 64s 2ms/step - loss: 0.3007 - acc: 0.9186\n",
      "Epoch 14/20\n",
      "30945/30945 [==============================] - 63s 2ms/step - loss: 0.3006 - acc: 0.9185\n",
      "Epoch 15/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30945/30945 [==============================] - 68s 2ms/step - loss: 0.3018 - acc: 0.9026\n",
      "Epoch 16/20\n",
      "30945/30945 [==============================] - 66s 2ms/step - loss: 0.2999 - acc: 0.9020\n",
      "Epoch 17/20\n",
      "30945/30945 [==============================] - 65s 2ms/step - loss: 0.3019 - acc: 0.9033\n",
      "Epoch 18/20\n",
      "30945/30945 [==============================] - 63s 2ms/step - loss: 0.3028 - acc: 0.8954\n",
      "Epoch 19/20\n",
      "30945/30945 [==============================] - 63s 2ms/step - loss: 0.3009 - acc: 0.8938\n",
      "Epoch 20/20\n",
      "30945/30945 [==============================] - 67s 2ms/step - loss: 0.3023 - acc: 0.8908\n",
      "15473/15473 [==============================] - 14s 934us/step\n",
      "30945/30945 [==============================] - 26s 837us/step\n",
      "[CV] .................... epochs=20, lr=0.003, nodes=64, total=22.0min\n",
      "[CV] epochs=20, lr=0.003, nodes=64 ...................................\n",
      "Epoch 1/20\n",
      "30945/30945 [==============================] - 70s 2ms/step - loss: 0.3607 - acc: 0.9771\n",
      "Epoch 2/20\n",
      "30945/30945 [==============================] - 57s 2ms/step - loss: 0.3423 - acc: 0.9740\n",
      "Epoch 3/20\n",
      "30945/30945 [==============================] - 54s 2ms/step - loss: 0.3346 - acc: 0.9677\n",
      "Epoch 4/20\n",
      "30945/30945 [==============================] - 61s 2ms/step - loss: 0.3271 - acc: 0.9604\n",
      "Epoch 5/20\n",
      "30945/30945 [==============================] - 62s 2ms/step - loss: 0.3223 - acc: 0.9555\n",
      "Epoch 6/20\n",
      "30945/30945 [==============================] - 59s 2ms/step - loss: 0.3178 - acc: 0.9451\n",
      "Epoch 7/20\n",
      "30945/30945 [==============================] - 55s 2ms/step - loss: 0.3158 - acc: 0.9417\n",
      "Epoch 8/20\n",
      "30945/30945 [==============================] - 57s 2ms/step - loss: 0.3129 - acc: 0.9295\n",
      "Epoch 9/20\n",
      "30945/30945 [==============================] - 60s 2ms/step - loss: 0.3124 - acc: 0.9328\n",
      "Epoch 10/20\n",
      "30945/30945 [==============================] - 58s 2ms/step - loss: 0.3086 - acc: 0.9262\n",
      "Epoch 11/20\n",
      "30945/30945 [==============================] - 58s 2ms/step - loss: 0.3100 - acc: 0.9251\n",
      "Epoch 12/20\n",
      "30945/30945 [==============================] - 56s 2ms/step - loss: 0.3094 - acc: 0.9232\n",
      "Epoch 13/20\n",
      "30945/30945 [==============================] - 55s 2ms/step - loss: 0.3067 - acc: 0.9151\n",
      "Epoch 14/20\n",
      "30945/30945 [==============================] - 57s 2ms/step - loss: 0.3113 - acc: 0.9072\n",
      "Epoch 15/20\n",
      "30945/30945 [==============================] - 58s 2ms/step - loss: 0.3076 - acc: 0.9105\n",
      "Epoch 16/20\n",
      "30945/30945 [==============================] - 58s 2ms/step - loss: 0.3077 - acc: 0.9047\n",
      "Epoch 17/20\n",
      "30945/30945 [==============================] - 57s 2ms/step - loss: 0.3079 - acc: 0.9012\n",
      "Epoch 18/20\n",
      "30945/30945 [==============================] - 55s 2ms/step - loss: 0.3087 - acc: 0.8971\n",
      "Epoch 19/20\n",
      "30945/30945 [==============================] - 55s 2ms/step - loss: 0.3064 - acc: 0.8968\n",
      "Epoch 20/20\n",
      "30945/30945 [==============================] - 53s 2ms/step - loss: 0.3098 - acc: 0.8919\n",
      "15473/15473 [==============================] - 14s 908us/step\n",
      "30945/30945 [==============================] - 24s 788us/step\n",
      "[CV] .................... epochs=20, lr=0.003, nodes=64, total=20.1min\n",
      "[CV] epochs=20, lr=0.003, nodes=64 ...................................\n",
      "Epoch 1/20\n",
      "30946/30946 [==============================] - 65s 2ms/step - loss: 0.3489 - acc: 0.9812\n",
      "Epoch 2/20\n",
      "30946/30946 [==============================] - 53s 2ms/step - loss: 0.3297 - acc: 0.9710\n",
      "Epoch 3/20\n",
      "30946/30946 [==============================] - 54s 2ms/step - loss: 0.3224 - acc: 0.9671\n",
      "Epoch 4/20\n",
      "30946/30946 [==============================] - 54s 2ms/step - loss: 0.3166 - acc: 0.9576\n",
      "Epoch 5/20\n",
      "30946/30946 [==============================] - 55s 2ms/step - loss: 0.3102 - acc: 0.9504\n",
      "Epoch 6/20\n",
      "30946/30946 [==============================] - 57s 2ms/step - loss: 0.3086 - acc: 0.9457\n",
      "Epoch 7/20\n",
      "30946/30946 [==============================] - 56s 2ms/step - loss: 0.3041 - acc: 0.9406\n",
      "Epoch 8/20\n",
      "30946/30946 [==============================] - 55s 2ms/step - loss: 0.3017 - acc: 0.9320\n",
      "Epoch 9/20\n",
      "30946/30946 [==============================] - 55s 2ms/step - loss: 0.3016 - acc: 0.9317\n",
      "Epoch 10/20\n",
      "30946/30946 [==============================] - 55s 2ms/step - loss: 0.3029 - acc: 0.9277\n",
      "Epoch 11/20\n",
      "30946/30946 [==============================] - 55s 2ms/step - loss: 0.3012 - acc: 0.9211\n",
      "Epoch 12/20\n",
      "30946/30946 [==============================] - 54s 2ms/step - loss: 0.3006 - acc: 0.9196\n",
      "Epoch 13/20\n",
      "30946/30946 [==============================] - 55s 2ms/step - loss: 0.3013 - acc: 0.9125\n",
      "Epoch 14/20\n",
      "30946/30946 [==============================] - 55s 2ms/step - loss: 0.3028 - acc: 0.9040\n",
      "Epoch 15/20\n",
      "30946/30946 [==============================] - 55s 2ms/step - loss: 0.2992 - acc: 0.9040\n",
      "Epoch 16/20\n",
      "30946/30946 [==============================] - 55s 2ms/step - loss: 0.3034 - acc: 0.9010\n",
      "Epoch 17/20\n",
      "30946/30946 [==============================] - 55s 2ms/step - loss: 0.2996 - acc: 0.8967\n",
      "Epoch 18/20\n",
      "30946/30946 [==============================] - 54s 2ms/step - loss: 0.3008 - acc: 0.8943\n",
      "Epoch 19/20\n",
      "30946/30946 [==============================] - 55s 2ms/step - loss: 0.3018 - acc: 0.8923\n",
      "Epoch 20/20\n",
      "30946/30946 [==============================] - 52s 2ms/step - loss: 0.3003 - acc: 0.8926\n",
      "15472/15472 [==============================] - 14s 908us/step\n",
      "30946/30946 [==============================] - 26s 854us/step\n",
      "[CV] .................... epochs=20, lr=0.003, nodes=64, total=19.2min\n",
      "[CV] epochs=30, lr=0.001, nodes=16 ...................................\n",
      "Epoch 1/30\n",
      "30945/30945 [==============================] - 36s 1ms/step - loss: 0.3703 - acc: 0.9533\n",
      "Epoch 2/30\n",
      "30945/30945 [==============================] - 24s 767us/step - loss: 0.3458 - acc: 0.9824\n",
      "Epoch 3/30\n",
      "30945/30945 [==============================] - 23s 748us/step - loss: 0.3388 - acc: 0.9815\n",
      "Epoch 4/30\n",
      "30945/30945 [==============================] - 23s 747us/step - loss: 0.3348 - acc: 0.9794\n",
      "Epoch 5/30\n",
      "30945/30945 [==============================] - 23s 749us/step - loss: 0.3346 - acc: 0.9779\n",
      "Epoch 6/30\n",
      "30945/30945 [==============================] - 23s 752us/step - loss: 0.3312 - acc: 0.9756\n",
      "Epoch 7/30\n",
      "30945/30945 [==============================] - 23s 753us/step - loss: 0.3293 - acc: 0.9741\n",
      "Epoch 8/30\n",
      "30945/30945 [==============================] - 23s 734us/step - loss: 0.3275 - acc: 0.9712\n",
      "Epoch 9/30\n",
      "30945/30945 [==============================] - 23s 740us/step - loss: 0.3256 - acc: 0.9688\n",
      "Epoch 10/30\n",
      "30945/30945 [==============================] - 23s 742us/step - loss: 0.3222 - acc: 0.9665\n",
      "Epoch 11/30\n",
      "30945/30945 [==============================] - 23s 735us/step - loss: 0.3208 - acc: 0.9590\n",
      "Epoch 12/30\n",
      "30945/30945 [==============================] - 23s 738us/step - loss: 0.3211 - acc: 0.9555\n",
      "Epoch 13/30\n",
      "30945/30945 [==============================] - 23s 750us/step - loss: 0.3190 - acc: 0.9587\n",
      "Epoch 14/30\n",
      "30945/30945 [==============================] - 23s 748us/step - loss: 0.3152 - acc: 0.9538\n",
      "Epoch 15/30\n",
      "30945/30945 [==============================] - 23s 744us/step - loss: 0.3161 - acc: 0.9534\n",
      "Epoch 16/30\n",
      "30945/30945 [==============================] - 23s 744us/step - loss: 0.3150 - acc: 0.9488\n",
      "Epoch 17/30\n",
      "30945/30945 [==============================] - 23s 746us/step - loss: 0.3128 - acc: 0.9461\n",
      "Epoch 18/30\n",
      "30945/30945 [==============================] - 23s 743us/step - loss: 0.3123 - acc: 0.9457\n",
      "Epoch 19/30\n",
      "30945/30945 [==============================] - 23s 730us/step - loss: 0.3095 - acc: 0.9430\n",
      "Epoch 20/30\n",
      "30945/30945 [==============================] - 23s 755us/step - loss: 0.3095 - acc: 0.9463\n",
      "Epoch 21/30\n",
      "30945/30945 [==============================] - 23s 745us/step - loss: 0.3095 - acc: 0.9434\n",
      "Epoch 22/30\n",
      "30945/30945 [==============================] - 23s 746us/step - loss: 0.3075 - acc: 0.9419\n",
      "Epoch 23/30\n",
      "30945/30945 [==============================] - 23s 738us/step - loss: 0.3072 - acc: 0.9345\n",
      "Epoch 24/30\n",
      "30945/30945 [==============================] - 23s 747us/step - loss: 0.3059 - acc: 0.9332\n",
      "Epoch 25/30\n",
      "30945/30945 [==============================] - 23s 742us/step - loss: 0.3067 - acc: 0.9308\n",
      "Epoch 26/30\n",
      "30945/30945 [==============================] - 23s 747us/step - loss: 0.3074 - acc: 0.9319\n",
      "Epoch 27/30\n",
      "30945/30945 [==============================] - 23s 743us/step - loss: 0.3062 - acc: 0.9291\n",
      "Epoch 28/30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30945/30945 [==============================] - 23s 752us/step - loss: 0.3055 - acc: 0.9248\n",
      "Epoch 29/30\n",
      "30945/30945 [==============================] - 23s 740us/step - loss: 0.3047 - acc: 0.9277\n",
      "Epoch 30/30\n",
      "30945/30945 [==============================] - 23s 753us/step - loss: 0.3047 - acc: 0.9231\n",
      "15473/15473 [==============================] - 13s 858us/step\n",
      "30945/30945 [==============================] - 21s 692us/step\n",
      "[CV] .................... epochs=30, lr=0.001, nodes=16, total=12.5min\n",
      "[CV] epochs=30, lr=0.001, nodes=16 ...................................\n",
      "Epoch 1/30\n",
      "30945/30945 [==============================] - 36s 1ms/step - loss: 0.3806 - acc: 0.9364\n",
      "Epoch 2/30\n",
      "30945/30945 [==============================] - 23s 737us/step - loss: 0.3550 - acc: 0.9847\n",
      "Epoch 3/30\n",
      "30945/30945 [==============================] - 23s 741us/step - loss: 0.3481 - acc: 0.9829\n",
      "Epoch 4/30\n",
      "30945/30945 [==============================] - 23s 741us/step - loss: 0.3434 - acc: 0.9805\n",
      "Epoch 5/30\n",
      "30945/30945 [==============================] - 23s 745us/step - loss: 0.3398 - acc: 0.9776\n",
      "Epoch 6/30\n",
      "30945/30945 [==============================] - 24s 765us/step - loss: 0.3361 - acc: 0.9750\n",
      "Epoch 7/30\n",
      "30945/30945 [==============================] - 24s 768us/step - loss: 0.3321 - acc: 0.9733\n",
      "Epoch 8/30\n",
      "30945/30945 [==============================] - 23s 756us/step - loss: 0.3299 - acc: 0.9693\n",
      "Epoch 9/30\n",
      "30945/30945 [==============================] - 23s 759us/step - loss: 0.3277 - acc: 0.9693\n",
      "Epoch 10/30\n",
      "30945/30945 [==============================] - 23s 748us/step - loss: 0.3267 - acc: 0.9660\n",
      "Epoch 11/30\n",
      "30945/30945 [==============================] - 23s 740us/step - loss: 0.3251 - acc: 0.9658\n",
      "Epoch 12/30\n",
      "30945/30945 [==============================] - 23s 745us/step - loss: 0.3246 - acc: 0.9624\n",
      "Epoch 13/30\n",
      "30945/30945 [==============================] - 23s 745us/step - loss: 0.3225 - acc: 0.9614\n",
      "Epoch 14/30\n",
      "30945/30945 [==============================] - 23s 739us/step - loss: 0.3209 - acc: 0.9567\n",
      "Epoch 15/30\n",
      "30945/30945 [==============================] - 23s 750us/step - loss: 0.3200 - acc: 0.9572\n",
      "Epoch 16/30\n",
      "30945/30945 [==============================] - 23s 752us/step - loss: 0.3184 - acc: 0.9559\n",
      "Epoch 17/30\n",
      "30945/30945 [==============================] - 23s 740us/step - loss: 0.3176 - acc: 0.9514\n",
      "Epoch 18/30\n",
      "30945/30945 [==============================] - 23s 737us/step - loss: 0.3161 - acc: 0.9489\n",
      "Epoch 19/30\n",
      "30945/30945 [==============================] - 23s 744us/step - loss: 0.3158 - acc: 0.9496\n",
      "Epoch 20/30\n",
      "30945/30945 [==============================] - 23s 731us/step - loss: 0.3148 - acc: 0.9470\n",
      "Epoch 21/30\n",
      "30945/30945 [==============================] - 22s 719us/step - loss: 0.3140 - acc: 0.9468\n",
      "Epoch 22/30\n",
      "30945/30945 [==============================] - 22s 723us/step - loss: 0.3150 - acc: 0.9448\n",
      "Epoch 23/30\n",
      "30945/30945 [==============================] - 22s 722us/step - loss: 0.3132 - acc: 0.9404\n",
      "Epoch 24/30\n",
      "30945/30945 [==============================] - 23s 728us/step - loss: 0.3134 - acc: 0.9391\n",
      "Epoch 25/30\n",
      "30945/30945 [==============================] - 23s 730us/step - loss: 0.3130 - acc: 0.9386\n",
      "Epoch 26/30\n",
      "30945/30945 [==============================] - 22s 718us/step - loss: 0.3105 - acc: 0.9331\n",
      "Epoch 27/30\n",
      "30945/30945 [==============================] - 23s 736us/step - loss: 0.3125 - acc: 0.9342\n",
      "Epoch 28/30\n",
      "30945/30945 [==============================] - 23s 747us/step - loss: 0.3112 - acc: 0.9329\n",
      "Epoch 29/30\n",
      "30945/30945 [==============================] - 23s 731us/step - loss: 0.3134 - acc: 0.9312\n",
      "Epoch 30/30\n",
      "30945/30945 [==============================] - 23s 744us/step - loss: 0.3116 - acc: 0.9337\n",
      "15473/15473 [==============================] - 14s 906us/step\n",
      "30945/30945 [==============================] - 21s 691us/step\n",
      "[CV] .................... epochs=30, lr=0.001, nodes=16, total=12.5min\n",
      "[CV] epochs=30, lr=0.001, nodes=16 ...................................\n",
      "Epoch 1/30\n",
      "30946/30946 [==============================] - 36s 1ms/step - loss: 0.3684 - acc: 0.9716\n",
      "Epoch 2/30\n",
      "30946/30946 [==============================] - 22s 724us/step - loss: 0.3425 - acc: 0.9813\n",
      "Epoch 3/30\n",
      "30946/30946 [==============================] - 23s 728us/step - loss: 0.3364 - acc: 0.9801\n",
      "Epoch 4/30\n",
      "30946/30946 [==============================] - 23s 727us/step - loss: 0.3331 - acc: 0.9775\n",
      "Epoch 5/30\n",
      "30946/30946 [==============================] - 22s 707us/step - loss: 0.3292 - acc: 0.9737\n",
      "Epoch 6/30\n",
      "30946/30946 [==============================] - 22s 715us/step - loss: 0.3278 - acc: 0.9712\n",
      "Epoch 7/30\n",
      "30946/30946 [==============================] - 22s 716us/step - loss: 0.3262 - acc: 0.9677\n",
      "Epoch 8/30\n",
      "30946/30946 [==============================] - 22s 703us/step - loss: 0.3217 - acc: 0.9640\n",
      "Epoch 9/30\n",
      "30946/30946 [==============================] - 22s 710us/step - loss: 0.3198 - acc: 0.9614\n",
      "Epoch 10/30\n",
      "30946/30946 [==============================] - 22s 708us/step - loss: 0.3183 - acc: 0.9596\n",
      "Epoch 11/30\n",
      "30946/30946 [==============================] - 22s 703us/step - loss: 0.3178 - acc: 0.9537\n",
      "Epoch 12/30\n",
      "30946/30946 [==============================] - 22s 697us/step - loss: 0.3157 - acc: 0.9568\n",
      "Epoch 13/30\n",
      "30946/30946 [==============================] - 22s 717us/step - loss: 0.3148 - acc: 0.9514\n",
      "Epoch 14/30\n",
      "30946/30946 [==============================] - 23s 743us/step - loss: 0.3124 - acc: 0.9512\n",
      "Epoch 15/30\n",
      "30946/30946 [==============================] - 22s 723us/step - loss: 0.3111 - acc: 0.9488\n",
      "Epoch 16/30\n",
      "30946/30946 [==============================] - 22s 725us/step - loss: 0.3110 - acc: 0.9501\n",
      "Epoch 17/30\n",
      "30946/30946 [==============================] - 22s 699us/step - loss: 0.3100 - acc: 0.9453\n",
      "Epoch 18/30\n",
      "30946/30946 [==============================] - 22s 700us/step - loss: 0.3087 - acc: 0.9465\n",
      "Epoch 19/30\n",
      "30946/30946 [==============================] - 22s 703us/step - loss: 0.3078 - acc: 0.9453\n",
      "Epoch 20/30\n",
      "30946/30946 [==============================] - 21s 681us/step - loss: 0.3074 - acc: 0.9377\n",
      "Epoch 21/30\n",
      "30946/30946 [==============================] - 21s 687us/step - loss: 0.3063 - acc: 0.9409\n",
      "Epoch 22/30\n",
      "30946/30946 [==============================] - 21s 688us/step - loss: 0.3046 - acc: 0.9355\n",
      "Epoch 23/30\n",
      "30946/30946 [==============================] - 21s 683us/step - loss: 0.3041 - acc: 0.9329\n",
      "Epoch 24/30\n",
      "30946/30946 [==============================] - 21s 688us/step - loss: 0.3050 - acc: 0.9368\n",
      "Epoch 25/30\n",
      "30946/30946 [==============================] - 22s 704us/step - loss: 0.3039 - acc: 0.9313\n",
      "Epoch 26/30\n",
      "30946/30946 [==============================] - 22s 704us/step - loss: 0.3026 - acc: 0.9275\n",
      "Epoch 27/30\n",
      "30946/30946 [==============================] - 22s 699us/step - loss: 0.3026 - acc: 0.9225\n",
      "Epoch 28/30\n",
      "30946/30946 [==============================] - 22s 704us/step - loss: 0.3022 - acc: 0.9193\n",
      "Epoch 29/30\n",
      "30946/30946 [==============================] - 22s 701us/step - loss: 0.3030 - acc: 0.9205\n",
      "Epoch 30/30\n",
      "30946/30946 [==============================] - 22s 714us/step - loss: 0.3023 - acc: 0.9172\n",
      "15472/15472 [==============================] - 14s 925us/step\n",
      "30946/30946 [==============================] - 25s 809us/step\n",
      "[CV] .................... epochs=30, lr=0.001, nodes=16, total=12.0min\n",
      "[CV] epochs=30, lr=0.001, nodes=32 ...................................\n",
      "Epoch 1/30\n",
      "30945/30945 [==============================] - 52s 2ms/step - loss: 0.3592 - acc: 0.9794\n",
      "Epoch 2/30\n",
      "30945/30945 [==============================] - 38s 1ms/step - loss: 0.3372 - acc: 0.9800\n",
      "Epoch 3/30\n",
      "30945/30945 [==============================] - 38s 1ms/step - loss: 0.3301 - acc: 0.9756\n",
      "Epoch 4/30\n",
      "30945/30945 [==============================] - 39s 1ms/step - loss: 0.3241 - acc: 0.9742\n",
      "Epoch 5/30\n",
      "30945/30945 [==============================] - 38s 1ms/step - loss: 0.3202 - acc: 0.9705\n",
      "Epoch 6/30\n",
      "30945/30945 [==============================] - 38s 1ms/step - loss: 0.3165 - acc: 0.9682\n",
      "Epoch 7/30\n",
      "30945/30945 [==============================] - 38s 1ms/step - loss: 0.3115 - acc: 0.9636\n",
      "Epoch 8/30\n",
      "30945/30945 [==============================] - 38s 1ms/step - loss: 0.3092 - acc: 0.9614\n",
      "Epoch 9/30\n",
      "30945/30945 [==============================] - 38s 1ms/step - loss: 0.3076 - acc: 0.9607\n",
      "Epoch 10/30\n",
      "30945/30945 [==============================] - 38s 1ms/step - loss: 0.3046 - acc: 0.9568\n",
      "Epoch 11/30\n",
      "30945/30945 [==============================] - 38s 1ms/step - loss: 0.3025 - acc: 0.9541\n",
      "Epoch 12/30\n",
      "30945/30945 [==============================] - 38s 1ms/step - loss: 0.3017 - acc: 0.9512\n",
      "Epoch 13/30\n",
      "30945/30945 [==============================] - 39s 1ms/step - loss: 0.2992 - acc: 0.9471\n",
      "Epoch 14/30\n",
      "30945/30945 [==============================] - 39s 1ms/step - loss: 0.2986 - acc: 0.9430\n",
      "Epoch 15/30\n",
      "30945/30945 [==============================] - 40s 1ms/step - loss: 0.2980 - acc: 0.9431\n",
      "Epoch 16/30\n",
      "30945/30945 [==============================] - 39s 1ms/step - loss: 0.2967 - acc: 0.9419\n",
      "Epoch 17/30\n",
      "30945/30945 [==============================] - 41s 1ms/step - loss: 0.2968 - acc: 0.9347\n",
      "Epoch 18/30\n",
      "30945/30945 [==============================] - 38s 1ms/step - loss: 0.2938 - acc: 0.9355\n",
      "Epoch 19/30\n",
      "30945/30945 [==============================] - 36s 1ms/step - loss: 0.2938 - acc: 0.9360\n",
      "Epoch 20/30\n",
      "30945/30945 [==============================] - 36s 1ms/step - loss: 0.2934 - acc: 0.9286\n",
      "Epoch 21/30\n",
      "30945/30945 [==============================] - 35s 1ms/step - loss: 0.2920 - acc: 0.9283\n",
      "Epoch 22/30\n",
      "30945/30945 [==============================] - 37s 1ms/step - loss: 0.2926 - acc: 0.9247\n",
      "Epoch 23/30\n",
      "30945/30945 [==============================] - 38s 1ms/step - loss: 0.2911 - acc: 0.9210\n",
      "Epoch 24/30\n",
      "30945/30945 [==============================] - 36s 1ms/step - loss: 0.2912 - acc: 0.9160\n",
      "Epoch 25/30\n",
      "30945/30945 [==============================] - 35s 1ms/step - loss: 0.2902 - acc: 0.9179\n",
      "Epoch 26/30\n",
      "30945/30945 [==============================] - 36s 1ms/step - loss: 0.2897 - acc: 0.9111\n",
      "Epoch 27/30\n",
      "30945/30945 [==============================] - 36s 1ms/step - loss: 0.2923 - acc: 0.9107\n",
      "Epoch 28/30\n",
      "30945/30945 [==============================] - 36s 1ms/step - loss: 0.2921 - acc: 0.9074\n",
      "Epoch 29/30\n",
      "30945/30945 [==============================] - 35s 1ms/step - loss: 0.2894 - acc: 0.9030\n",
      "Epoch 30/30\n",
      "30945/30945 [==============================] - 39s 1ms/step - loss: 0.2897 - acc: 0.8993\n",
      "15473/15473 [==============================] - 16s 1ms/step\n",
      "30945/30945 [==============================] - 25s 816us/step\n",
      "[CV] .................... epochs=30, lr=0.001, nodes=32, total=20.0min\n",
      "[CV] epochs=30, lr=0.001, nodes=32 ...................................\n",
      "Epoch 1/30\n",
      "30945/30945 [==============================] - 56s 2ms/step - loss: 0.3691 - acc: 0.9816\n",
      "Epoch 2/30\n",
      "30945/30945 [==============================] - 41s 1ms/step - loss: 0.3494 - acc: 0.9783\n",
      "Epoch 3/30\n",
      "30945/30945 [==============================] - 38s 1ms/step - loss: 0.3397 - acc: 0.9770\n",
      "Epoch 4/30\n",
      "30945/30945 [==============================] - 39s 1ms/step - loss: 0.3358 - acc: 0.9745\n",
      "Epoch 5/30\n",
      "30945/30945 [==============================] - 40s 1ms/step - loss: 0.3298 - acc: 0.9702\n",
      "Epoch 6/30\n",
      "30945/30945 [==============================] - 41s 1ms/step - loss: 0.3266 - acc: 0.9671\n",
      "Epoch 7/30\n",
      "30945/30945 [==============================] - 41s 1ms/step - loss: 0.3241 - acc: 0.9630\n",
      "Epoch 8/30\n",
      "30945/30945 [==============================] - 39s 1ms/step - loss: 0.3212 - acc: 0.9624\n",
      "Epoch 9/30\n",
      "30945/30945 [==============================] - 40s 1ms/step - loss: 0.3175 - acc: 0.9575\n",
      "Epoch 10/30\n",
      "30945/30945 [==============================] - 40s 1ms/step - loss: 0.3156 - acc: 0.9548\n",
      "Epoch 11/30\n",
      "30945/30945 [==============================] - 40s 1ms/step - loss: 0.3134 - acc: 0.9549\n",
      "Epoch 12/30\n",
      "30945/30945 [==============================] - 40s 1ms/step - loss: 0.3120 - acc: 0.9480\n",
      "Epoch 13/30\n",
      "30945/30945 [==============================] - 39s 1ms/step - loss: 0.3103 - acc: 0.9466\n",
      "Epoch 14/30\n",
      "30945/30945 [==============================] - 41s 1ms/step - loss: 0.3071 - acc: 0.9398\n",
      "Epoch 15/30\n",
      "30945/30945 [==============================] - 40s 1ms/step - loss: 0.3053 - acc: 0.9393\n",
      "Epoch 16/30\n",
      "30945/30945 [==============================] - 40s 1ms/step - loss: 0.3061 - acc: 0.9336\n",
      "Epoch 17/30\n",
      "30945/30945 [==============================] - 40s 1ms/step - loss: 0.3045 - acc: 0.9348\n",
      "Epoch 18/30\n",
      "30945/30945 [==============================] - 40s 1ms/step - loss: 0.3044 - acc: 0.9303\n",
      "Epoch 19/30\n",
      "30945/30945 [==============================] - 41s 1ms/step - loss: 0.3041 - acc: 0.9289\n",
      "Epoch 20/30\n",
      "30945/30945 [==============================] - 40s 1ms/step - loss: 0.3033 - acc: 0.9271\n",
      "Epoch 21/30\n",
      "30945/30945 [==============================] - 40s 1ms/step - loss: 0.3013 - acc: 0.9266\n",
      "Epoch 22/30\n",
      "30945/30945 [==============================] - 41s 1ms/step - loss: 0.3015 - acc: 0.9235\n",
      "Epoch 23/30\n",
      "30945/30945 [==============================] - 41s 1ms/step - loss: 0.3010 - acc: 0.9190\n",
      "Epoch 24/30\n",
      "30945/30945 [==============================] - 40s 1ms/step - loss: 0.3008 - acc: 0.9109\n",
      "Epoch 25/30\n",
      "30945/30945 [==============================] - 40s 1ms/step - loss: 0.3005 - acc: 0.9092\n",
      "Epoch 26/30\n",
      "30945/30945 [==============================] - 40s 1ms/step - loss: 0.2995 - acc: 0.9160\n",
      "Epoch 27/30\n",
      "30945/30945 [==============================] - 40s 1ms/step - loss: 0.3019 - acc: 0.9118\n",
      "Epoch 28/30\n",
      "30945/30945 [==============================] - 41s 1ms/step - loss: 0.3008 - acc: 0.9105\n",
      "Epoch 29/30\n",
      "30945/30945 [==============================] - 40s 1ms/step - loss: 0.3004 - acc: 0.9065\n",
      "Epoch 30/30\n",
      "30945/30945 [==============================] - 40s 1ms/step - loss: 0.3010 - acc: 0.9010\n",
      "15473/15473 [==============================] - 17s 1ms/step\n",
      "30945/30945 [==============================] - 25s 808us/step\n",
      "[CV] .................... epochs=30, lr=0.001, nodes=32, total=21.2min\n",
      "[CV] epochs=30, lr=0.001, nodes=32 ...................................\n",
      "Epoch 1/30\n",
      "30946/30946 [==============================] - 49s 2ms/step - loss: 0.3587 - acc: 0.9812\n",
      "Epoch 2/30\n",
      "30946/30946 [==============================] - 37s 1ms/step - loss: 0.3391 - acc: 0.9802\n",
      "Epoch 3/30\n",
      "30946/30946 [==============================] - 36s 1ms/step - loss: 0.3324 - acc: 0.9789\n",
      "Epoch 4/30\n",
      "30946/30946 [==============================] - 37s 1ms/step - loss: 0.3255 - acc: 0.9783\n",
      "Epoch 5/30\n",
      "30946/30946 [==============================] - 36s 1ms/step - loss: 0.3217 - acc: 0.9725\n",
      "Epoch 6/30\n",
      "30946/30946 [==============================] - 36s 1ms/step - loss: 0.3177 - acc: 0.9710\n",
      "Epoch 7/30\n",
      "30946/30946 [==============================] - 36s 1ms/step - loss: 0.3138 - acc: 0.9669\n",
      "Epoch 8/30\n",
      "30946/30946 [==============================] - 36s 1ms/step - loss: 0.3123 - acc: 0.9621\n",
      "Epoch 9/30\n",
      "30946/30946 [==============================] - 36s 1ms/step - loss: 0.3095 - acc: 0.9595\n",
      "Epoch 10/30\n",
      "30946/30946 [==============================] - 35s 1ms/step - loss: 0.3089 - acc: 0.9561\n",
      "Epoch 11/30\n",
      "30946/30946 [==============================] - 36s 1ms/step - loss: 0.3061 - acc: 0.9519\n",
      "Epoch 12/30\n",
      "30946/30946 [==============================] - 36s 1ms/step - loss: 0.3034 - acc: 0.9499\n",
      "Epoch 13/30\n",
      "30946/30946 [==============================] - 36s 1ms/step - loss: 0.3048 - acc: 0.9446\n",
      "Epoch 14/30\n",
      "30946/30946 [==============================] - 36s 1ms/step - loss: 0.3030 - acc: 0.9418\n",
      "Epoch 15/30\n",
      "30946/30946 [==============================] - 36s 1ms/step - loss: 0.3010 - acc: 0.9367\n",
      "Epoch 16/30\n",
      "30946/30946 [==============================] - 36s 1ms/step - loss: 0.2986 - acc: 0.9351\n",
      "Epoch 17/30\n",
      "30946/30946 [==============================] - 38s 1ms/step - loss: 0.2998 - acc: 0.9360\n",
      "Epoch 18/30\n",
      "30946/30946 [==============================] - 36s 1ms/step - loss: 0.2975 - acc: 0.9352\n",
      "Epoch 19/30\n",
      "30946/30946 [==============================] - 38s 1ms/step - loss: 0.2972 - acc: 0.9281\n",
      "Epoch 20/30\n",
      "30946/30946 [==============================] - 37s 1ms/step - loss: 0.2961 - acc: 0.9254\n",
      "Epoch 21/30\n",
      "30946/30946 [==============================] - 36s 1ms/step - loss: 0.2942 - acc: 0.9244\n",
      "Epoch 22/30\n",
      "30946/30946 [==============================] - 36s 1ms/step - loss: 0.2955 - acc: 0.9215\n",
      "Epoch 23/30\n",
      "30946/30946 [==============================] - 36s 1ms/step - loss: 0.2928 - acc: 0.9177\n",
      "Epoch 24/30\n",
      "30946/30946 [==============================] - 36s 1ms/step - loss: 0.2928 - acc: 0.9144\n",
      "Epoch 25/30\n",
      "30946/30946 [==============================] - 36s 1ms/step - loss: 0.2920 - acc: 0.9110\n",
      "Epoch 26/30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30946/30946 [==============================] - 36s 1ms/step - loss: 0.2913 - acc: 0.9141\n",
      "Epoch 27/30\n",
      "30946/30946 [==============================] - 36s 1ms/step - loss: 0.2918 - acc: 0.9088\n",
      "Epoch 28/30\n",
      "30946/30946 [==============================] - 37s 1ms/step - loss: 0.2915 - acc: 0.9094\n",
      "Epoch 29/30\n",
      "30946/30946 [==============================] - 37s 1ms/step - loss: 0.2902 - acc: 0.9022\n",
      "Epoch 30/30\n",
      "30946/30946 [==============================] - 37s 1ms/step - loss: 0.2899 - acc: 0.9019\n",
      "15472/15472 [==============================] - 16s 1ms/step\n",
      "30946/30946 [==============================] - 25s 812us/step\n",
      "[CV] .................... epochs=30, lr=0.001, nodes=32, total=19.2min\n",
      "[CV] epochs=30, lr=0.001, nodes=64 ...................................\n",
      "Epoch 1/30\n",
      "30945/30945 [==============================] - 76s 2ms/step - loss: 0.3576 - acc: 0.9797\n",
      "Epoch 2/30\n",
      "30945/30945 [==============================] - 63s 2ms/step - loss: 0.3346 - acc: 0.9770\n",
      "Epoch 3/30\n",
      "30945/30945 [==============================] - 63s 2ms/step - loss: 0.3259 - acc: 0.9727\n",
      "Epoch 4/30\n",
      "30945/30945 [==============================] - 63s 2ms/step - loss: 0.3197 - acc: 0.9715\n",
      "Epoch 5/30\n",
      "30945/30945 [==============================] - 65s 2ms/step - loss: 0.3145 - acc: 0.9661\n",
      "Epoch 6/30\n",
      "30945/30945 [==============================] - 63s 2ms/step - loss: 0.3097 - acc: 0.9618\n",
      "Epoch 7/30\n",
      "30945/30945 [==============================] - 63s 2ms/step - loss: 0.3059 - acc: 0.9600\n",
      "Epoch 8/30\n",
      "30945/30945 [==============================] - 62s 2ms/step - loss: 0.3020 - acc: 0.9565\n",
      "Epoch 9/30\n",
      "30945/30945 [==============================] - 63s 2ms/step - loss: 0.2990 - acc: 0.9515\n",
      "Epoch 10/30\n",
      "30945/30945 [==============================] - 63s 2ms/step - loss: 0.2965 - acc: 0.9514\n",
      "Epoch 11/30\n",
      "30945/30945 [==============================] - 65s 2ms/step - loss: 0.2932 - acc: 0.9465\n",
      "Epoch 12/30\n",
      "30945/30945 [==============================] - 64s 2ms/step - loss: 0.2921 - acc: 0.9432\n",
      "Epoch 13/30\n",
      "30945/30945 [==============================] - 64s 2ms/step - loss: 0.2906 - acc: 0.9379\n",
      "Epoch 14/30\n",
      "30945/30945 [==============================] - 64s 2ms/step - loss: 0.2885 - acc: 0.9336\n",
      "Epoch 15/30\n",
      "30945/30945 [==============================] - 63s 2ms/step - loss: 0.2893 - acc: 0.9300\n",
      "Epoch 16/30\n",
      "30945/30945 [==============================] - 62s 2ms/step - loss: 0.2871 - acc: 0.9297\n",
      "Epoch 17/30\n",
      "30945/30945 [==============================] - 62s 2ms/step - loss: 0.2876 - acc: 0.9218\n",
      "Epoch 18/30\n",
      "30945/30945 [==============================] - 63s 2ms/step - loss: 0.2871 - acc: 0.9236\n",
      "Epoch 19/30\n",
      "30945/30945 [==============================] - 62s 2ms/step - loss: 0.2876 - acc: 0.9214\n",
      "Epoch 20/30\n",
      "30945/30945 [==============================] - 64s 2ms/step - loss: 0.2879 - acc: 0.9201\n",
      "Epoch 21/30\n",
      "30945/30945 [==============================] - 63s 2ms/step - loss: 0.2859 - acc: 0.9110\n",
      "Epoch 22/30\n",
      "30945/30945 [==============================] - 64s 2ms/step - loss: 0.2854 - acc: 0.9075\n",
      "Epoch 23/30\n",
      "30945/30945 [==============================] - 64s 2ms/step - loss: 0.2846 - acc: 0.9111\n",
      "Epoch 24/30\n",
      "30945/30945 [==============================] - 64s 2ms/step - loss: 0.2857 - acc: 0.9038\n",
      "Epoch 25/30\n",
      "30945/30945 [==============================] - 63s 2ms/step - loss: 0.2846 - acc: 0.9042\n",
      "Epoch 26/30\n",
      "30945/30945 [==============================] - 63s 2ms/step - loss: 0.2845 - acc: 0.9040\n",
      "Epoch 27/30\n",
      "30945/30945 [==============================] - 64s 2ms/step - loss: 0.2855 - acc: 0.8937\n",
      "Epoch 28/30\n",
      "30945/30945 [==============================] - 63s 2ms/step - loss: 0.2848 - acc: 0.8947\n",
      "Epoch 29/30\n",
      "30945/30945 [==============================] - 64s 2ms/step - loss: 0.2847 - acc: 0.8925\n",
      "Epoch 30/30\n",
      "30945/30945 [==============================] - 65s 2ms/step - loss: 0.2838 - acc: 0.8937\n",
      "15473/15473 [==============================] - 17s 1ms/step\n",
      "30945/30945 [==============================] - 30s 964us/step\n",
      "[CV] .................... epochs=30, lr=0.001, nodes=64, total=32.8min\n",
      "[CV] epochs=30, lr=0.001, nodes=64 ...................................\n",
      "Epoch 1/30\n",
      "30945/30945 [==============================] - 75s 2ms/step - loss: 0.3655 - acc: 0.9797\n",
      "Epoch 2/30\n",
      "30945/30945 [==============================] - 63s 2ms/step - loss: 0.3445 - acc: 0.9773\n",
      "Epoch 3/30\n",
      "30945/30945 [==============================] - 63s 2ms/step - loss: 0.3353 - acc: 0.9753\n",
      "Epoch 4/30\n",
      "30945/30945 [==============================] - 64s 2ms/step - loss: 0.3284 - acc: 0.9719\n",
      "Epoch 5/30\n",
      "30945/30945 [==============================] - 62s 2ms/step - loss: 0.3235 - acc: 0.9687\n",
      "Epoch 6/30\n",
      "30945/30945 [==============================] - 62s 2ms/step - loss: 0.3193 - acc: 0.9627\n",
      "Epoch 7/30\n",
      "30945/30945 [==============================] - 62s 2ms/step - loss: 0.3146 - acc: 0.9561\n",
      "Epoch 8/30\n",
      "30945/30945 [==============================] - 64s 2ms/step - loss: 0.3106 - acc: 0.9538\n",
      "Epoch 9/30\n",
      "30945/30945 [==============================] - 63s 2ms/step - loss: 0.3082 - acc: 0.9465\n",
      "Epoch 10/30\n",
      "30945/30945 [==============================] - 62s 2ms/step - loss: 0.3063 - acc: 0.9448\n",
      "Epoch 11/30\n",
      "30945/30945 [==============================] - 63s 2ms/step - loss: 0.3040 - acc: 0.9407\n",
      "Epoch 12/30\n",
      "30945/30945 [==============================] - 62s 2ms/step - loss: 0.3014 - acc: 0.9320\n",
      "Epoch 13/30\n",
      "30945/30945 [==============================] - 61s 2ms/step - loss: 0.3003 - acc: 0.9333\n",
      "Epoch 14/30\n",
      "30945/30945 [==============================] - 63s 2ms/step - loss: 0.2998 - acc: 0.9279\n",
      "Epoch 15/30\n",
      "30945/30945 [==============================] - 62s 2ms/step - loss: 0.2991 - acc: 0.9243\n",
      "Epoch 16/30\n",
      "30945/30945 [==============================] - 61s 2ms/step - loss: 0.2975 - acc: 0.9237\n",
      "Epoch 17/30\n",
      "30945/30945 [==============================] - 63s 2ms/step - loss: 0.2978 - acc: 0.9205\n",
      "Epoch 18/30\n",
      "30945/30945 [==============================] - 62s 2ms/step - loss: 0.2963 - acc: 0.9209\n",
      "Epoch 19/30\n",
      "30945/30945 [==============================] - 62s 2ms/step - loss: 0.2964 - acc: 0.9160\n",
      "Epoch 20/30\n",
      "30945/30945 [==============================] - 63s 2ms/step - loss: 0.2945 - acc: 0.9116\n",
      "Epoch 21/30\n",
      "30945/30945 [==============================] - 62s 2ms/step - loss: 0.2955 - acc: 0.9076: 1s\n",
      "Epoch 22/30\n",
      "30945/30945 [==============================] - 62s 2ms/step - loss: 0.2961 - acc: 0.9029\n",
      "Epoch 23/30\n",
      "30945/30945 [==============================] - 61s 2ms/step - loss: 0.2961 - acc: 0.9041\n",
      "Epoch 24/30\n",
      "30945/30945 [==============================] - 63s 2ms/step - loss: 0.2966 - acc: 0.9002\n",
      "Epoch 25/30\n",
      "30945/30945 [==============================] - ETA: 0s - loss: 0.2960 - acc: 0.897 - 63s 2ms/step - loss: 0.2960 - acc: 0.8974\n",
      "Epoch 26/30\n",
      "30945/30945 [==============================] - 61s 2ms/step - loss: 0.2934 - acc: 0.8973\n",
      "Epoch 27/30\n",
      "30945/30945 [==============================] - 61s 2ms/step - loss: 0.2939 - acc: 0.8922\n",
      "Epoch 28/30\n",
      "30945/30945 [==============================] - 62s 2ms/step - loss: 0.2939 - acc: 0.8933\n",
      "Epoch 29/30\n",
      "30945/30945 [==============================] - 62s 2ms/step - loss: 0.2959 - acc: 0.8901\n",
      "Epoch 30/30\n",
      "30945/30945 [==============================] - 61s 2ms/step - loss: 0.2946 - acc: 0.8894\n",
      "15473/15473 [==============================] - 18s 1ms/step\n",
      "30945/30945 [==============================] - 30s 955us/step\n",
      "[CV] .................... epochs=30, lr=0.001, nodes=64, total=32.3min\n",
      "[CV] epochs=30, lr=0.001, nodes=64 ...................................\n",
      "Epoch 1/30\n",
      "30946/30946 [==============================] - 72s 2ms/step - loss: 0.3570 - acc: 0.9778\n",
      "Epoch 2/30\n",
      "30946/30946 [==============================] - 63s 2ms/step - loss: 0.3332 - acc: 0.9796\n",
      "Epoch 3/30\n",
      "30946/30946 [==============================] - 61s 2ms/step - loss: 0.3239 - acc: 0.9756\n",
      "Epoch 4/30\n",
      "30946/30946 [==============================] - 61s 2ms/step - loss: 0.3176 - acc: 0.9696\n",
      "Epoch 5/30\n",
      "30946/30946 [==============================] - 62s 2ms/step - loss: 0.3136 - acc: 0.9649\n",
      "Epoch 6/30\n",
      "30946/30946 [==============================] - 60s 2ms/step - loss: 0.3090 - acc: 0.9633\n",
      "Epoch 7/30\n",
      "30946/30946 [==============================] - 62s 2ms/step - loss: 0.3063 - acc: 0.9573\n",
      "Epoch 8/30\n",
      "30946/30946 [==============================] - 61s 2ms/step - loss: 0.3013 - acc: 0.9549\n",
      "Epoch 9/30\n",
      "30946/30946 [==============================] - 61s 2ms/step - loss: 0.2991 - acc: 0.9525\n",
      "Epoch 10/30\n",
      "30946/30946 [==============================] - 60s 2ms/step - loss: 0.2965 - acc: 0.9467\n",
      "Epoch 11/30\n",
      "30946/30946 [==============================] - 59s 2ms/step - loss: 0.2939 - acc: 0.9417\n",
      "Epoch 12/30\n",
      "30946/30946 [==============================] - 60s 2ms/step - loss: 0.2936 - acc: 0.9417\n",
      "Epoch 13/30\n",
      "30946/30946 [==============================] - 62s 2ms/step - loss: 0.2933 - acc: 0.9399\n",
      "Epoch 14/30\n",
      "30946/30946 [==============================] - 61s 2ms/step - loss: 0.2902 - acc: 0.9302\n",
      "Epoch 15/30\n",
      "30946/30946 [==============================] - 60s 2ms/step - loss: 0.2884 - acc: 0.9270\n",
      "Epoch 16/30\n",
      "30946/30946 [==============================] - 59s 2ms/step - loss: 0.2870 - acc: 0.9290\n",
      "Epoch 17/30\n",
      "30946/30946 [==============================] - 62s 2ms/step - loss: 0.2866 - acc: 0.9243\n",
      "Epoch 18/30\n",
      "30946/30946 [==============================] - 62s 2ms/step - loss: 0.2869 - acc: 0.9213\n",
      "Epoch 19/30\n",
      "30946/30946 [==============================] - 60s 2ms/step - loss: 0.2852 - acc: 0.9168\n",
      "Epoch 20/30\n",
      "30946/30946 [==============================] - 60s 2ms/step - loss: 0.2855 - acc: 0.9138\n",
      "Epoch 21/30\n",
      "30946/30946 [==============================] - 62s 2ms/step - loss: 0.2849 - acc: 0.9078\n",
      "Epoch 22/30\n",
      "30946/30946 [==============================] - 61s 2ms/step - loss: 0.2852 - acc: 0.9068\n",
      "Epoch 23/30\n",
      "30946/30946 [==============================] - 60s 2ms/step - loss: 0.2838 - acc: 0.9087\n",
      "Epoch 24/30\n",
      "30946/30946 [==============================] - 60s 2ms/step - loss: 0.2838 - acc: 0.9037\n",
      "Epoch 25/30\n",
      "30946/30946 [==============================] - 1259s 41ms/step - loss: 0.2851 - acc: 0.9023\n",
      "Epoch 26/30\n",
      "30946/30946 [==============================] - 32621s 1s/step - loss: 0.2840 - acc: 0.8957\n",
      "Epoch 27/30\n",
      "30946/30946 [==============================] - 46s 1ms/step - loss: 0.2839 - acc: 0.9011\n",
      "Epoch 28/30\n",
      "30946/30946 [==============================] - 48s 2ms/step - loss: 0.2842 - acc: 0.8935\n",
      "Epoch 29/30\n",
      "30946/30946 [==============================] - 48s 2ms/step - loss: 0.2856 - acc: 0.8936\n",
      "Epoch 30/30\n",
      "30946/30946 [==============================] - 49s 2ms/step - loss: 0.2843 - acc: 0.8920\n",
      "15472/15472 [==============================] - 14s 919us/step\n",
      "30946/30946 [==============================] - 24s 763us/step\n",
      "[CV] ................... epochs=30, lr=0.001, nodes=64, total=593.2min\n",
      "[CV] epochs=30, lr=0.002, nodes=16 ...................................\n",
      "Epoch 1/30\n",
      "30945/30945 [==============================] - 39s 1ms/step - loss: 0.3593 - acc: 0.9760\n",
      "Epoch 2/30\n",
      "30945/30945 [==============================] - 25s 798us/step - loss: 0.3403 - acc: 0.9836\n",
      "Epoch 3/30\n",
      "30945/30945 [==============================] - 25s 798us/step - loss: 0.3345 - acc: 0.9805\n",
      "Epoch 4/30\n",
      "30945/30945 [==============================] - 25s 804us/step - loss: 0.3313 - acc: 0.9736\n",
      "Epoch 5/30\n",
      "30945/30945 [==============================] - 25s 806us/step - loss: 0.3281 - acc: 0.9696\n",
      "Epoch 6/30\n",
      "30945/30945 [==============================] - 25s 813us/step - loss: 0.3246 - acc: 0.9683\n",
      "Epoch 7/30\n",
      "30945/30945 [==============================] - 25s 814us/step - loss: 0.3230 - acc: 0.9625\n",
      "Epoch 8/30\n",
      "30945/30945 [==============================] - 25s 800us/step - loss: 0.3211 - acc: 0.9628\n",
      "Epoch 9/30\n",
      "30945/30945 [==============================] - 25s 823us/step - loss: 0.3191 - acc: 0.9577\n",
      "Epoch 10/30\n",
      "30945/30945 [==============================] - 26s 824us/step - loss: 0.3167 - acc: 0.9593\n",
      "Epoch 11/30\n",
      "30945/30945 [==============================] - 25s 816us/step - loss: 0.3163 - acc: 0.9596\n",
      "Epoch 12/30\n",
      "30945/30945 [==============================] - 28s 905us/step - loss: 0.3158 - acc: 0.9589\n",
      "Epoch 13/30\n",
      "30945/30945 [==============================] - 26s 837us/step - loss: 0.3140 - acc: 0.9548\n",
      "Epoch 14/30\n",
      "30945/30945 [==============================] - 26s 834us/step - loss: 0.3128 - acc: 0.9529\n",
      "Epoch 15/30\n",
      "30945/30945 [==============================] - 25s 819us/step - loss: 0.3125 - acc: 0.9509\n",
      "Epoch 16/30\n",
      "30945/30945 [==============================] - 26s 829us/step - loss: 0.3115 - acc: 0.9465\n",
      "Epoch 17/30\n",
      "30945/30945 [==============================] - 25s 817us/step - loss: 0.3082 - acc: 0.9461\n",
      "Epoch 18/30\n",
      "30945/30945 [==============================] - 26s 850us/step - loss: 0.3090 - acc: 0.9436\n",
      "Epoch 19/30\n",
      "30945/30945 [==============================] - 26s 852us/step - loss: 0.3072 - acc: 0.9405\n",
      "Epoch 20/30\n",
      "30945/30945 [==============================] - 26s 845us/step - loss: 0.3078 - acc: 0.9388\n",
      "Epoch 21/30\n",
      "30945/30945 [==============================] - 26s 837us/step - loss: 0.3059 - acc: 0.9350\n",
      "Epoch 22/30\n",
      "30945/30945 [==============================] - 26s 835us/step - loss: 0.3052 - acc: 0.9292\n",
      "Epoch 23/30\n",
      "30945/30945 [==============================] - 25s 823us/step - loss: 0.3057 - acc: 0.9294\n",
      "Epoch 24/30\n",
      "30945/30945 [==============================] - 26s 851us/step - loss: 0.3046 - acc: 0.9191\n",
      "Epoch 25/30\n",
      "30945/30945 [==============================] - 28s 907us/step - loss: 0.3046 - acc: 0.9202\n",
      "Epoch 26/30\n",
      "30945/30945 [==============================] - 27s 876us/step - loss: 0.3034 - acc: 0.9180\n",
      "Epoch 27/30\n",
      "30945/30945 [==============================] - 26s 835us/step - loss: 0.3040 - acc: 0.9123\n",
      "Epoch 28/30\n",
      "30945/30945 [==============================] - 26s 831us/step - loss: 0.3035 - acc: 0.9123\n",
      "Epoch 29/30\n",
      "30945/30945 [==============================] - 26s 843us/step - loss: 0.3033 - acc: 0.9109\n",
      "Epoch 30/30\n",
      "30945/30945 [==============================] - 27s 869us/step - loss: 0.3028 - acc: 0.9094\n",
      "15473/15473 [==============================] - 15s 982us/step\n",
      "30945/30945 [==============================] - 24s 761us/step\n",
      "[CV] .................... epochs=30, lr=0.002, nodes=16, total=13.9min\n",
      "[CV] epochs=30, lr=0.002, nodes=16 ...................................\n",
      "Epoch 1/30\n",
      "30945/30945 [==============================] - 39s 1ms/step - loss: 0.3678 - acc: 0.9748\n",
      "Epoch 2/30\n",
      "30945/30945 [==============================] - 29s 939us/step - loss: 0.3481 - acc: 0.9827\n",
      "Epoch 3/30\n",
      "30945/30945 [==============================] - 26s 841us/step - loss: 0.3417 - acc: 0.9795\n",
      "Epoch 4/30\n",
      "30945/30945 [==============================] - 25s 813us/step - loss: 0.3389 - acc: 0.9762\n",
      "Epoch 5/30\n",
      "30945/30945 [==============================] - 25s 818us/step - loss: 0.3353 - acc: 0.9712\n",
      "Epoch 6/30\n",
      "30945/30945 [==============================] - 25s 819us/step - loss: 0.3350 - acc: 0.9694\n",
      "Epoch 7/30\n",
      "30945/30945 [==============================] - 26s 825us/step - loss: 0.3314 - acc: 0.9624\n",
      "Epoch 8/30\n",
      "30945/30945 [==============================] - 25s 820us/step - loss: 0.3301 - acc: 0.9566\n",
      "Epoch 9/30\n",
      "30945/30945 [==============================] - 25s 818us/step - loss: 0.3306 - acc: 0.9573\n",
      "Epoch 10/30\n",
      "30945/30945 [==============================] - 25s 822us/step - loss: 0.3277 - acc: 0.9516\n",
      "Epoch 11/30\n",
      "30945/30945 [==============================] - 27s 878us/step - loss: 0.3259 - acc: 0.9444\n",
      "Epoch 12/30\n",
      "30945/30945 [==============================] - 24s 786us/step - loss: 0.3251 - acc: 0.9441\n",
      "Epoch 13/30\n",
      "30945/30945 [==============================] - 23s 752us/step - loss: 0.3237 - acc: 0.9389\n",
      "Epoch 14/30\n",
      "30945/30945 [==============================] - 23s 733us/step - loss: 0.3215 - acc: 0.9381\n",
      "Epoch 15/30\n",
      "30945/30945 [==============================] - 22s 723us/step - loss: 0.3217 - acc: 0.9361\n",
      "Epoch 16/30\n",
      "30945/30945 [==============================] - 23s 736us/step - loss: 0.3209 - acc: 0.9333\n",
      "Epoch 17/30\n",
      "30945/30945 [==============================] - 23s 743us/step - loss: 0.3195 - acc: 0.9327\n",
      "Epoch 18/30\n",
      "30945/30945 [==============================] - 23s 745us/step - loss: 0.3207 - acc: 0.9301\n",
      "Epoch 19/30\n",
      "30945/30945 [==============================] - 23s 734us/step - loss: 0.3185 - acc: 0.9292\n",
      "Epoch 20/30\n",
      "30945/30945 [==============================] - 23s 746us/step - loss: 0.3207 - acc: 0.9223\n",
      "Epoch 21/30\n",
      "30945/30945 [==============================] - 23s 746us/step - loss: 0.3202 - acc: 0.9257\n",
      "Epoch 22/30\n",
      "30945/30945 [==============================] - 23s 744us/step - loss: 0.3188 - acc: 0.9191\n",
      "Epoch 23/30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30945/30945 [==============================] - 25s 822us/step - loss: 0.3195 - acc: 0.9178\n",
      "Epoch 24/30\n",
      "30945/30945 [==============================] - 24s 780us/step - loss: 0.3194 - acc: 0.9173\n",
      "Epoch 25/30\n",
      "30945/30945 [==============================] - 22s 703us/step - loss: 0.3188 - acc: 0.9147\n",
      "Epoch 26/30\n",
      "30945/30945 [==============================] - 22s 721us/step - loss: 0.3193 - acc: 0.9092\n",
      "Epoch 27/30\n",
      "30945/30945 [==============================] - 23s 742us/step - loss: 0.3192 - acc: 0.9111\n",
      "Epoch 28/30\n",
      "30945/30945 [==============================] - 23s 752us/step - loss: 0.3194 - acc: 0.9019\n",
      "Epoch 29/30\n",
      "30945/30945 [==============================] - 23s 737us/step - loss: 0.3204 - acc: 0.9066\n",
      "Epoch 30/30\n",
      "30945/30945 [==============================] - 23s 736us/step - loss: 0.3190 - acc: 0.9017\n",
      "15473/15473 [==============================] - 14s 928us/step\n",
      "30945/30945 [==============================] - 22s 697us/step\n",
      "[CV] .................... epochs=30, lr=0.002, nodes=16, total=13.1min\n",
      "[CV] epochs=30, lr=0.002, nodes=16 ...................................\n",
      "Epoch 1/30\n",
      "30946/30946 [==============================] - 35s 1ms/step - loss: 0.3600 - acc: 0.9842\n",
      "Epoch 2/30\n",
      "30946/30946 [==============================] - 24s 770us/step - loss: 0.3391 - acc: 0.9810\n",
      "Epoch 3/30\n",
      "30946/30946 [==============================] - 23s 735us/step - loss: 0.3342 - acc: 0.9774\n",
      "Epoch 4/30\n",
      "30946/30946 [==============================] - 23s 743us/step - loss: 0.3297 - acc: 0.9725\n",
      "Epoch 5/30\n",
      "30946/30946 [==============================] - 24s 783us/step - loss: 0.3251 - acc: 0.9671\n",
      "Epoch 6/30\n",
      "30946/30946 [==============================] - 25s 807us/step - loss: 0.3229 - acc: 0.9669\n",
      "Epoch 7/30\n",
      "30946/30946 [==============================] - 27s 873us/step - loss: 0.3201 - acc: 0.9633\n",
      "Epoch 8/30\n",
      "30946/30946 [==============================] - 28s 890us/step - loss: 0.3180 - acc: 0.9637\n",
      "Epoch 9/30\n",
      "30946/30946 [==============================] - 26s 853us/step - loss: 0.3145 - acc: 0.9584\n",
      "Epoch 10/30\n",
      "30946/30946 [==============================] - 26s 849us/step - loss: 0.3161 - acc: 0.9579\n",
      "Epoch 11/30\n",
      "30946/30946 [==============================] - 26s 846us/step - loss: 0.3142 - acc: 0.9604\n",
      "Epoch 12/30\n",
      "30946/30946 [==============================] - 27s 864us/step - loss: 0.3126 - acc: 0.9531\n",
      "Epoch 13/30\n",
      "30946/30946 [==============================] - 27s 863us/step - loss: 0.3107 - acc: 0.9509\n",
      "Epoch 14/30\n",
      "30946/30946 [==============================] - 26s 856us/step - loss: 0.3107 - acc: 0.9516\n",
      "Epoch 15/30\n",
      "30946/30946 [==============================] - 23s 753us/step - loss: 0.3085 - acc: 0.9494\n",
      "Epoch 16/30\n",
      "30946/30946 [==============================] - 23s 756us/step - loss: 0.3089 - acc: 0.9456\n",
      "Epoch 17/30\n",
      "30946/30946 [==============================] - 24s 776us/step - loss: 0.3087 - acc: 0.9434\n",
      "Epoch 18/30\n",
      "30946/30946 [==============================] - 25s 823us/step - loss: 0.3064 - acc: 0.9389\n",
      "Epoch 19/30\n",
      "30946/30946 [==============================] - 25s 793us/step - loss: 0.3068 - acc: 0.9345\n",
      "Epoch 20/30\n",
      "30946/30946 [==============================] - 23s 730us/step - loss: 0.3060 - acc: 0.9331\n",
      "Epoch 21/30\n",
      "30946/30946 [==============================] - 22s 723us/step - loss: 0.3056 - acc: 0.9302\n",
      "Epoch 22/30\n",
      "30946/30946 [==============================] - 22s 720us/step - loss: 0.3064 - acc: 0.9309\n",
      "Epoch 23/30\n",
      "30946/30946 [==============================] - 22s 717us/step - loss: 0.3073 - acc: 0.9271\n",
      "Epoch 24/30\n",
      "30946/30946 [==============================] - 23s 728us/step - loss: 0.3031 - acc: 0.9199\n",
      "Epoch 25/30\n",
      "30946/30946 [==============================] - 23s 736us/step - loss: 0.3052 - acc: 0.9214\n",
      "Epoch 26/30\n",
      "30946/30946 [==============================] - 23s 735us/step - loss: 0.3073 - acc: 0.9184\n",
      "Epoch 27/30\n",
      "30946/30946 [==============================] - 23s 734us/step - loss: 0.3039 - acc: 0.9135\n",
      "Epoch 28/30\n",
      "30946/30946 [==============================] - 23s 751us/step - loss: 0.3062 - acc: 0.9113\n",
      "Epoch 29/30\n",
      "30946/30946 [==============================] - 24s 781us/step - loss: 0.3033 - acc: 0.9131\n",
      "Epoch 30/30\n",
      "30946/30946 [==============================] - 25s 806us/step - loss: 0.3067 - acc: 0.9145\n",
      "15472/15472 [==============================] - 15s 948us/step\n",
      "30946/30946 [==============================] - 22s 712us/step\n",
      "[CV] .................... epochs=30, lr=0.002, nodes=16, total=13.2min\n",
      "[CV] epochs=30, lr=0.002, nodes=32 ...................................\n",
      "Epoch 1/30\n",
      "30945/30945 [==============================] - 47s 2ms/step - loss: 0.3546 - acc: 0.9650\n",
      "Epoch 2/30\n",
      "30945/30945 [==============================] - 36s 1ms/step - loss: 0.3343 - acc: 0.9787\n",
      "Epoch 3/30\n",
      "30945/30945 [==============================] - 36s 1ms/step - loss: 0.3268 - acc: 0.9739\n",
      "Epoch 4/30\n",
      "30945/30945 [==============================] - 37s 1ms/step - loss: 0.3207 - acc: 0.9700\n",
      "Epoch 5/30\n",
      "30945/30945 [==============================] - 33s 1ms/step - loss: 0.3158 - acc: 0.9682\n",
      "Epoch 6/30\n",
      "30945/30945 [==============================] - 33s 1ms/step - loss: 0.3129 - acc: 0.9642\n",
      "Epoch 7/30\n",
      "30945/30945 [==============================] - 35s 1ms/step - loss: 0.3070 - acc: 0.9605\n",
      "Epoch 8/30\n",
      "30945/30945 [==============================] - 35s 1ms/step - loss: 0.3069 - acc: 0.9552\n",
      "Epoch 9/30\n",
      "30945/30945 [==============================] - 35s 1ms/step - loss: 0.3050 - acc: 0.9527\n",
      "Epoch 10/30\n",
      "30945/30945 [==============================] - 35s 1ms/step - loss: 0.3034 - acc: 0.9472\n",
      "Epoch 11/30\n",
      "30945/30945 [==============================] - 36s 1ms/step - loss: 0.3019 - acc: 0.9452\n",
      "Epoch 12/30\n",
      "30945/30945 [==============================] - 36s 1ms/step - loss: 0.3004 - acc: 0.9399\n",
      "Epoch 13/30\n",
      "30945/30945 [==============================] - 36s 1ms/step - loss: 0.2995 - acc: 0.9370\n",
      "Epoch 14/30\n",
      "30945/30945 [==============================] - 37s 1ms/step - loss: 0.2995 - acc: 0.9320\n",
      "Epoch 15/30\n",
      "30945/30945 [==============================] - 35s 1ms/step - loss: 0.2977 - acc: 0.9234\n",
      "Epoch 16/30\n",
      "30945/30945 [==============================] - 34s 1ms/step - loss: 0.3000 - acc: 0.9205\n",
      "Epoch 17/30\n",
      "30945/30945 [==============================] - 34s 1ms/step - loss: 0.2974 - acc: 0.9201\n",
      "Epoch 18/30\n",
      "30945/30945 [==============================] - 35s 1ms/step - loss: 0.2962 - acc: 0.9134\n",
      "Epoch 19/30\n",
      "30945/30945 [==============================] - 35s 1ms/step - loss: 0.2970 - acc: 0.9145\n",
      "Epoch 20/30\n",
      "30945/30945 [==============================] - 36s 1ms/step - loss: 0.2959 - acc: 0.9054\n",
      "Epoch 21/30\n",
      "30945/30945 [==============================] - 35s 1ms/step - loss: 0.2960 - acc: 0.9036\n",
      "Epoch 22/30\n",
      "30945/30945 [==============================] - 36s 1ms/step - loss: 0.2959 - acc: 0.8992\n",
      "Epoch 23/30\n",
      "30945/30945 [==============================] - 34s 1ms/step - loss: 0.2965 - acc: 0.8946\n",
      "Epoch 24/30\n",
      "30945/30945 [==============================] - 34s 1ms/step - loss: 0.2940 - acc: 0.8987\n",
      "Epoch 25/30\n",
      "30945/30945 [==============================] - 34s 1ms/step - loss: 0.2964 - acc: 0.8950\n",
      "Epoch 26/30\n",
      "30945/30945 [==============================] - 35s 1ms/step - loss: 0.2954 - acc: 0.8943\n",
      "Epoch 27/30\n",
      "30945/30945 [==============================] - 34s 1ms/step - loss: 0.2983 - acc: 0.8937\n",
      "Epoch 28/30\n",
      "30945/30945 [==============================] - 35s 1ms/step - loss: 0.2967 - acc: 0.8873\n",
      "Epoch 29/30\n",
      "30945/30945 [==============================] - 35s 1ms/step - loss: 0.2968 - acc: 0.8805\n",
      "Epoch 30/30\n",
      "30945/30945 [==============================] - 35s 1ms/step - loss: 0.2963 - acc: 0.8781\n",
      "15473/15473 [==============================] - 15s 988us/step\n",
      "30945/30945 [==============================] - 25s 802us/step\n",
      "[CV] .................... epochs=30, lr=0.002, nodes=32, total=18.5min\n",
      "[CV] epochs=30, lr=0.002, nodes=32 ...................................\n",
      "Epoch 1/30\n",
      "30945/30945 [==============================] - 46s 1ms/step - loss: 0.3639 - acc: 0.9800\n",
      "Epoch 2/30\n",
      "30945/30945 [==============================] - 37s 1ms/step - loss: 0.3466 - acc: 0.9783\n",
      "Epoch 3/30\n",
      "30945/30945 [==============================] - 35s 1ms/step - loss: 0.3391 - acc: 0.9736\n",
      "Epoch 4/30\n",
      "30945/30945 [==============================] - 35s 1ms/step - loss: 0.3343 - acc: 0.9703\n",
      "Epoch 5/30\n",
      "30945/30945 [==============================] - 34s 1ms/step - loss: 0.3293 - acc: 0.9663\n",
      "Epoch 6/30\n",
      "30945/30945 [==============================] - 35s 1ms/step - loss: 0.3249 - acc: 0.9633\n",
      "Epoch 7/30\n",
      "30945/30945 [==============================] - 38s 1ms/step - loss: 0.3230 - acc: 0.9597\n",
      "Epoch 8/30\n",
      "30945/30945 [==============================] - 38s 1ms/step - loss: 0.3204 - acc: 0.9547\n",
      "Epoch 9/30\n",
      "30945/30945 [==============================] - 36s 1ms/step - loss: 0.3177 - acc: 0.9534\n",
      "Epoch 10/30\n",
      "30945/30945 [==============================] - 38s 1ms/step - loss: 0.3169 - acc: 0.9524\n",
      "Epoch 11/30\n",
      "30945/30945 [==============================] - 34s 1ms/step - loss: 0.3144 - acc: 0.9459\n",
      "Epoch 12/30\n",
      "30945/30945 [==============================] - 33s 1ms/step - loss: 0.3121 - acc: 0.9387\n",
      "Epoch 13/30\n",
      "30945/30945 [==============================] - 33s 1ms/step - loss: 0.3092 - acc: 0.9409\n",
      "Epoch 14/30\n",
      "30945/30945 [==============================] - 33s 1ms/step - loss: 0.3103 - acc: 0.9352\n",
      "Epoch 15/30\n",
      "30945/30945 [==============================] - 33s 1ms/step - loss: 0.3087 - acc: 0.9338\n",
      "Epoch 16/30\n",
      "30945/30945 [==============================] - 33s 1ms/step - loss: 0.3084 - acc: 0.9295\n",
      "Epoch 17/30\n",
      "30945/30945 [==============================] - 35s 1ms/step - loss: 0.3073 - acc: 0.9227\n",
      "Epoch 18/30\n",
      "30945/30945 [==============================] - 34s 1ms/step - loss: 0.3078 - acc: 0.9173\n",
      "Epoch 19/30\n",
      "30945/30945 [==============================] - 34s 1ms/step - loss: 0.3067 - acc: 0.9206\n",
      "Epoch 20/30\n",
      "30945/30945 [==============================] - 33s 1ms/step - loss: 0.3056 - acc: 0.9124\n",
      "Epoch 21/30\n",
      "30945/30945 [==============================] - 33s 1ms/step - loss: 0.3065 - acc: 0.9114\n",
      "Epoch 22/30\n",
      "30945/30945 [==============================] - 36s 1ms/step - loss: 0.3061 - acc: 0.9024\n",
      "Epoch 23/30\n",
      "30945/30945 [==============================] - 36s 1ms/step - loss: 0.3012 - acc: 0.9007\n",
      "Epoch 24/30\n",
      "30945/30945 [==============================] - 35s 1ms/step - loss: 0.3038 - acc: 0.8993\n",
      "Epoch 25/30\n",
      "30945/30945 [==============================] - 32s 1ms/step - loss: 0.3030 - acc: 0.8960\n",
      "Epoch 26/30\n",
      "30945/30945 [==============================] - 31s 1ms/step - loss: 0.3036 - acc: 0.8969\n",
      "Epoch 27/30\n",
      "30945/30945 [==============================] - 35s 1ms/step - loss: 0.3025 - acc: 0.8979\n",
      "Epoch 28/30\n",
      "30945/30945 [==============================] - 36s 1ms/step - loss: 0.3017 - acc: 0.8970\n",
      "Epoch 29/30\n",
      "30945/30945 [==============================] - 36s 1ms/step - loss: 0.3038 - acc: 0.8949\n",
      "Epoch 30/30\n",
      "30945/30945 [==============================] - 36s 1ms/step - loss: 0.3027 - acc: 0.8926\n",
      "15473/15473 [==============================] - 15s 999us/step\n",
      "30945/30945 [==============================] - 27s 883us/step\n",
      "[CV] .................... epochs=30, lr=0.002, nodes=32, total=18.3min\n",
      "[CV] epochs=30, lr=0.002, nodes=32 ...................................\n",
      "Epoch 1/30\n",
      "30946/30946 [==============================] - 51s 2ms/step - loss: 0.3534 - acc: 0.9795\n",
      "Epoch 2/30\n",
      "30946/30946 [==============================] - 37s 1ms/step - loss: 0.3335 - acc: 0.9784\n",
      "Epoch 3/30\n",
      "30946/30946 [==============================] - 36s 1ms/step - loss: 0.3252 - acc: 0.9720\n",
      "Epoch 4/30\n",
      "30946/30946 [==============================] - 37s 1ms/step - loss: 0.3202 - acc: 0.9669\n",
      "Epoch 5/30\n",
      "30946/30946 [==============================] - 37s 1ms/step - loss: 0.3157 - acc: 0.9632\n",
      "Epoch 6/30\n",
      "30946/30946 [==============================] - 34s 1ms/step - loss: 0.3133 - acc: 0.9530\n",
      "Epoch 7/30\n",
      "30946/30946 [==============================] - 34s 1ms/step - loss: 0.3094 - acc: 0.9508\n",
      "Epoch 8/30\n",
      "30946/30946 [==============================] - 33s 1ms/step - loss: 0.3069 - acc: 0.9444\n",
      "Epoch 9/30\n",
      "30946/30946 [==============================] - 34s 1ms/step - loss: 0.3069 - acc: 0.9408\n",
      "Epoch 10/30\n",
      "30946/30946 [==============================] - 34s 1ms/step - loss: 0.3023 - acc: 0.9346\n",
      "Epoch 11/30\n",
      "30946/30946 [==============================] - 33s 1ms/step - loss: 0.3026 - acc: 0.9374\n",
      "Epoch 12/30\n",
      "30946/30946 [==============================] - 32s 1ms/step - loss: 0.3023 - acc: 0.9293\n",
      "Epoch 13/30\n",
      "30946/30946 [==============================] - 36s 1ms/step - loss: 0.2992 - acc: 0.9259\n",
      "Epoch 14/30\n",
      "30946/30946 [==============================] - 34s 1ms/step - loss: 0.3001 - acc: 0.9218\n",
      "Epoch 15/30\n",
      "30946/30946 [==============================] - 35s 1ms/step - loss: 0.3017 - acc: 0.9209\n",
      "Epoch 16/30\n",
      "30946/30946 [==============================] - 35s 1ms/step - loss: 0.2981 - acc: 0.9143\n",
      "Epoch 17/30\n",
      "30946/30946 [==============================] - 38s 1ms/step - loss: 0.2976 - acc: 0.9133\n",
      "Epoch 18/30\n",
      "30946/30946 [==============================] - 36s 1ms/step - loss: 0.2984 - acc: 0.9074\n",
      "Epoch 19/30\n",
      "30946/30946 [==============================] - 36s 1ms/step - loss: 0.2974 - acc: 0.9064\n",
      "Epoch 20/30\n",
      "30946/30946 [==============================] - 36s 1ms/step - loss: 0.2970 - acc: 0.9022\n",
      "Epoch 21/30\n",
      "30946/30946 [==============================] - 36s 1ms/step - loss: 0.2972 - acc: 0.9003\n",
      "Epoch 22/30\n",
      "30946/30946 [==============================] - 36s 1ms/step - loss: 0.2958 - acc: 0.8946\n",
      "Epoch 23/30\n",
      "30946/30946 [==============================] - 36s 1ms/step - loss: 0.2990 - acc: 0.8967\n",
      "Epoch 24/30\n",
      "30946/30946 [==============================] - 36s 1ms/step - loss: 0.2977 - acc: 0.8912\n",
      "Epoch 25/30\n",
      "30946/30946 [==============================] - 36s 1ms/step - loss: 0.2978 - acc: 0.8885\n",
      "Epoch 26/30\n",
      "30946/30946 [==============================] - 36s 1ms/step - loss: 0.2995 - acc: 0.8906\n",
      "Epoch 27/30\n",
      "30946/30946 [==============================] - 36s 1ms/step - loss: 0.2978 - acc: 0.8923\n",
      "Epoch 28/30\n",
      "30946/30946 [==============================] - 36s 1ms/step - loss: 0.2968 - acc: 0.8865\n",
      "Epoch 29/30\n",
      "30946/30946 [==============================] - 36s 1ms/step - loss: 0.2954 - acc: 0.8839\n",
      "Epoch 30/30\n",
      "30946/30946 [==============================] - 36s 1ms/step - loss: 0.2958 - acc: 0.8816\n",
      "15472/15472 [==============================] - 17s 1ms/step\n",
      "30946/30946 [==============================] - 25s 814us/step\n",
      "[CV] .................... epochs=30, lr=0.002, nodes=32, total=18.8min\n",
      "[CV] epochs=30, lr=0.002, nodes=64 ...................................\n",
      "Epoch 1/30\n",
      "30945/30945 [==============================] - 73s 2ms/step - loss: 0.3522 - acc: 0.9786\n",
      "Epoch 2/30\n",
      "30945/30945 [==============================] - 60s 2ms/step - loss: 0.3324 - acc: 0.9738\n",
      "Epoch 3/30\n",
      "30945/30945 [==============================] - 62s 2ms/step - loss: 0.3228 - acc: 0.9688\n",
      "Epoch 4/30\n",
      "30945/30945 [==============================] - 62s 2ms/step - loss: 0.3155 - acc: 0.9634\n",
      "Epoch 5/30\n",
      "30945/30945 [==============================] - 59s 2ms/step - loss: 0.3111 - acc: 0.9595\n",
      "Epoch 6/30\n",
      "30945/30945 [==============================] - 55s 2ms/step - loss: 0.3061 - acc: 0.9542\n",
      "Epoch 7/30\n",
      "30945/30945 [==============================] - 59s 2ms/step - loss: 0.3020 - acc: 0.9460\n",
      "Epoch 8/30\n",
      "30945/30945 [==============================] - 65s 2ms/step - loss: 0.3013 - acc: 0.9469\n",
      "Epoch 9/30\n",
      "30945/30945 [==============================] - 61s 2ms/step - loss: 0.2991 - acc: 0.9455\n",
      "Epoch 10/30\n",
      "30945/30945 [==============================] - 60s 2ms/step - loss: 0.2968 - acc: 0.9392\n",
      "Epoch 11/30\n",
      "30945/30945 [==============================] - 59s 2ms/step - loss: 0.2961 - acc: 0.9323\n",
      "Epoch 12/30\n",
      "30945/30945 [==============================] - 61s 2ms/step - loss: 0.2934 - acc: 0.9283\n",
      "Epoch 13/30\n",
      "30945/30945 [==============================] - 57s 2ms/step - loss: 0.2946 - acc: 0.9304\n",
      "Epoch 14/30\n",
      "30945/30945 [==============================] - 57s 2ms/step - loss: 0.2959 - acc: 0.9210\n",
      "Epoch 15/30\n",
      "30945/30945 [==============================] - 57s 2ms/step - loss: 0.2945 - acc: 0.9184\n",
      "Epoch 16/30\n",
      "30945/30945 [==============================] - 59s 2ms/step - loss: 0.2938 - acc: 0.9195\n",
      "Epoch 17/30\n",
      "30945/30945 [==============================] - 60s 2ms/step - loss: 0.2947 - acc: 0.9106\n",
      "Epoch 18/30\n",
      "30945/30945 [==============================] - 63s 2ms/step - loss: 0.2932 - acc: 0.9123\n",
      "Epoch 19/30\n",
      "30945/30945 [==============================] - 64s 2ms/step - loss: 0.2924 - acc: 0.9026\n",
      "Epoch 20/30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30945/30945 [==============================] - 64s 2ms/step - loss: 0.2955 - acc: 0.9027\n",
      "Epoch 21/30\n",
      "30945/30945 [==============================] - 65s 2ms/step - loss: 0.2927 - acc: 0.9015\n",
      "Epoch 22/30\n",
      "30945/30945 [==============================] - 64s 2ms/step - loss: 0.2943 - acc: 0.9038\n",
      "Epoch 23/30\n",
      "30945/30945 [==============================] - 63s 2ms/step - loss: 0.2930 - acc: 0.8963\n",
      "Epoch 24/30\n",
      "30945/30945 [==============================] - 63s 2ms/step - loss: 0.2946 - acc: 0.8939\n",
      "Epoch 25/30\n",
      "30945/30945 [==============================] - 64s 2ms/step - loss: 0.2956 - acc: 0.8918\n",
      "Epoch 26/30\n",
      "30945/30945 [==============================] - 64s 2ms/step - loss: 0.2933 - acc: 0.8879\n",
      "Epoch 27/30\n",
      "30945/30945 [==============================] - 64s 2ms/step - loss: 0.2946 - acc: 0.8891\n",
      "Epoch 28/30\n",
      "30945/30945 [==============================] - 59s 2ms/step - loss: 0.2941 - acc: 0.8809\n",
      "Epoch 29/30\n",
      "30945/30945 [==============================] - 55s 2ms/step - loss: 0.2964 - acc: 0.8816\n",
      "Epoch 30/30\n",
      "30945/30945 [==============================] - 56s 2ms/step - loss: 0.2965 - acc: 0.8790\n",
      "15473/15473 [==============================] - 16s 1ms/step\n",
      "30945/30945 [==============================] - 25s 798us/step\n",
      "[CV] .................... epochs=30, lr=0.002, nodes=64, total=31.4min\n",
      "[CV] epochs=30, lr=0.002, nodes=64 ...................................\n",
      "Epoch 1/30\n",
      "30945/30945 [==============================] - 66s 2ms/step - loss: 0.3608 - acc: 0.9783\n",
      "Epoch 2/30\n",
      "30945/30945 [==============================] - 55s 2ms/step - loss: 0.3404 - acc: 0.9753\n",
      "Epoch 3/30\n",
      "30945/30945 [==============================] - 55s 2ms/step - loss: 0.3316 - acc: 0.9690\n",
      "Epoch 4/30\n",
      "30945/30945 [==============================] - 55s 2ms/step - loss: 0.3247 - acc: 0.9651\n",
      "Epoch 5/30\n",
      "30945/30945 [==============================] - 56s 2ms/step - loss: 0.3196 - acc: 0.9587\n",
      "Epoch 6/30\n",
      "30945/30945 [==============================] - 54s 2ms/step - loss: 0.3160 - acc: 0.9548\n",
      "Epoch 7/30\n",
      "30945/30945 [==============================] - 55s 2ms/step - loss: 0.3116 - acc: 0.9479\n",
      "Epoch 8/30\n",
      "30945/30945 [==============================] - 56s 2ms/step - loss: 0.3099 - acc: 0.9447\n",
      "Epoch 9/30\n",
      "30945/30945 [==============================] - 55s 2ms/step - loss: 0.3073 - acc: 0.9337\n",
      "Epoch 10/30\n",
      "30945/30945 [==============================] - 56s 2ms/step - loss: 0.3059 - acc: 0.9286\n",
      "Epoch 11/30\n",
      "30945/30945 [==============================] - 56s 2ms/step - loss: 0.3023 - acc: 0.9199\n",
      "Epoch 12/30\n",
      "30945/30945 [==============================] - 56s 2ms/step - loss: 0.3040 - acc: 0.9200\n",
      "Epoch 13/30\n",
      "30945/30945 [==============================] - 56s 2ms/step - loss: 0.3043 - acc: 0.9201\n",
      "Epoch 14/30\n",
      "30945/30945 [==============================] - 55s 2ms/step - loss: 0.3026 - acc: 0.9193\n",
      "Epoch 15/30\n",
      "30945/30945 [==============================] - 55s 2ms/step - loss: 0.3014 - acc: 0.9116\n",
      "Epoch 16/30\n",
      "30945/30945 [==============================] - 55s 2ms/step - loss: 0.3038 - acc: 0.9034\n",
      "Epoch 17/30\n",
      "30945/30945 [==============================] - 55s 2ms/step - loss: 0.3022 - acc: 0.9002\n",
      "Epoch 18/30\n",
      "30945/30945 [==============================] - 56s 2ms/step - loss: 0.3032 - acc: 0.9011\n",
      "Epoch 19/30\n",
      "30945/30945 [==============================] - 56s 2ms/step - loss: 0.3014 - acc: 0.9009\n",
      "Epoch 20/30\n",
      "30945/30945 [==============================] - 55s 2ms/step - loss: 0.3030 - acc: 0.8902\n",
      "Epoch 21/30\n",
      "30945/30945 [==============================] - 55s 2ms/step - loss: 0.3022 - acc: 0.8955\n",
      "Epoch 22/30\n",
      "30945/30945 [==============================] - 56s 2ms/step - loss: 0.3016 - acc: 0.8893\n",
      "Epoch 23/30\n",
      "30945/30945 [==============================] - 56s 2ms/step - loss: 0.3042 - acc: 0.8835\n",
      "Epoch 24/30\n",
      "30945/30945 [==============================] - 56s 2ms/step - loss: 0.3032 - acc: 0.8814\n",
      "Epoch 25/30\n",
      "30945/30945 [==============================] - 56s 2ms/step - loss: 0.3009 - acc: 0.8759\n",
      "Epoch 26/30\n",
      "30945/30945 [==============================] - 56s 2ms/step - loss: 0.3025 - acc: 0.8836\n",
      "Epoch 27/30\n",
      "30945/30945 [==============================] - 56s 2ms/step - loss: 0.3007 - acc: 0.8792\n",
      "Epoch 28/30\n",
      "30945/30945 [==============================] - 55s 2ms/step - loss: 0.3042 - acc: 0.8780\n",
      "Epoch 29/30\n",
      "30945/30945 [==============================] - 56s 2ms/step - loss: 0.3036 - acc: 0.8805\n",
      "Epoch 30/30\n",
      "30945/30945 [==============================] - 55s 2ms/step - loss: 0.3029 - acc: 0.8777\n",
      "15473/15473 [==============================] - 16s 1ms/step\n",
      "30945/30945 [==============================] - 25s 809us/step\n",
      "[CV] .................... epochs=30, lr=0.002, nodes=64, total=28.7min\n",
      "[CV] epochs=30, lr=0.002, nodes=64 ...................................\n",
      "Epoch 1/30\n",
      "30946/30946 [==============================] - 66s 2ms/step - loss: 0.3521 - acc: 0.9815\n",
      "Epoch 2/30\n",
      "30946/30946 [==============================] - 55s 2ms/step - loss: 0.3292 - acc: 0.9752\n",
      "Epoch 3/30\n",
      "30946/30946 [==============================] - 54s 2ms/step - loss: 0.3206 - acc: 0.9707\n",
      "Epoch 4/30\n",
      "30946/30946 [==============================] - 55s 2ms/step - loss: 0.3153 - acc: 0.9642\n",
      "Epoch 5/30\n",
      "30946/30946 [==============================] - 55s 2ms/step - loss: 0.3089 - acc: 0.9577\n",
      "Epoch 6/30\n",
      "30946/30946 [==============================] - 55s 2ms/step - loss: 0.3056 - acc: 0.9534\n",
      "Epoch 7/30\n",
      "30946/30946 [==============================] - 54s 2ms/step - loss: 0.3027 - acc: 0.9461\n",
      "Epoch 8/30\n",
      "30946/30946 [==============================] - 56s 2ms/step - loss: 0.2992 - acc: 0.9445\n",
      "Epoch 9/30\n",
      "30946/30946 [==============================] - 55s 2ms/step - loss: 0.2966 - acc: 0.9364\n",
      "Epoch 10/30\n",
      "30946/30946 [==============================] - 55s 2ms/step - loss: 0.2964 - acc: 0.9316\n",
      "Epoch 11/30\n",
      "30946/30946 [==============================] - 55s 2ms/step - loss: 0.2946 - acc: 0.9244\n",
      "Epoch 12/30\n",
      "30946/30946 [==============================] - 55s 2ms/step - loss: 0.2947 - acc: 0.9217\n",
      "Epoch 13/30\n",
      "30946/30946 [==============================] - 55s 2ms/step - loss: 0.2934 - acc: 0.9202\n",
      "Epoch 14/30\n",
      "30946/30946 [==============================] - 55s 2ms/step - loss: 0.2952 - acc: 0.9170\n",
      "Epoch 15/30\n",
      "30946/30946 [==============================] - 55s 2ms/step - loss: 0.2936 - acc: 0.9110\n",
      "Epoch 16/30\n",
      "30946/30946 [==============================] - 55s 2ms/step - loss: 0.2959 - acc: 0.9032\n",
      "Epoch 17/30\n",
      "30946/30946 [==============================] - 55s 2ms/step - loss: 0.2966 - acc: 0.9048\n",
      "Epoch 18/30\n",
      "30946/30946 [==============================] - 55s 2ms/step - loss: 0.2938 - acc: 0.8992\n",
      "Epoch 19/30\n",
      "30946/30946 [==============================] - 56s 2ms/step - loss: 0.2930 - acc: 0.8952\n",
      "Epoch 20/30\n",
      "30946/30946 [==============================] - 55s 2ms/step - loss: 0.2944 - acc: 0.8946\n",
      "Epoch 21/30\n",
      "30946/30946 [==============================] - 55s 2ms/step - loss: 0.2964 - acc: 0.8944\n",
      "Epoch 22/30\n",
      "30946/30946 [==============================] - 56s 2ms/step - loss: 0.2959 - acc: 0.8921\n",
      "Epoch 23/30\n",
      "30946/30946 [==============================] - 56s 2ms/step - loss: 0.2962 - acc: 0.8894\n",
      "Epoch 24/30\n",
      "30946/30946 [==============================] - 56s 2ms/step - loss: 0.2992 - acc: 0.8806\n",
      "Epoch 25/30\n",
      "30946/30946 [==============================] - 54s 2ms/step - loss: 0.2951 - acc: 0.8854\n",
      "Epoch 26/30\n",
      "30946/30946 [==============================] - 55s 2ms/step - loss: 0.2989 - acc: 0.8746\n",
      "Epoch 27/30\n",
      "30946/30946 [==============================] - 55s 2ms/step - loss: 0.2943 - acc: 0.8769\n",
      "Epoch 28/30\n",
      "30946/30946 [==============================] - 55s 2ms/step - loss: 0.2967 - acc: 0.8761\n",
      "Epoch 29/30\n",
      "30946/30946 [==============================] - 55s 2ms/step - loss: 0.2980 - acc: 0.8686\n",
      "Epoch 30/30\n",
      "30946/30946 [==============================] - 56s 2ms/step - loss: 0.2970 - acc: 0.8715\n",
      "15472/15472 [==============================] - 16s 1ms/step\n",
      "30946/30946 [==============================] - 25s 801us/step\n",
      "[CV] .................... epochs=30, lr=0.002, nodes=64, total=28.6min\n",
      "[CV] epochs=30, lr=0.003, nodes=16 ...................................\n",
      "Epoch 1/30\n",
      "30945/30945 [==============================] - 37s 1ms/step - loss: 0.3552 - acc: 0.9788\n",
      "Epoch 2/30\n",
      "30945/30945 [==============================] - 24s 791us/step - loss: 0.3379 - acc: 0.9803\n",
      "Epoch 3/30\n",
      "30945/30945 [==============================] - 24s 764us/step - loss: 0.3338 - acc: 0.9733\n",
      "Epoch 4/30\n",
      "30945/30945 [==============================] - 23s 755us/step - loss: 0.3298 - acc: 0.9698\n",
      "Epoch 5/30\n",
      "30945/30945 [==============================] - 24s 768us/step - loss: 0.3234 - acc: 0.9653\n",
      "Epoch 6/30\n",
      "30945/30945 [==============================] - 24s 762us/step - loss: 0.3198 - acc: 0.9593\n",
      "Epoch 7/30\n",
      "30945/30945 [==============================] - 24s 761us/step - loss: 0.3183 - acc: 0.9598\n",
      "Epoch 8/30\n",
      "30945/30945 [==============================] - 23s 756us/step - loss: 0.3161 - acc: 0.9526\n",
      "Epoch 9/30\n",
      "30945/30945 [==============================] - 24s 764us/step - loss: 0.3151 - acc: 0.9533\n",
      "Epoch 10/30\n",
      "30945/30945 [==============================] - 23s 753us/step - loss: 0.3122 - acc: 0.9486\n",
      "Epoch 11/30\n",
      "30945/30945 [==============================] - 23s 756us/step - loss: 0.3115 - acc: 0.9469\n",
      "Epoch 12/30\n",
      "30945/30945 [==============================] - 23s 755us/step - loss: 0.3113 - acc: 0.9472\n",
      "Epoch 13/30\n",
      "30945/30945 [==============================] - 24s 765us/step - loss: 0.3092 - acc: 0.9427\n",
      "Epoch 14/30\n",
      "30945/30945 [==============================] - 24s 763us/step - loss: 0.3089 - acc: 0.9408\n",
      "Epoch 15/30\n",
      "30945/30945 [==============================] - 24s 765us/step - loss: 0.3093 - acc: 0.9362\n",
      "Epoch 16/30\n",
      "30945/30945 [==============================] - 24s 764us/step - loss: 0.3066 - acc: 0.9349\n",
      "Epoch 17/30\n",
      "30945/30945 [==============================] - 23s 751us/step - loss: 0.3079 - acc: 0.9322\n",
      "Epoch 18/30\n",
      "30945/30945 [==============================] - 24s 769us/step - loss: 0.3054 - acc: 0.9265\n",
      "Epoch 19/30\n",
      "30945/30945 [==============================] - 23s 759us/step - loss: 0.3080 - acc: 0.9271\n",
      "Epoch 20/30\n",
      "30945/30945 [==============================] - 23s 758us/step - loss: 0.3094 - acc: 0.9220\n",
      "Epoch 21/30\n",
      "30945/30945 [==============================] - 23s 759us/step - loss: 0.3074 - acc: 0.9211\n",
      "Epoch 22/30\n",
      "30945/30945 [==============================] - 23s 744us/step - loss: 0.3068 - acc: 0.9216\n",
      "Epoch 23/30\n",
      "30945/30945 [==============================] - 24s 761us/step - loss: 0.3068 - acc: 0.9140\n",
      "Epoch 24/30\n",
      "30945/30945 [==============================] - 23s 759us/step - loss: 0.3081 - acc: 0.9069\n",
      "Epoch 25/30\n",
      "30945/30945 [==============================] - 23s 756us/step - loss: 0.3054 - acc: 0.9058\n",
      "Epoch 26/30\n",
      "30945/30945 [==============================] - 24s 760us/step - loss: 0.3078 - acc: 0.9099\n",
      "Epoch 27/30\n",
      "30945/30945 [==============================] - 23s 744us/step - loss: 0.3080 - acc: 0.9012\n",
      "Epoch 28/30\n",
      "30945/30945 [==============================] - 23s 758us/step - loss: 0.3075 - acc: 0.9003\n",
      "Epoch 29/30\n",
      "30945/30945 [==============================] - 24s 765us/step - loss: 0.3075 - acc: 0.8988\n",
      "Epoch 30/30\n",
      "30945/30945 [==============================] - 24s 760us/step - loss: 0.3090 - acc: 0.9051\n",
      "15473/15473 [==============================] - 15s 948us/step\n",
      "30945/30945 [==============================] - 22s 704us/step\n",
      "[CV] .................... epochs=30, lr=0.003, nodes=16, total=12.8min\n",
      "[CV] epochs=30, lr=0.003, nodes=16 ...................................\n",
      "Epoch 1/30\n",
      "30945/30945 [==============================] - 36s 1ms/step - loss: 0.3647 - acc: 0.9788\n",
      "Epoch 2/30\n",
      "30945/30945 [==============================] - 25s 815us/step - loss: 0.3490 - acc: 0.9827\n",
      "Epoch 3/30\n",
      "30945/30945 [==============================] - 24s 767us/step - loss: 0.3428 - acc: 0.9781\n",
      "Epoch 4/30\n",
      "30945/30945 [==============================] - 24s 764us/step - loss: 0.3387 - acc: 0.9751\n",
      "Epoch 5/30\n",
      "30945/30945 [==============================] - 24s 772us/step - loss: 0.3358 - acc: 0.9687\n",
      "Epoch 6/30\n",
      "30945/30945 [==============================] - 24s 772us/step - loss: 0.3309 - acc: 0.9692\n",
      "Epoch 7/30\n",
      "30945/30945 [==============================] - 23s 758us/step - loss: 0.3300 - acc: 0.9603\n",
      "Epoch 8/30\n",
      "30945/30945 [==============================] - 23s 756us/step - loss: 0.3284 - acc: 0.9554\n",
      "Epoch 9/30\n",
      "30945/30945 [==============================] - 24s 761us/step - loss: 0.3267 - acc: 0.9543\n",
      "Epoch 10/30\n",
      "30945/30945 [==============================] - 24s 767us/step - loss: 0.3240 - acc: 0.9447\n",
      "Epoch 11/30\n",
      "30945/30945 [==============================] - 24s 766us/step - loss: 0.3238 - acc: 0.9429\n",
      "Epoch 12/30\n",
      "30945/30945 [==============================] - 24s 769us/step - loss: 0.3221 - acc: 0.9407\n",
      "Epoch 13/30\n",
      "30945/30945 [==============================] - 24s 768us/step - loss: 0.3227 - acc: 0.9406\n",
      "Epoch 14/30\n",
      "30945/30945 [==============================] - 24s 760us/step - loss: 0.3225 - acc: 0.9332\n",
      "Epoch 15/30\n",
      "30945/30945 [==============================] - 24s 761us/step - loss: 0.3229 - acc: 0.9350\n",
      "Epoch 16/30\n",
      "30945/30945 [==============================] - 24s 763us/step - loss: 0.3233 - acc: 0.9295\n",
      "Epoch 17/30\n",
      "30945/30945 [==============================] - 24s 763us/step - loss: 0.3220 - acc: 0.9291\n",
      "Epoch 18/30\n",
      "30945/30945 [==============================] - 24s 770us/step - loss: 0.3219 - acc: 0.9171\n",
      "Epoch 19/30\n",
      "30945/30945 [==============================] - 24s 761us/step - loss: 0.3217 - acc: 0.9240\n",
      "Epoch 20/30\n",
      "30945/30945 [==============================] - 24s 770us/step - loss: 0.3239 - acc: 0.9238\n",
      "Epoch 21/30\n",
      "30945/30945 [==============================] - 24s 764us/step - loss: 0.3242 - acc: 0.9209\n",
      "Epoch 22/30\n",
      "30945/30945 [==============================] - 24s 764us/step - loss: 0.3223 - acc: 0.9182\n",
      "Epoch 23/30\n",
      "30945/30945 [==============================] - 23s 753us/step - loss: 0.3202 - acc: 0.9169\n",
      "Epoch 24/30\n",
      "30945/30945 [==============================] - 23s 741us/step - loss: 0.3213 - acc: 0.9140\n",
      "Epoch 25/30\n",
      "30945/30945 [==============================] - 24s 760us/step - loss: 0.3218 - acc: 0.9163\n",
      "Epoch 26/30\n",
      "30945/30945 [==============================] - 23s 755us/step - loss: 0.3235 - acc: 0.9107\n",
      "Epoch 27/30\n",
      "30945/30945 [==============================] - 23s 759us/step - loss: 0.3246 - acc: 0.8952\n",
      "Epoch 28/30\n",
      "30945/30945 [==============================] - 23s 754us/step - loss: 0.3231 - acc: 0.9058\n",
      "Epoch 29/30\n",
      "30945/30945 [==============================] - 25s 796us/step - loss: 0.3230 - acc: 0.9040\n",
      "Epoch 30/30\n",
      "30945/30945 [==============================] - 24s 774us/step - loss: 0.3245 - acc: 0.9030\n",
      "15473/15473 [==============================] - 15s 975us/step\n",
      "30945/30945 [==============================] - 22s 697us/step\n",
      "[CV] .................... epochs=30, lr=0.003, nodes=16, total=12.9min\n",
      "[CV] epochs=30, lr=0.003, nodes=16 ...................................\n",
      "Epoch 1/30\n",
      "30946/30946 [==============================] - 37s 1ms/step - loss: 0.3561 - acc: 0.9680\n",
      "Epoch 2/30\n",
      "30946/30946 [==============================] - 24s 776us/step - loss: 0.3396 - acc: 0.9843\n",
      "Epoch 3/30\n",
      "30946/30946 [==============================] - 23s 750us/step - loss: 0.3345 - acc: 0.9782\n",
      "Epoch 4/30\n",
      "30946/30946 [==============================] - 23s 755us/step - loss: 0.3292 - acc: 0.9704\n",
      "Epoch 5/30\n",
      "30946/30946 [==============================] - 23s 748us/step - loss: 0.3241 - acc: 0.9654\n",
      "Epoch 6/30\n",
      "30946/30946 [==============================] - 23s 748us/step - loss: 0.3206 - acc: 0.9656\n",
      "Epoch 7/30\n",
      "30946/30946 [==============================] - 24s 765us/step - loss: 0.3193 - acc: 0.9626\n",
      "Epoch 8/30\n",
      "30946/30946 [==============================] - 23s 746us/step - loss: 0.3168 - acc: 0.9569\n",
      "Epoch 9/30\n",
      "30946/30946 [==============================] - 23s 748us/step - loss: 0.3149 - acc: 0.9568\n",
      "Epoch 10/30\n",
      "30946/30946 [==============================] - 24s 767us/step - loss: 0.3144 - acc: 0.9563\n",
      "Epoch 11/30\n",
      "30946/30946 [==============================] - 23s 750us/step - loss: 0.3108 - acc: 0.9521\n",
      "Epoch 12/30\n",
      "30946/30946 [==============================] - 24s 763us/step - loss: 0.3087 - acc: 0.9476\n",
      "Epoch 13/30\n",
      "30946/30946 [==============================] - 23s 746us/step - loss: 0.3081 - acc: 0.9455\n",
      "Epoch 14/30\n",
      "30946/30946 [==============================] - 23s 748us/step - loss: 0.3091 - acc: 0.9383\n",
      "Epoch 15/30\n",
      "30946/30946 [==============================] - 23s 748us/step - loss: 0.3061 - acc: 0.9335\n",
      "Epoch 16/30\n",
      "30946/30946 [==============================] - 23s 741us/step - loss: 0.3055 - acc: 0.9350\n",
      "Epoch 17/30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30946/30946 [==============================] - 23s 745us/step - loss: 0.3050 - acc: 0.9294\n",
      "Epoch 18/30\n",
      "30946/30946 [==============================] - 23s 749us/step - loss: 0.3043 - acc: 0.9247\n",
      "Epoch 19/30\n",
      "30946/30946 [==============================] - 23s 743us/step - loss: 0.3011 - acc: 0.9232\n",
      "Epoch 20/30\n",
      "30946/30946 [==============================] - 23s 755us/step - loss: 0.3019 - acc: 0.9242\n",
      "Epoch 21/30\n",
      "30946/30946 [==============================] - 24s 762us/step - loss: 0.3025 - acc: 0.9211\n",
      "Epoch 22/30\n",
      "30946/30946 [==============================] - 23s 751us/step - loss: 0.2993 - acc: 0.9179\n",
      "Epoch 23/30\n",
      "30946/30946 [==============================] - 23s 754us/step - loss: 0.3013 - acc: 0.9133\n",
      "Epoch 24/30\n",
      "30946/30946 [==============================] - 23s 754us/step - loss: 0.2995 - acc: 0.9096\n",
      "Epoch 25/30\n",
      "30946/30946 [==============================] - 23s 743us/step - loss: 0.2999 - acc: 0.9058\n",
      "Epoch 26/30\n",
      "30946/30946 [==============================] - 23s 742us/step - loss: 0.2993 - acc: 0.9064\n",
      "Epoch 27/30\n",
      "30946/30946 [==============================] - 23s 739us/step - loss: 0.3015 - acc: 0.9016\n",
      "Epoch 28/30\n",
      "30946/30946 [==============================] - 23s 757us/step - loss: 0.3023 - acc: 0.9017\n",
      "Epoch 29/30\n",
      "30946/30946 [==============================] - 24s 761us/step - loss: 0.3014 - acc: 0.8974\n",
      "Epoch 30/30\n",
      "30946/30946 [==============================] - 23s 751us/step - loss: 0.3022 - acc: 0.8960\n",
      "15472/15472 [==============================] - 15s 949us/step\n",
      "30946/30946 [==============================] - 22s 699us/step\n",
      "[CV] .................... epochs=30, lr=0.003, nodes=16, total=12.7min\n",
      "[CV] epochs=30, lr=0.003, nodes=32 ...................................\n",
      "Epoch 1/30\n",
      "30945/30945 [==============================] - 46s 1ms/step - loss: 0.3515 - acc: 0.9801\n",
      "Epoch 2/30\n",
      "30945/30945 [==============================] - 35s 1ms/step - loss: 0.3358 - acc: 0.9799\n",
      "Epoch 3/30\n",
      "30945/30945 [==============================] - 34s 1ms/step - loss: 0.3267 - acc: 0.9718\n",
      "Epoch 4/30\n",
      "30945/30945 [==============================] - 35s 1ms/step - loss: 0.3209 - acc: 0.9682\n",
      "Epoch 5/30\n",
      "30945/30945 [==============================] - 34s 1ms/step - loss: 0.3180 - acc: 0.9597\n",
      "Epoch 6/30\n",
      "30945/30945 [==============================] - 34s 1ms/step - loss: 0.3135 - acc: 0.9578\n",
      "Epoch 7/30\n",
      "30945/30945 [==============================] - 34s 1ms/step - loss: 0.3116 - acc: 0.9536\n",
      "Epoch 8/30\n",
      "30945/30945 [==============================] - 34s 1ms/step - loss: 0.3075 - acc: 0.9519\n",
      "Epoch 9/30\n",
      "30945/30945 [==============================] - 34s 1ms/step - loss: 0.3073 - acc: 0.9437\n",
      "Epoch 10/30\n",
      "30945/30945 [==============================] - 34s 1ms/step - loss: 0.3056 - acc: 0.9415\n",
      "Epoch 11/30\n",
      "30945/30945 [==============================] - 34s 1ms/step - loss: 0.3046 - acc: 0.9321\n",
      "Epoch 12/30\n",
      "30945/30945 [==============================] - 34s 1ms/step - loss: 0.3031 - acc: 0.9357\n",
      "Epoch 13/30\n",
      "30945/30945 [==============================] - 34s 1ms/step - loss: 0.3046 - acc: 0.9279\n",
      "Epoch 14/30\n",
      "30945/30945 [==============================] - 34s 1ms/step - loss: 0.3033 - acc: 0.9263\n",
      "Epoch 15/30\n",
      "30945/30945 [==============================] - 34s 1ms/step - loss: 0.3037 - acc: 0.9160\n",
      "Epoch 16/30\n",
      "30945/30945 [==============================] - 34s 1ms/step - loss: 0.3036 - acc: 0.9136\n",
      "Epoch 17/30\n",
      "30945/30945 [==============================] - 34s 1ms/step - loss: 0.3037 - acc: 0.9100\n",
      "Epoch 18/30\n",
      "30945/30945 [==============================] - 34s 1ms/step - loss: 0.3044 - acc: 0.9127\n",
      "Epoch 19/30\n",
      "30945/30945 [==============================] - 34s 1ms/step - loss: 0.3021 - acc: 0.8991\n",
      "Epoch 20/30\n",
      "30945/30945 [==============================] - 34s 1ms/step - loss: 0.3022 - acc: 0.9069\n",
      "Epoch 21/30\n",
      "30945/30945 [==============================] - 34s 1ms/step - loss: 0.3040 - acc: 0.9038\n",
      "Epoch 22/30\n",
      "30945/30945 [==============================] - 34s 1ms/step - loss: 0.3058 - acc: 0.8990\n",
      "Epoch 23/30\n",
      "30945/30945 [==============================] - 34s 1ms/step - loss: 0.3070 - acc: 0.8975\n",
      "Epoch 24/30\n",
      "30945/30945 [==============================] - 34s 1ms/step - loss: 0.3060 - acc: 0.8867\n",
      "Epoch 25/30\n",
      "30945/30945 [==============================] - 34s 1ms/step - loss: 0.3058 - acc: 0.8894\n",
      "Epoch 26/30\n",
      "30945/30945 [==============================] - 34s 1ms/step - loss: 0.3067 - acc: 0.8874\n",
      "Epoch 27/30\n",
      "30945/30945 [==============================] - 34s 1ms/step - loss: 0.3069 - acc: 0.8922\n",
      "Epoch 28/30\n",
      "30945/30945 [==============================] - 35s 1ms/step - loss: 0.3084 - acc: 0.8843\n",
      "Epoch 29/30\n",
      "30945/30945 [==============================] - 35s 1ms/step - loss: 0.3060 - acc: 0.8848\n",
      "Epoch 30/30\n",
      "30945/30945 [==============================] - 35s 1ms/step - loss: 0.3086 - acc: 0.8805\n",
      "15473/15473 [==============================] - 15s 996us/step\n",
      "30945/30945 [==============================] - 25s 802us/step\n",
      "[CV] .................... epochs=30, lr=0.003, nodes=32, total=18.1min\n",
      "[CV] epochs=30, lr=0.003, nodes=32 ...................................\n",
      "Epoch 1/30\n",
      "30945/30945 [==============================] - 46s 1ms/step - loss: 0.3613 - acc: 0.9762\n",
      "Epoch 2/30\n",
      "30945/30945 [==============================] - 35s 1ms/step - loss: 0.3452 - acc: 0.9791\n",
      "Epoch 3/30\n",
      "30945/30945 [==============================] - 34s 1ms/step - loss: 0.3386 - acc: 0.9727\n",
      "Epoch 4/30\n",
      "30945/30945 [==============================] - 35s 1ms/step - loss: 0.3325 - acc: 0.9677\n",
      "Epoch 5/30\n",
      "30945/30945 [==============================] - 35s 1ms/step - loss: 0.3301 - acc: 0.9635\n",
      "Epoch 6/30\n",
      "30945/30945 [==============================] - 34s 1ms/step - loss: 0.3242 - acc: 0.9602\n",
      "Epoch 7/30\n",
      "30945/30945 [==============================] - 35s 1ms/step - loss: 0.3245 - acc: 0.9545\n",
      "Epoch 8/30\n",
      "30945/30945 [==============================] - 34s 1ms/step - loss: 0.3206 - acc: 0.9487\n",
      "Epoch 9/30\n",
      "30945/30945 [==============================] - 34s 1ms/step - loss: 0.3183 - acc: 0.9468\n",
      "Epoch 10/30\n",
      "30945/30945 [==============================] - 34s 1ms/step - loss: 0.3163 - acc: 0.9364\n",
      "Epoch 11/30\n",
      "30945/30945 [==============================] - 34s 1ms/step - loss: 0.3164 - acc: 0.9329\n",
      "Epoch 12/30\n",
      "30945/30945 [==============================] - 34s 1ms/step - loss: 0.3161 - acc: 0.9295\n",
      "Epoch 13/30\n",
      "30945/30945 [==============================] - 34s 1ms/step - loss: 0.3175 - acc: 0.9286\n",
      "Epoch 14/30\n",
      "30945/30945 [==============================] - 34s 1ms/step - loss: 0.3170 - acc: 0.9277\n",
      "Epoch 15/30\n",
      "30945/30945 [==============================] - 35s 1ms/step - loss: 0.3164 - acc: 0.9172\n",
      "Epoch 16/30\n",
      "30945/30945 [==============================] - 34s 1ms/step - loss: 0.3153 - acc: 0.9080\n",
      "Epoch 17/30\n",
      "30945/30945 [==============================] - 34s 1ms/step - loss: 0.3168 - acc: 0.9050\n",
      "Epoch 18/30\n",
      "30945/30945 [==============================] - 34s 1ms/step - loss: 0.3152 - acc: 0.9027\n",
      "Epoch 19/30\n",
      "30945/30945 [==============================] - 34s 1ms/step - loss: 0.3134 - acc: 0.9048\n",
      "Epoch 20/30\n",
      "30945/30945 [==============================] - 34s 1ms/step - loss: 0.3157 - acc: 0.9081\n",
      "Epoch 21/30\n",
      "30945/30945 [==============================] - 34s 1ms/step - loss: 0.3146 - acc: 0.8976\n",
      "Epoch 22/30\n",
      "30945/30945 [==============================] - 34s 1ms/step - loss: 0.3150 - acc: 0.8923\n",
      "Epoch 23/30\n",
      "30945/30945 [==============================] - 34s 1ms/step - loss: 0.3131 - acc: 0.8900\n",
      "Epoch 24/30\n",
      "30945/30945 [==============================] - 34s 1ms/step - loss: 0.3174 - acc: 0.8890\n",
      "Epoch 25/30\n",
      "30945/30945 [==============================] - 34s 1ms/step - loss: 0.3153 - acc: 0.8855\n",
      "Epoch 26/30\n",
      "30945/30945 [==============================] - 34s 1ms/step - loss: 0.3163 - acc: 0.8917\n",
      "Epoch 27/30\n",
      "30945/30945 [==============================] - 34s 1ms/step - loss: 0.3170 - acc: 0.8752\n",
      "Epoch 28/30\n",
      "30945/30945 [==============================] - 34s 1ms/step - loss: 0.3176 - acc: 0.8842\n",
      "Epoch 29/30\n",
      "30945/30945 [==============================] - 34s 1ms/step - loss: 0.3157 - acc: 0.8806\n",
      "Epoch 30/30\n",
      "30945/30945 [==============================] - 34s 1ms/step - loss: 0.3153 - acc: 0.8745\n",
      "15473/15473 [==============================] - 15s 998us/step\n",
      "30945/30945 [==============================] - 25s 808us/step\n",
      "[CV] .................... epochs=30, lr=0.003, nodes=32, total=18.1min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] epochs=30, lr=0.003, nodes=32 ...................................\n",
      "Epoch 1/30\n",
      "30946/30946 [==============================] - 46s 1ms/step - loss: 0.3526 - acc: 0.9823\n",
      "Epoch 2/30\n",
      "30946/30946 [==============================] - 34s 1ms/step - loss: 0.3338 - acc: 0.9771\n",
      "Epoch 3/30\n",
      "30946/30946 [==============================] - 33s 1ms/step - loss: 0.3271 - acc: 0.9722\n",
      "Epoch 4/30\n",
      "30946/30946 [==============================] - 33s 1ms/step - loss: 0.3207 - acc: 0.9624\n",
      "Epoch 5/30\n",
      "30946/30946 [==============================] - 33s 1ms/step - loss: 0.3190 - acc: 0.9596\n",
      "Epoch 6/30\n",
      "30946/30946 [==============================] - 33s 1ms/step - loss: 0.3156 - acc: 0.9543\n",
      "Epoch 7/30\n",
      "30946/30946 [==============================] - 33s 1ms/step - loss: 0.3119 - acc: 0.9472\n",
      "Epoch 8/30\n",
      "30946/30946 [==============================] - 34s 1ms/step - loss: 0.3103 - acc: 0.9466\n",
      "Epoch 9/30\n",
      "30946/30946 [==============================] - 33s 1ms/step - loss: 0.3051 - acc: 0.9394\n",
      "Epoch 10/30\n",
      "30946/30946 [==============================] - 33s 1ms/step - loss: 0.3050 - acc: 0.9371\n",
      "Epoch 11/30\n",
      "30946/30946 [==============================] - 33s 1ms/step - loss: 0.3037 - acc: 0.9259\n",
      "Epoch 12/30\n",
      "30946/30946 [==============================] - 33s 1ms/step - loss: 0.3017 - acc: 0.9263\n",
      "Epoch 13/30\n",
      "30946/30946 [==============================] - 33s 1ms/step - loss: 0.3012 - acc: 0.9174\n",
      "Epoch 14/30\n",
      "30946/30946 [==============================] - 33s 1ms/step - loss: 0.3009 - acc: 0.9195\n",
      "Epoch 15/30\n",
      "30946/30946 [==============================] - 33s 1ms/step - loss: 0.2998 - acc: 0.9163\n",
      "Epoch 16/30\n",
      "30946/30946 [==============================] - 33s 1ms/step - loss: 0.3008 - acc: 0.9074\n",
      "Epoch 17/30\n",
      "30946/30946 [==============================] - 33s 1ms/step - loss: 0.2994 - acc: 0.9083\n",
      "Epoch 18/30\n",
      "30946/30946 [==============================] - 33s 1ms/step - loss: 0.2965 - acc: 0.8994\n",
      "Epoch 19/30\n",
      "30946/30946 [==============================] - 33s 1ms/step - loss: 0.2986 - acc: 0.9006\n",
      "Epoch 20/30\n",
      "30946/30946 [==============================] - 33s 1ms/step - loss: 0.2973 - acc: 0.8997\n",
      "Epoch 21/30\n",
      "30946/30946 [==============================] - 33s 1ms/step - loss: 0.2975 - acc: 0.8981\n",
      "Epoch 22/30\n",
      "30946/30946 [==============================] - 33s 1ms/step - loss: 0.2993 - acc: 0.8963\n",
      "Epoch 23/30\n",
      "30946/30946 [==============================] - 33s 1ms/step - loss: 0.2981 - acc: 0.8915\n",
      "Epoch 24/30\n",
      "30946/30946 [==============================] - 33s 1ms/step - loss: 0.2980 - acc: 0.8861\n",
      "Epoch 25/30\n",
      "30946/30946 [==============================] - 33s 1ms/step - loss: 0.2997 - acc: 0.8875\n",
      "Epoch 26/30\n",
      "30946/30946 [==============================] - 33s 1ms/step - loss: 0.2978 - acc: 0.8903\n",
      "Epoch 27/30\n",
      "30946/30946 [==============================] - 33s 1ms/step - loss: 0.2988 - acc: 0.8847\n",
      "Epoch 28/30\n",
      "30946/30946 [==============================] - 33s 1ms/step - loss: 0.2985 - acc: 0.8803\n",
      "Epoch 29/30\n",
      "30946/30946 [==============================] - 33s 1ms/step - loss: 0.2992 - acc: 0.8843\n",
      "Epoch 30/30\n",
      "30946/30946 [==============================] - 33s 1ms/step - loss: 0.2982 - acc: 0.8777\n",
      "15472/15472 [==============================] - 15s 1ms/step\n",
      "30946/30946 [==============================] - 23s 752us/step\n",
      "[CV] .................... epochs=30, lr=0.003, nodes=32, total=17.6min\n",
      "[CV] epochs=30, lr=0.003, nodes=64 ...................................\n",
      "Epoch 1/30\n",
      "30945/30945 [==============================] - 67s 2ms/step - loss: 0.3507 - acc: 0.9771\n",
      "Epoch 2/30\n",
      "30945/30945 [==============================] - 57s 2ms/step - loss: 0.3321 - acc: 0.9726\n",
      "Epoch 3/30\n",
      "30945/30945 [==============================] - 55s 2ms/step - loss: 0.3241 - acc: 0.9665\n",
      "Epoch 4/30\n",
      "30945/30945 [==============================] - 57s 2ms/step - loss: 0.3158 - acc: 0.9608\n",
      "Epoch 5/30\n",
      "30945/30945 [==============================] - 57s 2ms/step - loss: 0.3106 - acc: 0.9541\n",
      "Epoch 6/30\n",
      "30945/30945 [==============================] - 57s 2ms/step - loss: 0.3080 - acc: 0.9506\n",
      "Epoch 7/30\n",
      "30945/30945 [==============================] - 57s 2ms/step - loss: 0.3058 - acc: 0.9442\n",
      "Epoch 8/30\n",
      "30945/30945 [==============================] - 57s 2ms/step - loss: 0.3035 - acc: 0.9391\n",
      "Epoch 9/30\n",
      "30945/30945 [==============================] - 57s 2ms/step - loss: 0.3020 - acc: 0.9348\n",
      "Epoch 10/30\n",
      "30945/30945 [==============================] - 57s 2ms/step - loss: 0.3013 - acc: 0.9313\n",
      "Epoch 11/30\n",
      "30945/30945 [==============================] - 57s 2ms/step - loss: 0.2984 - acc: 0.9225\n",
      "Epoch 12/30\n",
      "30945/30945 [==============================] - 57s 2ms/step - loss: 0.3002 - acc: 0.9185\n",
      "Epoch 13/30\n",
      "30945/30945 [==============================] - 57s 2ms/step - loss: 0.3022 - acc: 0.9124\n",
      "Epoch 14/30\n",
      "30945/30945 [==============================] - 56s 2ms/step - loss: 0.3014 - acc: 0.9117\n",
      "Epoch 15/30\n",
      "30945/30945 [==============================] - 56s 2ms/step - loss: 0.3047 - acc: 0.9088\n",
      "Epoch 16/30\n",
      "30945/30945 [==============================] - 57s 2ms/step - loss: 0.3038 - acc: 0.9043\n",
      "Epoch 17/30\n",
      "30945/30945 [==============================] - 57s 2ms/step - loss: 0.3033 - acc: 0.9013\n",
      "Epoch 18/30\n",
      "30945/30945 [==============================] - 57s 2ms/step - loss: 0.3017 - acc: 0.8984\n",
      "Epoch 19/30\n",
      "30945/30945 [==============================] - 57s 2ms/step - loss: 0.3030 - acc: 0.9023\n",
      "Epoch 20/30\n",
      "30945/30945 [==============================] - 57s 2ms/step - loss: 0.3079 - acc: 0.8878\n",
      "Epoch 21/30\n",
      "30945/30945 [==============================] - 57s 2ms/step - loss: 0.3040 - acc: 0.8931\n",
      "Epoch 22/30\n",
      "30945/30945 [==============================] - 57s 2ms/step - loss: 0.3037 - acc: 0.8868\n",
      "Epoch 23/30\n",
      "30945/30945 [==============================] - 58s 2ms/step - loss: 0.3031 - acc: 0.8848\n",
      "Epoch 24/30\n",
      "30945/30945 [==============================] - 56s 2ms/step - loss: 0.3044 - acc: 0.8863\n",
      "Epoch 25/30\n",
      "30945/30945 [==============================] - 58s 2ms/step - loss: 0.3043 - acc: 0.8872\n",
      "Epoch 26/30\n",
      "30945/30945 [==============================] - 56s 2ms/step - loss: 0.3062 - acc: 0.8805\n",
      "Epoch 27/30\n",
      "30945/30945 [==============================] - 57s 2ms/step - loss: 0.3048 - acc: 0.8801\n",
      "Epoch 28/30\n",
      "30945/30945 [==============================] - 57s 2ms/step - loss: 0.3034 - acc: 0.8786\n",
      "Epoch 29/30\n",
      "30945/30945 [==============================] - 58s 2ms/step - loss: 0.3047 - acc: 0.8728\n",
      "Epoch 30/30\n",
      "30945/30945 [==============================] - 56s 2ms/step - loss: 0.3074 - acc: 0.8708\n",
      "15473/15473 [==============================] - 14s 883us/step\n",
      "30945/30945 [==============================] - 23s 740us/step\n",
      "[CV] .................... epochs=30, lr=0.003, nodes=64, total=29.4min\n",
      "[CV] epochs=30, lr=0.003, nodes=64 ...................................\n",
      "Epoch 1/30\n",
      "30945/30945 [==============================] - 65s 2ms/step - loss: 0.3611 - acc: 0.9753\n",
      "Epoch 2/30\n",
      "30945/30945 [==============================] - 53s 2ms/step - loss: 0.3423 - acc: 0.9746\n",
      "Epoch 3/30\n",
      "30945/30945 [==============================] - 54s 2ms/step - loss: 0.3332 - acc: 0.9673\n",
      "Epoch 4/30\n",
      "30945/30945 [==============================] - 54s 2ms/step - loss: 0.3269 - acc: 0.9636\n",
      "Epoch 5/30\n",
      "30945/30945 [==============================] - 54s 2ms/step - loss: 0.3212 - acc: 0.9570\n",
      "Epoch 6/30\n",
      "30945/30945 [==============================] - 53s 2ms/step - loss: 0.3186 - acc: 0.9488\n",
      "Epoch 7/30\n",
      "30945/30945 [==============================] - 54s 2ms/step - loss: 0.3161 - acc: 0.9459\n",
      "Epoch 8/30\n",
      "30945/30945 [==============================] - 54s 2ms/step - loss: 0.3139 - acc: 0.9413\n",
      "Epoch 9/30\n",
      "30945/30945 [==============================] - 53s 2ms/step - loss: 0.3139 - acc: 0.9366\n",
      "Epoch 10/30\n",
      "30945/30945 [==============================] - 53s 2ms/step - loss: 0.3122 - acc: 0.9334\n",
      "Epoch 11/30\n",
      "30945/30945 [==============================] - 53s 2ms/step - loss: 0.3117 - acc: 0.9246\n",
      "Epoch 12/30\n",
      "30945/30945 [==============================] - 54s 2ms/step - loss: 0.3113 - acc: 0.9239\n",
      "Epoch 13/30\n",
      "30945/30945 [==============================] - 54s 2ms/step - loss: 0.3101 - acc: 0.9192\n",
      "Epoch 14/30\n",
      "30945/30945 [==============================] - 54s 2ms/step - loss: 0.3109 - acc: 0.9167\n",
      "Epoch 15/30\n",
      "30945/30945 [==============================] - 53s 2ms/step - loss: 0.3136 - acc: 0.9156\n",
      "Epoch 16/30\n",
      "30945/30945 [==============================] - 53s 2ms/step - loss: 0.3120 - acc: 0.9071\n",
      "Epoch 17/30\n",
      "30945/30945 [==============================] - 53s 2ms/step - loss: 0.3112 - acc: 0.9056\n",
      "Epoch 18/30\n",
      "30945/30945 [==============================] - 53s 2ms/step - loss: 0.3111 - acc: 0.8931\n",
      "Epoch 19/30\n",
      "30945/30945 [==============================] - 54s 2ms/step - loss: 0.3101 - acc: 0.8974\n",
      "Epoch 20/30\n",
      "30945/30945 [==============================] - 53s 2ms/step - loss: 0.3130 - acc: 0.8895\n",
      "Epoch 21/30\n",
      "30945/30945 [==============================] - 53s 2ms/step - loss: 0.3092 - acc: 0.8938\n",
      "Epoch 22/30\n",
      "30945/30945 [==============================] - 53s 2ms/step - loss: 0.3096 - acc: 0.8904\n",
      "Epoch 23/30\n",
      "30945/30945 [==============================] - 53s 2ms/step - loss: 0.3136 - acc: 0.8872\n",
      "Epoch 24/30\n",
      "30945/30945 [==============================] - 53s 2ms/step - loss: 0.3114 - acc: 0.8820\n",
      "Epoch 25/30\n",
      "30945/30945 [==============================] - 53s 2ms/step - loss: 0.3110 - acc: 0.8763\n",
      "Epoch 26/30\n",
      "30945/30945 [==============================] - 52s 2ms/step - loss: 0.3130 - acc: 0.8857\n",
      "Epoch 27/30\n",
      "30945/30945 [==============================] - 54s 2ms/step - loss: 0.3100 - acc: 0.8712\n",
      "Epoch 28/30\n",
      "30945/30945 [==============================] - 54s 2ms/step - loss: 0.3110 - acc: 0.8778\n",
      "Epoch 29/30\n",
      "30945/30945 [==============================] - 53s 2ms/step - loss: 0.3092 - acc: 0.8739\n",
      "Epoch 30/30\n",
      "30945/30945 [==============================] - 52s 2ms/step - loss: 0.3103 - acc: 0.8714\n",
      "15473/15473 [==============================] - 16s 1ms/step\n",
      "30945/30945 [==============================] - 25s 810us/step\n",
      "[CV] .................... epochs=30, lr=0.003, nodes=64, total=27.7min\n",
      "[CV] epochs=30, lr=0.003, nodes=64 ...................................\n",
      "Epoch 1/30\n",
      "30946/30946 [==============================] - 66s 2ms/step - loss: 0.3500 - acc: 0.9782\n",
      "Epoch 2/30\n",
      "30946/30946 [==============================] - 55s 2ms/step - loss: 0.3314 - acc: 0.9730\n",
      "Epoch 3/30\n",
      "30946/30946 [==============================] - 55s 2ms/step - loss: 0.3215 - acc: 0.9672\n",
      "Epoch 4/30\n",
      "30946/30946 [==============================] - 54s 2ms/step - loss: 0.3165 - acc: 0.9574\n",
      "Epoch 5/30\n",
      "30946/30946 [==============================] - 55s 2ms/step - loss: 0.3089 - acc: 0.9505\n",
      "Epoch 6/30\n",
      "30946/30946 [==============================] - 55s 2ms/step - loss: 0.3075 - acc: 0.9494\n",
      "Epoch 7/30\n",
      "30946/30946 [==============================] - 55s 2ms/step - loss: 0.3031 - acc: 0.9425\n",
      "Epoch 8/30\n",
      "30946/30946 [==============================] - 54s 2ms/step - loss: 0.3020 - acc: 0.9327\n",
      "Epoch 9/30\n",
      "30946/30946 [==============================] - 54s 2ms/step - loss: 0.3018 - acc: 0.9267\n",
      "Epoch 10/30\n",
      "30946/30946 [==============================] - 55s 2ms/step - loss: 0.2997 - acc: 0.9191\n",
      "Epoch 11/30\n",
      "30946/30946 [==============================] - 55s 2ms/step - loss: 0.2990 - acc: 0.9197\n",
      "Epoch 12/30\n",
      "30946/30946 [==============================] - 55s 2ms/step - loss: 0.2984 - acc: 0.9203\n",
      "Epoch 13/30\n",
      "30946/30946 [==============================] - 55s 2ms/step - loss: 0.2979 - acc: 0.9107\n",
      "Epoch 14/30\n",
      "30946/30946 [==============================] - 56s 2ms/step - loss: 0.2976 - acc: 0.9034\n",
      "Epoch 15/30\n",
      "30946/30946 [==============================] - 55s 2ms/step - loss: 0.2955 - acc: 0.9067\n",
      "Epoch 16/30\n",
      "30946/30946 [==============================] - 55s 2ms/step - loss: 0.2961 - acc: 0.9030\n",
      "Epoch 17/30\n",
      "30946/30946 [==============================] - 56s 2ms/step - loss: 0.2995 - acc: 0.8987\n",
      "Epoch 18/30\n",
      "30946/30946 [==============================] - 55s 2ms/step - loss: 0.2973 - acc: 0.8911\n",
      "Epoch 19/30\n",
      "30946/30946 [==============================] - 56s 2ms/step - loss: 0.2986 - acc: 0.8862\n",
      "Epoch 20/30\n",
      "30946/30946 [==============================] - 56s 2ms/step - loss: 0.3000 - acc: 0.8894\n",
      "Epoch 21/30\n",
      "30946/30946 [==============================] - 56s 2ms/step - loss: 0.2995 - acc: 0.8803\n",
      "Epoch 22/30\n",
      "30946/30946 [==============================] - 54s 2ms/step - loss: 0.3002 - acc: 0.8782\n",
      "Epoch 23/30\n",
      "30946/30946 [==============================] - 56s 2ms/step - loss: 0.3014 - acc: 0.8740\n",
      "Epoch 24/30\n",
      "30946/30946 [==============================] - 55s 2ms/step - loss: 0.3013 - acc: 0.8715\n",
      "Epoch 25/30\n",
      "30946/30946 [==============================] - 55s 2ms/step - loss: 0.3024 - acc: 0.8618\n",
      "Epoch 26/30\n",
      "30946/30946 [==============================] - 56s 2ms/step - loss: 0.3032 - acc: 0.8683\n",
      "Epoch 27/30\n",
      "30946/30946 [==============================] - 56s 2ms/step - loss: 0.3019 - acc: 0.8635\n",
      "Epoch 28/30\n",
      "30946/30946 [==============================] - 56s 2ms/step - loss: 0.3032 - acc: 0.8641\n",
      "Epoch 29/30\n",
      "30946/30946 [==============================] - 56s 2ms/step - loss: 0.3030 - acc: 0.8644\n",
      "Epoch 30/30\n",
      "30946/30946 [==============================] - 56s 2ms/step - loss: 0.3010 - acc: 0.8560\n",
      "15472/15472 [==============================] - 16s 1ms/step\n",
      "30946/30946 [==============================] - 26s 831us/step\n",
      "[CV] .................... epochs=30, lr=0.003, nodes=64, total=28.6min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  81 out of  81 | elapsed: 1693.6min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "46418/46418 [==============================] - 47s 1ms/step - loss: 0.3641 - acc: 0.9618\n",
      "Epoch 2/10\n",
      "46418/46418 [==============================] - 45s 965us/step - loss: 0.3442 - acc: 0.9830\n",
      "Epoch 3/10\n",
      "46418/46418 [==============================] - 44s 946us/step - loss: 0.3383 - acc: 0.9804\n",
      "Epoch 4/10\n",
      "46418/46418 [==============================] - 44s 944us/step - loss: 0.3344 - acc: 0.9750\n",
      "Epoch 5/10\n",
      "46418/46418 [==============================] - 43s 936us/step - loss: 0.3320 - acc: 0.9718\n",
      "Epoch 6/10\n",
      "46418/46418 [==============================] - 43s 934us/step - loss: 0.3297 - acc: 0.9654\n",
      "Epoch 7/10\n",
      "46418/46418 [==============================] - 43s 933us/step - loss: 0.3277 - acc: 0.9643\n",
      "Epoch 8/10\n",
      "46418/46418 [==============================] - 43s 934us/step - loss: 0.3257 - acc: 0.9574\n",
      "Epoch 9/10\n",
      "46418/46418 [==============================] - 43s 937us/step - loss: 0.3251 - acc: 0.9565\n",
      "Epoch 10/10\n",
      "46418/46418 [==============================] - 43s 937us/step - loss: 0.3240 - acc: 0.9539\n"
     ]
    }
   ],
   "source": [
    "#start fitting process\n",
    "param_grid = dict(epochs=epochs,nodes=nodes, lr=lrs)\n",
    "grid = GridSearchCV(estimator=model, param_grid=param_grid, n_jobs=1,refit=True,verbose=2)\n",
    "grid_result = grid.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GridSearchCV(cv=None, error_score='raise',\n",
      "       estimator=<keras.wrappers.scikit_learn.KerasClassifier object at 0x7ffc79278>,\n",
      "       fit_params=None, iid=True, n_jobs=1,\n",
      "       param_grid={'epochs': [10, 20, 30], 'nodes': [16, 32, 64], 'lr': [0.001, 0.002, 0.003]},\n",
      "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
      "       scoring=None, verbose=2)\n"
     ]
    }
   ],
   "source": [
    "print(grid_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best estimator : <keras.wrappers.scikit_learn.KerasClassifier object at 0x887d8e8d0>\n",
      "Best score : 0.9802662760148995\n",
      "Best params : {'epochs': 10, 'lr': 0.001, 'nodes': 16}\n"
     ]
    }
   ],
   "source": [
    "print('Best estimator : {}'.format (grid.best_estimator_))\n",
    "print('Best score : {}'.format(grid.best_score_))\n",
    "print('Best params : {}'.format(grid.best_params_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'mean_fit_time': array([  282.14273198,   412.61235968,   590.69232233,   267.92312781,\n",
      "         392.4418989 ,   593.37367829,   246.37826745,   373.27251657,\n",
      "         585.33218129,   446.11738094,   675.25052961,  1095.17514602,\n",
      "         467.25050513,   668.95570461,  1108.70000831,   472.17317764,\n",
      "         698.6985542 ,  1210.74587321,   725.23662893,  1192.23849821,\n",
      "       13149.07480772,   788.9326237 ,  1096.581803  ,  1758.84920621,\n",
      "         752.81749868,  1062.1605703 ,  1698.34982109]), 'std_fit_time': array([2.23591969e+01, 2.15047723e+00, 2.64419706e+01, 2.76638036e+00,\n",
      "       1.48957421e+01, 1.52180747e+01, 1.64775877e+01, 1.12871429e+01,\n",
      "       4.83799418e+00, 3.62796152e+01, 1.81110625e+01, 3.96805023e+00,\n",
      "       4.08766490e+00, 3.99024957e+00, 1.62677176e+01, 7.07579227e+00,\n",
      "       3.89000555e+01, 6.99882339e+01, 1.55882980e+01, 4.87303314e+01,\n",
      "       1.58591078e+04, 2.11081407e+01, 1.12746574e+01, 7.81184425e+01,\n",
      "       6.30624252e+00, 1.40923421e+01, 4.29098750e+01]), 'mean_score_time': array([12.02174298, 14.38173946, 13.46587944, 12.32335536, 12.92721065,\n",
      "       13.93557262, 11.21999733, 13.33071971, 14.39609599, 11.50784167,\n",
      "       13.76164508, 13.82472722, 12.9402113 , 13.82380398, 14.44641264,\n",
      "       13.24558075, 14.79218674, 14.20285447, 13.89610442, 16.36801004,\n",
      "       16.2751472 , 14.77849229, 15.88712605, 15.95045932, 14.8662227 ,\n",
      "       15.4829824 , 15.09711059]), 'std_score_time': array([1.16481462, 0.11500077, 0.40565325, 0.03134912, 0.37499668,\n",
      "       0.29574422, 0.73839175, 0.05551965, 0.13849248, 0.64646563,\n",
      "       0.31374801, 0.02677314, 0.08158559, 0.04038155, 0.64145047,\n",
      "       0.16964276, 1.26399535, 0.18698179, 0.4390211 , 0.22425822,\n",
      "       1.47202456, 0.33031886, 0.68195178, 0.27370412, 0.20737284,\n",
      "       0.02631901, 1.01448767]), 'param_epochs': masked_array(data=[10, 10, 10, 10, 10, 10, 10, 10, 10, 20, 20, 20, 20, 20,\n",
      "                   20, 20, 20, 20, 30, 30, 30, 30, 30, 30, 30, 30, 30],\n",
      "             mask=[False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False],\n",
      "       fill_value='?',\n",
      "            dtype=object), 'param_lr': masked_array(data=[0.001, 0.001, 0.001, 0.002, 0.002, 0.002, 0.003, 0.003,\n",
      "                   0.003, 0.001, 0.001, 0.001, 0.002, 0.002, 0.002, 0.003,\n",
      "                   0.003, 0.003, 0.001, 0.001, 0.001, 0.002, 0.002, 0.002,\n",
      "                   0.003, 0.003, 0.003],\n",
      "             mask=[False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False],\n",
      "       fill_value='?',\n",
      "            dtype=object), 'param_nodes': masked_array(data=[16, 32, 64, 16, 32, 64, 16, 32, 64, 16, 32, 64, 16, 32,\n",
      "                   64, 16, 32, 64, 16, 32, 64, 16, 32, 64, 16, 32, 64],\n",
      "             mask=[False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False],\n",
      "       fill_value='?',\n",
      "            dtype=object), 'params': [{'epochs': 10, 'lr': 0.001, 'nodes': 16}, {'epochs': 10, 'lr': 0.001, 'nodes': 32}, {'epochs': 10, 'lr': 0.001, 'nodes': 64}, {'epochs': 10, 'lr': 0.002, 'nodes': 16}, {'epochs': 10, 'lr': 0.002, 'nodes': 32}, {'epochs': 10, 'lr': 0.002, 'nodes': 64}, {'epochs': 10, 'lr': 0.003, 'nodes': 16}, {'epochs': 10, 'lr': 0.003, 'nodes': 32}, {'epochs': 10, 'lr': 0.003, 'nodes': 64}, {'epochs': 20, 'lr': 0.001, 'nodes': 16}, {'epochs': 20, 'lr': 0.001, 'nodes': 32}, {'epochs': 20, 'lr': 0.001, 'nodes': 64}, {'epochs': 20, 'lr': 0.002, 'nodes': 16}, {'epochs': 20, 'lr': 0.002, 'nodes': 32}, {'epochs': 20, 'lr': 0.002, 'nodes': 64}, {'epochs': 20, 'lr': 0.003, 'nodes': 16}, {'epochs': 20, 'lr': 0.003, 'nodes': 32}, {'epochs': 20, 'lr': 0.003, 'nodes': 64}, {'epochs': 30, 'lr': 0.001, 'nodes': 16}, {'epochs': 30, 'lr': 0.001, 'nodes': 32}, {'epochs': 30, 'lr': 0.001, 'nodes': 64}, {'epochs': 30, 'lr': 0.002, 'nodes': 16}, {'epochs': 30, 'lr': 0.002, 'nodes': 32}, {'epochs': 30, 'lr': 0.002, 'nodes': 64}, {'epochs': 30, 'lr': 0.003, 'nodes': 16}, {'epochs': 30, 'lr': 0.003, 'nodes': 32}, {'epochs': 30, 'lr': 0.003, 'nodes': 64}], 'split0_test_score': array([0.98351968, 0.97725069, 0.95779745, 0.98009436, 0.96833193,\n",
      "       0.95088218, 0.97544109, 0.95139921, 0.97214503, 0.97382537,\n",
      "       0.95404899, 0.93013637, 0.96426032, 0.94584114, 0.90609449,\n",
      "       0.95165773, 0.91869709, 0.90305694, 0.96005946, 0.92302721,\n",
      "       0.89995476, 0.94920184, 0.91766303, 0.90758095, 0.94842629,\n",
      "       0.93239837, 0.92606476]), 'split1_test_score': array([0.9747948 , 0.97679829, 0.96361404, 0.9777031 , 0.97240354,\n",
      "       0.96561753, 0.97608738, 0.96955988, 0.96348478, 0.97033542,\n",
      "       0.95740968, 0.94674594, 0.97621664, 0.94357914, 0.90674077,\n",
      "       0.95960706, 0.94286822, 0.92451367, 0.96975376, 0.9380857 ,\n",
      "       0.92179926, 0.94222193, 0.92515996, 0.92257481, 0.94144639,\n",
      "       0.91307439, 0.92386738]), 'split2_test_score': array([0.98248449, 0.97440538, 0.95934592, 0.97330662, 0.96904085,\n",
      "       0.96464581, 0.9663909 , 0.95314116, 0.95643744, 0.9709152 ,\n",
      "       0.94525595, 0.92638314, 0.9473242 , 0.93181231, 0.92567218,\n",
      "       0.94234747, 0.92418563, 0.87609876, 0.96063857, 0.93265253,\n",
      "       0.90324457, 0.93368666, 0.89438987, 0.90059462, 0.94034385,\n",
      "       0.91171148, 0.88139866]), 'mean_test_score': array([0.98026628, 0.97615149, 0.96025249, 0.97703477, 0.96992546,\n",
      "       0.96038175, 0.97263992, 0.95803352, 0.96402258, 0.97169202,\n",
      "       0.95223836, 0.93442199, 0.96260072, 0.94041105, 0.91283554,\n",
      "       0.95120427, 0.92858374, 0.90122366, 0.96348399, 0.93125512,\n",
      "       0.90833297, 0.94170365, 0.91240467, 0.91025033, 0.94340558,\n",
      "       0.91906157, 0.91044422]), 'std_test_score': array([0.00389199, 0.00124839, 0.00245964, 0.00281108, 0.00177604,\n",
      "       0.00672902, 0.00442646, 0.00818146, 0.00642383, 0.00152699,\n",
      "       0.00512424, 0.00884817, 0.01185346, 0.00614976, 0.00908042,\n",
      "       0.00705345, 0.01034636, 0.01980766, 0.00443977, 0.00622657,\n",
      "       0.00961651, 0.0063446 , 0.01310052, 0.0091697 , 0.00357866,\n",
      "       0.00944709, 0.02055724]), 'rank_test_score': array([ 1,  3, 11,  2,  6, 10,  4, 12,  7,  5, 13, 18,  9, 17, 22, 14, 20,\n",
      "       27,  8, 19, 26, 16, 23, 25, 15, 21, 24], dtype=int32), 'split0_train_score': array([0.98545807, 0.97676523, 0.95201163, 0.97634513, 0.96351592,\n",
      "       0.94703506, 0.97259654, 0.94364195, 0.97056067, 0.97450315,\n",
      "       0.94926482, 0.92506059, 0.95983196, 0.94231701, 0.89794797,\n",
      "       0.95401519, 0.91278074, 0.89251899, 0.95789304, 0.92008402,\n",
      "       0.88993375, 0.94819842, 0.91694943, 0.90176119, 0.95097754,\n",
      "       0.93633867, 0.92502828]), 'split1_train_score': array([0.97014057, 0.97498788, 0.96125384, 0.97731459, 0.96742608,\n",
      "       0.9592826 , 0.9723057 , 0.96749071, 0.95708515, 0.96984973,\n",
      "       0.95369203, 0.94057198, 0.97847794, 0.93679108, 0.89193731,\n",
      "       0.95847471, 0.94322185, 0.91291   , 0.96933269, 0.9372435 ,\n",
      "       0.91714332, 0.94076587, 0.91888835, 0.91601228, 0.94028114,\n",
      "       0.90990467, 0.92308935]), 'split2_train_score': array([0.98203322, 0.9707232 , 0.95692497, 0.96859045, 0.96232146,\n",
      "       0.96170749, 0.96361404, 0.94936341, 0.95253021, 0.97088477,\n",
      "       0.94302979, 0.92257481, 0.94955729, 0.93181671, 0.91840626,\n",
      "       0.94025076, 0.91921411, 0.8577199 , 0.96177212, 0.93414335,\n",
      "       0.89724035, 0.93582369, 0.89071285, 0.89930847, 0.94845861,\n",
      "       0.91268662, 0.87665611]), 'mean_train_score': array([0.97921062, 0.97415877, 0.95673015, 0.97408339, 0.96442115,\n",
      "       0.95600838, 0.96950543, 0.95349869, 0.96005868, 0.97174588,\n",
      "       0.94866222, 0.92940246, 0.9626224 , 0.93697494, 0.90276385,\n",
      "       0.95091355, 0.92507223, 0.8877163 , 0.96299928, 0.93049029,\n",
      "       0.90143914, 0.94159599, 0.90885021, 0.90569398, 0.94657243,\n",
      "       0.91964332, 0.90825791]), 'std_train_score': array([0.00656413, 0.00253536, 0.00377563, 0.00390421, 0.00218004,\n",
      "       0.00642186, 0.00416753, 0.01016583, 0.00765531, 0.00199495,\n",
      "       0.00437365, 0.00796297, 0.01197055, 0.0042887 , 0.01132978,\n",
      "       0.00775643, 0.0130997 , 0.02278576, 0.00475015, 0.00746639,\n",
      "       0.01149819, 0.00508595, 0.01284945, 0.00736453, 0.00456592,\n",
      "       0.0118599 , 0.02235986])}\n"
     ]
    }
   ],
   "source": [
    "print(grid.cv_results_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#predictions\n",
    "predictions = grid.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(23209, 6)\n"
     ]
    }
   ],
   "source": [
    "#predictions\n",
    "predict = grid.predict_proba(X_test)\n",
    "print(predict.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Log_loss : 0.3504030505499869\n",
      "Hamming_loss : 15.158630990851249\n",
      "Accuracy : 21.612305571114653\n"
     ]
    }
   ],
   "source": [
    "#calculate score\n",
    "loss = log_loss(Y_test,predict)\n",
    "print(\"Log_loss : {}\".format(loss))\n",
    "predict = np.round(predict)\n",
    "loss = hamming_loss(Y_test,predict)\n",
    "print(\"Hamming_loss : {}\".format(loss*100))\n",
    "accuracy = accuracy_score(Y_test,predict)\n",
    "print(\"Accuracy : {}\".format(accuracy*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Free Form Visualisation \n",
    "Let us have a plot showing the **hamming-loss** and **log-loss** of different models, which we selected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import matplotlib.cm as cm\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYwAAAE5CAYAAACDPheMAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nJUkYERFRSRJGRERUkoQRERGV/H/LbTmVkDrdSwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1053d0da0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "x = ['BR-MultNB','BR-GausNB','BR-SVC','CC-MultNB','LP-MultNB','BP-MLL-ini','BP-MLL-fin']\n",
    "y = [3.27,20.74,4.26,3.56,3.17,13.96,15.158]\n",
    "colors = itertools.cycle(['b', 'g', 'r', 'c', 'm', 'y', 'k'])\n",
    "plt.ylabel('Hamming-Loss')\n",
    "plt.xlabel('Model-details')\n",
    "plt.xticks(rotation=90)\n",
    "for i in range(len(y)):\n",
    "    plt.bar(x[i], y[i], color=next(colors))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYwAAAE5CAYAAACDPheMAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nIqKSBEZERFSSwIiIiEr+P2MtWFYAG0YWAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x106d5f320>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "x = ['BR-MultNB','BR-GausNB','BR-SVC','CC-MultNB','LP-MultNB','BP-MLL-ini','BP-MLL-fin']\n",
    "y = [1.92,1.422,0.46,1.5,1.47,0.36,0.35]\n",
    "colors = itertools.cycle(['b', 'g', 'r', 'c', 'm', 'y', 'k'])\n",
    "plt.ylabel('Log-Loss')\n",
    "plt.xlabel('Model-details')\n",
    "plt.xticks(rotation=90)\n",
    "for i in range(len(y)):\n",
    "    plt.bar(x[i], y[i], color=next(colors))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- While showing among the best problem transformation method models, hamming-loss was considered (this is because for BP-MLL neural network we had to round the final results to get the hamming-loss because of the output being multivalued probabilities)\n",
    "- But while chosing among the best Adaptation Algorithm model, log loss was preferred."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
