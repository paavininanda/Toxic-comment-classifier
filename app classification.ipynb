{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GOOGLE EDUCATION APP CLASSIFICATION \n",
    "\n",
    "1. Import necessary files <br/>\n",
    "2. Read the csv file <br/>\n",
    "3. List the various fields in our dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(124, 21)\n"
     ]
    }
   ],
   "source": [
    "#Read the csv file into dataframe df\n",
    "df = pd.read_csv(\"train1.csv\")\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "appname                  object\n",
      "updated                  object\n",
      "file_size                object\n",
      "download                 object\n",
      "version                  object\n",
      "compatibility            object\n",
      "price                    object\n",
      "rating_value            float64\n",
      "star_total               object\n",
      "editors_choice           object\n",
      "offered_by               object\n",
      "description              object\n",
      "Language Learning         int64\n",
      "Computer Engineering      int64\n",
      "General Learning          int64\n",
      "Exam Preparation          int64\n",
      "Maths                     int64\n",
      "Art                       int64\n",
      "other engineering         int64\n",
      "Educational Gaming        int64\n",
      "misc                      int64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "#List the fields in our dataframe\n",
    "print(df.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hence we have a dataset consistly of 124 samples. Each sample contains 21 fields. <br/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Separate the comment field data and outcome labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    Learn Spanish, French, German, Italian, Russia...\n",
      "1    Speak a new language with confidence. Learn Sp...\n",
      "2    Start speaking a new language on day one! Try ...\n",
      "3    This app contains Implementation (full working...\n",
      "4    Learn on the go with the Coursera App for Andr...\n",
      "Name: description, dtype: object\n"
     ]
    }
   ],
   "source": [
    "comment = df['description']\n",
    "print(comment.head())\n",
    "comment = comment.as_matrix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Language Learning  Computer Engineering  General Learning  \\\n",
      "0                  1                     0                 0   \n",
      "1                  1                     0                 0   \n",
      "2                  1                     0                 0   \n",
      "3                  0                     1                 0   \n",
      "4                  1                     1                 1   \n",
      "\n",
      "   Exam Preparation  Maths  Art  other engineering  Educational Gaming  misc  \n",
      "0                 0      0    0                  0                   0     0  \n",
      "1                 0      0    0                  0                   0     0  \n",
      "2                 0      0    0                  0                   0     0  \n",
      "3                 0      0    0                  0                   0     0  \n",
      "4                 0      0    1                  1                   0     0  \n"
     ]
    }
   ],
   "source": [
    "label = df[['Language Learning', 'Computer Engineering' , 'General Learning' , 'Exam Preparation' , 'Maths' , 'Art', 'other engineering', 'Educational Gaming', 'misc']]\n",
    "print(label.head())\n",
    "label = label.as_matrix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Only for testing dataset for Nan values\n",
    "# count= 0\n",
    "# for ix in range(label.shape[0]):\n",
    "#     if(label[ix][8]!=0. and label[ix][8]!=1.):\n",
    "#         print(ix)\n",
    "#         print (comment[ix])\n",
    "#         count+=1\n",
    "#         print(label[ix])\n",
    "# print(count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let us find out the frequency of occurence of multilabelled data \n",
    "- ct1 counts samples having atleast one label\n",
    "- ct2 counts samples having 2 or more than 2 labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "124\n",
      "27\n"
     ]
    }
   ],
   "source": [
    "ct1,ct2 = 0,0\n",
    "for i in range(label.shape[0]):\n",
    "    ct = np.count_nonzero(label[i])\n",
    "    if ct :\n",
    "        ct1 = ct1+1\n",
    "    if ct>1 :\n",
    "        ct2 = ct2+1\n",
    "print(ct1)\n",
    "print(ct2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Visualisations\n",
    "### Let us analyse the no. of comments having lengths varying from 0 to 1200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average length of comment: 1426.919\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "x = [len(comment[i]) for i in range(comment.shape[0])]\n",
    "\n",
    "print('average length of comment: {:.3f}'.format(sum(x)/len(x)) )\n",
    "bins = [1,200,400,600,800,1000,1200]\n",
    "plt.hist(x, bins=bins)\n",
    "plt.xlabel('Length of comments')\n",
    "plt.ylabel('Number of comments')       \n",
    "plt.axis([0, 1200, 0, 20])\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Number of comments classified as toxic,severe_toxic,....etc depending on their lengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "y = np.zeros(label.shape)\n",
    "for ix in range(comment.shape[0]):\n",
    "    l = len(comment[ix])\n",
    "    if label[ix][0] :\n",
    "        y[ix][0] = l\n",
    "    if label[ix][1] :\n",
    "        y[ix][1] = l\n",
    "    if label[ix][2] :\n",
    "        y[ix][2] = l\n",
    "    if label[ix][3] :\n",
    "        y[ix][3] = l\n",
    "    if label[ix][4] :\n",
    "        y[ix][4] = l\n",
    "    if label[ix][5] :\n",
    "        y[ix][5] = l\n",
    "\n",
    "labelsplt = ['Language Learning', 'Computer Engineering' , 'General Learnng' , 'Exam Preparation' , 'Maths' , 'Art', 'other engineering', 'Educational Gaming', 'misc']\n",
    "color = ['red','green','blue','yellow','orange','chartreuse','black','magenta','purple']        \n",
    "plt.hist(y,bins = bins,label = labelsplt,color = color)\n",
    "plt.axis([0, 1500, 0, 8])\n",
    "plt.xlabel('Length of comments')\n",
    "plt.ylabel('Number of comments') \n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating a separate variable for app description (comments) and labels (classifiers)\n",
    "comments = []\n",
    "labels = []\n",
    "\n",
    "for ix in range(comment.shape[0]):\n",
    "    comments.append(comment[ix])\n",
    "    labels.append(label[ix])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = np.asarray(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 0 0 0 0 0 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "print (labels[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "124\n"
     ]
    }
   ],
   "source": [
    "print(len(comments))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing \n",
    "Preprocessing involved the following steps, but these will be performed in a slightly different manner:\n",
    "- Removing Punctuations and other special characters\n",
    "- Splitting the comments into individual words\n",
    "- Removing Stop Words\n",
    "- Stemming and Lemmatising\n",
    "- Applying Count Vectoriser\n",
    "- Splitting dataset into Training and Testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing a string containing all punctuations to be removed\n",
    "The string library contains punctuation characters. This is imported and all numbers are appended to this string. Also, we can notice that our comment_text field contains strings such as won't, didn't, etc which contain apostrophe character('). To prevent these words from being converted to wont/didnt, the character ' represented as \\' in escape sequence notation is replaced by empty character in the punctuation string. <br/>\n",
    "\n",
    "**maketrans()** returns a translation table that maps each character in the punctuation_edit into the character at the same position in the outtab string i.e. it replaces every character in the removal list with a space, since outtab contains a string with spaces."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "!\"#$%&'()*+,-./:;<=>?@[\\]^_`{|}~\n",
      "!\"#$%&()*+,-./:;<=>?@[\\]^_`{|}~0123456789\n"
     ]
    }
   ],
   "source": [
    "import string\n",
    "print(string.punctuation)\n",
    "punctuation_edit = string.punctuation.replace('\\'','') +\"0123456789\"\n",
    "print (punctuation_edit)\n",
    "outtab = \"                                         \"\n",
    "trantab = str.maketrans(punctuation_edit, outtab)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Updating the list of stop words\n",
    "**Stop words** are those words that are frequently used in both written and verbal communication and thereby do not have either a positive/negative impact on our statement.E.g. is, this, us,etc. <br/>\n",
    "Single letter words if existing or created due to any preprocessing step do not convey any useful meaning and hence can be directly removed. Hence letters from b to z, will be added to the list of stop words imported directly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from stop_words import get_stop_words\n",
    "stop_words = get_stop_words('english')\n",
    "stop_words.append('')\n",
    "\n",
    "for x in range(ord('b'), ord('z')+1):\n",
    "    stop_words.append(chr(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['a', 'about', 'above', 'after', 'again', 'against', 'all', 'am', 'an', 'and', 'any', 'are', \"aren't\", 'as', 'at', 'be', 'because', 'been', 'before', 'being', 'below', 'between', 'both', 'but', 'by', \"can't\", 'cannot', 'could', \"couldn't\", 'did', \"didn't\", 'do', 'does', \"doesn't\", 'doing', \"don't\", 'down', 'during', 'each', 'few', 'for', 'from', 'further', 'had', \"hadn't\", 'has', \"hasn't\", 'have', \"haven't\", 'having', 'he', \"he'd\", \"he'll\", \"he's\", 'her', 'here', \"here's\", 'hers', 'herself', 'him', 'himself', 'his', 'how', \"how's\", 'i', \"i'd\", \"i'll\", \"i'm\", \"i've\", 'if', 'in', 'into', 'is', \"isn't\", 'it', \"it's\", 'its', 'itself', \"let's\", 'me', 'more', 'most', \"mustn't\", 'my', 'myself', 'no', 'nor', 'not', 'of', 'off', 'on', 'once', 'only', 'or', 'other', 'ought', 'our', 'ours', 'ourselves', 'out', 'over', 'own', 'same', \"shan't\", 'she', \"she'd\", \"she'll\", \"she's\", 'should', \"shouldn't\", 'so', 'some', 'such', 'than', 'that', \"that's\", 'the', 'their', 'theirs', 'them', 'themselves', 'then', 'there', \"there's\", 'these', 'they', \"they'd\", \"they'll\", \"they're\", \"they've\", 'this', 'those', 'through', 'to', 'too', 'under', 'until', 'up', 'very', 'was', \"wasn't\", 'we', \"we'd\", \"we'll\", \"we're\", \"we've\", 'were', \"weren't\", 'what', \"what's\", 'when', \"when's\", 'where', \"where's\", 'which', 'while', 'who', \"who's\", 'whom', 'why', \"why's\", 'with', \"won't\", 'would', \"wouldn't\", 'you', \"you'd\", \"you'll\", \"you're\", \"you've\", 'your', 'yours', 'yourself', 'yourselves', '', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z']\n"
     ]
    }
   ],
   "source": [
    "print (stop_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stemming and Lemmatizing\n",
    "**Stemming** is the process of converting inflected/derived words to their word stem or the root form. Basically, a large number of similar origin words are converted to the same word.E.g. words like \"stems\", \"stemmer\", \"stemming\", \"stemmed\" as based on \"stem\". This helps in achieving the training process with a better accuracy.<br/>\n",
    "**Lemmatizing** is the process of grouping together the inflected forms of a word so they can be analysed as a single item. This is quite similar to stemming in its working but differs since it depends on correctly identifying the intended part of speech and meaning of a word in a sentence, as well as within the larger context surrounding that sentence, such as neighboring sentences or even an entire document.<br/>\n",
    "The **wordnet library in nltk** will be used for this purpose. Stemmer and Lemmatizer are also imported from nltk.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.stem import PorterStemmer, WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to /Users/paavini/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#create objects for stemmer and lemmatizer\n",
    "lemmatiser = WordNetLemmatizer()\n",
    "stemmer = PorterStemmer()\n",
    "#download words from wordnet library\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We can now, loop once through all the comments applying :\n",
    "- punctuation removal\n",
    "- splitting the words by space\n",
    "- applying stemmer and lemmatizer\n",
    "- recombining the words again for further processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(comments)):\n",
    "    comments[i] = comments[i].lower().translate(trantab)\n",
    "    l = []\n",
    "    for word in comments[i].split():\n",
    "        l.append(stemmer.stem(lemmatiser.lemmatize(word,pos=\"v\")))\n",
    "    comments[i] = \" \".join(l)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Applying Count Vectorizer\n",
    "Here we can finally convert our comments into a matrix of token counts, which signifies the number of times it occurs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import required library\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "#create object supplying our custom stop words\n",
    "count_vector = CountVectorizer(stop_words=stop_words)\n",
    "#fitting it to converts comments into bag of words format\n",
    "tf = count_vector.fit_transform(comments).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(124, 3095)\n"
     ]
    }
   ],
   "source": [
    "# print(count_vector.get_feature_names())\n",
    "print(tf.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hence from its shape we can imply that after all preprocessing we have a list of 52905 words in total.\n",
    "## Splitting dataset into training and testing\n",
    "- Since the system was going out of memory using train_test_split, I had jumbled all the indexes in the beginning itself. \n",
    "- The shuffle function defined here performs the task of assigning first 2/3rd values to train and remaining 1/3rd values to the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(31, 3095)\n",
      "(93, 3095)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "def shuffle(matrix, target, test_proportion):\n",
    "    ratio = int(matrix.shape[0]/test_proportion)\n",
    "    X_train = matrix[ratio:,:]\n",
    "    X_test =  matrix[:ratio,:]\n",
    "    Y_train = target[ratio:,:]\n",
    "    Y_test =  target[:ratio,:]\n",
    "    return X_train, X_test, Y_train, Y_test\n",
    "\n",
    "# X_train, X_test, Y_train, Y_test = shuffle(tf, labels,5)\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(tf, labels, test_size=0.25, random_state=42)\n",
    "\n",
    "print(X_test.shape)\n",
    "print(X_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementation :\n",
    "### Let us define all the evaluation metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import hamming_loss\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import log_loss\n",
    "\n",
    "def evaluate_score(Y_test,predict): \n",
    "    loss = hamming_loss(Y_test,predict)\n",
    "    print(\"Hamming_loss : {}\".format(loss*100))\n",
    "    accuracy = accuracy_score(Y_test,predict)\n",
    "    print(\"Accuracy : {}\".format(accuracy*100))\n",
    "    try : \n",
    "        loss = log_loss(Y_test,predict)\n",
    "    except :\n",
    "        loss = log_loss(Y_test,predict.toarray())\n",
    "    print(\"Log_loss : {}\".format(loss))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Starting with the First Model -\n",
    "### Problem Transformation Methods :\n",
    "**These include the Binary Relevance, Label Powerset and Classifier Chain methods. Implementations of these methods is available in the scikit-multilearn library. **\n",
    "- I will be implementing the most basic method,which is the **Binary Relevance** method from scratch. It does not take into account the interdependence of labels and basically creates a separate classifier for each of the labels.\n",
    "- Scikit-multilearn library's classifier will also be imported and tested with different classifiers to observe if it gives similar results.\n",
    "\n",
    "### 1. Binary Relevance (BR) Method with MultinomialNB classifiers (from scratch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 0 0 1 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "print (Y_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clf will be the list of the classifiers for all the 6 labels\n",
    "# each classifier is fit with the training data and corresponding classifier\n",
    "clf = []\n",
    "for ix in range(9):\n",
    "    clf.append(MultinomialNB())\n",
    "    clf[ix].fit(X_train,Y_train[:,ix])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(31, 9)\n"
     ]
    }
   ],
   "source": [
    "# predict list contains the predictions, it is transposed later to get the proper shape\n",
    "predict = []\n",
    "for ix in range(9):\n",
    "    predict.append(clf[ix].predict(X_test))\n",
    "\n",
    "predict = np.asarray(np.transpose(predict))\n",
    "print(predict.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hamming_loss : 12.186379928315413\n",
      "Accuracy : 51.61290322580645\n",
      "Log_loss : 8.632300984363441\n"
     ]
    }
   ],
   "source": [
    "# calculate results\n",
    "evaluate_score(Y_test,predict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. BR Method with Multinomial classifier (from scikit-multilearn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BinaryRelevance(classifier=MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True),\n",
       "        require_dense=[False, True])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#create and fit classifier\n",
    "from skmultilearn.problem_transform import BinaryRelevance\n",
    "classifier = BinaryRelevance(classifier = MultinomialNB(), require_dense = [False, True])\n",
    "classifier.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#predictions\n",
    "predictions = classifier.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hamming_loss : 12.186379928315413\n",
      "Accuracy : 51.61290322580645\n",
      "Log_loss : 8.632300984363441\n"
     ]
    }
   ],
   "source": [
    "#calculate scores\n",
    "evaluate_score(Y_test,predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. BR Method with GausseanNB classifier (from scratch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "#create and fit classifiers\n",
    "clf = []\n",
    "for ix in range(9):\n",
    "    clf.append(GaussianNB())\n",
    "    clf[ix].fit(X_train,Y_train[:,ix])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#predictions\n",
    "predict = []\n",
    "for ix in range(9):\n",
    "    predict.append(clf[ix].predict(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hamming_loss : 11.11111111111111\n",
      "Accuracy : 29.03225806451613\n",
      "Log_loss : 6.299449825496276\n"
     ]
    }
   ],
   "source": [
    "#calculate scores\n",
    "predict = np.asarray(np.transpose(predict))\n",
    "evaluate_score(Y_test,predict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Classifier chain with MultinomialNB classifier (from scikit-multilearn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ClassifierChain(classifier=MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True),\n",
       "        require_dense=[True, True])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#create and fit classifier\n",
    "from skmultilearn.problem_transform import ClassifierChain\n",
    "classifier = ClassifierChain(MultinomialNB())\n",
    "classifier.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "#predictions\n",
    "predictions = classifier.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hamming_loss : 11.469534050179211\n",
      "Accuracy : 51.61290322580645\n",
      "Log_loss : 8.61542201198394\n"
     ]
    }
   ],
   "source": [
    "#calculate scores\n",
    "evaluate_score(Y_test,predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Label Powerset with MultinomialNB classifier (from scikit-multilearn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LabelPowerset(classifier=MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True),\n",
       "       require_dense=[True, True])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#create and fit classifier\n",
    "from skmultilearn.problem_transform import LabelPowerset\n",
    "classifier = LabelPowerset(MultinomialNB())\n",
    "classifier.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "#predictions\n",
    "predictions = classifier.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hamming_loss : 9.31899641577061\n",
      "Accuracy : 61.29032258064516\n",
      "Log_loss : 18.998418005893868\n"
     ]
    }
   ],
   "source": [
    "#calculate scores\n",
    "evaluate_score(Y_test,predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adaptation Algorithms\n",
    "### 6. MLkNN  with k=2 (from scikit-multilearn)\n",
    "This is the adapted multi-label version of K Nearest Neighbours. Its implementation is available in the multilearn library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLkNN(ignore_first_neighbours=0, k=5, s=1.0)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#create and fit classifier\n",
    "from skmultilearn.adapt import MLkNN\n",
    "classifier = MLkNN(k=5)\n",
    "classifier.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "#predictions\n",
    "predictions = classifier.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hamming_loss : 11.469534050179211\n",
      "Accuracy : 35.483870967741936\n",
      "Log_loss : 11.344114234571348\n"
     ]
    }
   ],
   "source": [
    "#calculate scores\n",
    "evaluate_score(Y_test,predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. BP-MLL Neural Networks (from scratch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 20)                61920     \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 20)                0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 9)                 189       \n",
      "=================================================================\n",
      "Total params: 62,109\n",
      "Trainable params: 62,109\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#define model architecture\n",
    "model = Sequential()\n",
    "model.add(Dense(20, activation='relu', input_dim = X_train.shape[1]))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Dense(9, activation='softmax'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "#compile model with all parameters set\n",
    "model.compile(optimizer='rmsprop',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "93/93 [==============================] - 0s 3ms/step - loss: 2.8532 - acc: 0.1398\n",
      "Epoch 2/10\n",
      "93/93 [==============================] - 0s 151us/step - loss: 2.5047 - acc: 0.3226\n",
      "Epoch 3/10\n",
      "93/93 [==============================] - 0s 173us/step - loss: 2.3101 - acc: 0.4731\n",
      "Epoch 4/10\n",
      "93/93 [==============================] - 0s 183us/step - loss: 2.0817 - acc: 0.5699\n",
      "Epoch 5/10\n",
      "93/93 [==============================] - 0s 170us/step - loss: 1.8782 - acc: 0.6774\n",
      "Epoch 6/10\n",
      "93/93 [==============================] - 0s 161us/step - loss: 1.8952 - acc: 0.6344\n",
      "Epoch 7/10\n",
      "93/93 [==============================] - 0s 161us/step - loss: 1.6681 - acc: 0.7849\n",
      "Epoch 8/10\n",
      "93/93 [==============================] - 0s 160us/step - loss: 1.6252 - acc: 0.7527\n",
      "Epoch 9/10\n",
      "93/93 [==============================] - 0s 144us/step - loss: 1.5235 - acc: 0.7527\n",
      "Epoch 10/10\n",
      "93/93 [==============================] - 0s 165us/step - loss: 1.4325 - acc: 0.7634\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x120d29e48>"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Fit using check pointer\n",
    "from keras.callbacks import ModelCheckpoint  \n",
    "\n",
    "checkpointer = ModelCheckpoint(filepath='saved_models/weights.best.myneural.h5py', \n",
    "                               verbose=1, save_best_only=True)\n",
    "model.fit(X_train, Y_train, epochs=10, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "#predictions\n",
    "predict = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.04141634 0.06546991 0.01012321 0.12140076 0.17862456 0.14328544\n",
      " 0.09208215 0.26459968 0.08299797]\n"
     ]
    }
   ],
   "source": [
    "print(predict[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Since the results returned by the model are in the form of probabilities, they have to be explicitly converted to either 0/1 using the round function. This is because the hamming_loss and accuracy_score cannot work on these values directly. However, log loss can compute loss directly without modifying the values.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Log_loss : 2.048833615356876\n",
      "Hamming_loss : 13.620071684587815\n",
      "Accuracy : 12.903225806451612\n"
     ]
    }
   ],
   "source": [
    "#calculate score\n",
    "loss = log_loss(Y_test,predict)\n",
    "print(\"Log_loss : {}\".format(loss))\n",
    "predict = np.round(predict)\n",
    "loss = hamming_loss(Y_test,predict)\n",
    "print(\"Hamming_loss : {}\".format(loss*100))\n",
    "accuracy = accuracy_score(Y_test,predict)\n",
    "print(\"Accuracy : {}\".format(accuracy*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Let us try improving the BP-MLL model (Refining)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Dropout\n",
    "from keras import optimizers\n",
    "\n",
    "#define parameters for using in param grid\n",
    "nodes = [16, 32] # number of nodes in the hidden layer\n",
    "lrs = [0.001, 0.002, 0.003] # learning rate, default = 0.001\n",
    "epochs = [10,20]\n",
    "batch_size = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(nodes=10,lr=0.001):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(nodes, activation='relu', input_dim = X_train.shape[1]))\n",
    "    model.add(Dropout(0.3))\n",
    "    model.add(Dense(9, activation='softmax'))\n",
    "    opt = optimizers.RMSprop(lr=lr)\n",
    "    model.compile(optimizer=opt,\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "model = KerasClassifier(build_fn=create_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 12 candidates, totalling 36 fits\n",
      "[CV] epochs=10, lr=0.001, nodes=16 ...................................\n",
      "Epoch 1/10\n",
      "62/62 [==============================] - 0s 6ms/step - loss: 2.8156 - acc: 0.1774\n",
      "Epoch 2/10\n",
      "62/62 [==============================] - 0s 148us/step - loss: 2.4316 - acc: 0.2742\n",
      "Epoch 3/10\n",
      "62/62 [==============================] - 0s 171us/step - loss: 2.1968 - acc: 0.5000\n",
      "Epoch 4/10\n",
      "62/62 [==============================] - 0s 162us/step - loss: 2.0765 - acc: 0.5968\n",
      "Epoch 5/10\n",
      "62/62 [==============================] - 0s 164us/step - loss: 1.9246 - acc: 0.6452\n",
      "Epoch 6/10\n",
      "62/62 [==============================] - 0s 182us/step - loss: 1.7802 - acc: 0.6613\n",
      "Epoch 7/10\n",
      "62/62 [==============================] - 0s 154us/step - loss: 1.6844 - acc: 0.7258\n",
      "Epoch 8/10\n",
      "62/62 [==============================] - 0s 190us/step - loss: 1.5620 - acc: 0.8065\n",
      "Epoch 9/10\n",
      "62/62 [==============================] - 0s 196us/step - loss: 1.5291 - acc: 0.7419\n",
      "Epoch 10/10\n",
      "62/62 [==============================] - 0s 173us/step - loss: 1.4527 - acc: 0.7419\n",
      "31/31 [==============================] - 0s 1ms/step\n",
      "62/62 [==============================] - 0s 90us/step\n",
      "[CV] .................... epochs=10, lr=0.001, nodes=16, total=   1.1s\n",
      "[CV] epochs=10, lr=0.001, nodes=16 ...................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    1.1s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "62/62 [==============================] - 0s 6ms/step - loss: 3.0977 - acc: 0.0806\n",
      "Epoch 2/10\n",
      "62/62 [==============================] - 0s 151us/step - loss: 2.7317 - acc: 0.2742\n",
      "Epoch 3/10\n",
      "62/62 [==============================] - 0s 185us/step - loss: 2.5161 - acc: 0.3387\n",
      "Epoch 4/10\n",
      "62/62 [==============================] - 0s 178us/step - loss: 2.2944 - acc: 0.4677\n",
      "Epoch 5/10\n",
      "62/62 [==============================] - 0s 170us/step - loss: 2.1759 - acc: 0.5323\n",
      "Epoch 6/10\n",
      "62/62 [==============================] - 0s 184us/step - loss: 2.0458 - acc: 0.5645\n",
      "Epoch 7/10\n",
      "62/62 [==============================] - 0s 201us/step - loss: 1.9493 - acc: 0.6129\n",
      "Epoch 8/10\n",
      "62/62 [==============================] - 0s 158us/step - loss: 1.9330 - acc: 0.5806\n",
      "Epoch 9/10\n",
      "62/62 [==============================] - 0s 164us/step - loss: 1.8695 - acc: 0.6613\n",
      "Epoch 10/10\n",
      "62/62 [==============================] - 0s 186us/step - loss: 1.7811 - acc: 0.6290\n",
      "31/31 [==============================] - 0s 2ms/step\n",
      "62/62 [==============================] - 0s 96us/step\n",
      "[CV] .................... epochs=10, lr=0.001, nodes=16, total=   1.2s\n",
      "[CV] epochs=10, lr=0.001, nodes=16 ...................................\n",
      "Epoch 1/10\n",
      "62/62 [==============================] - 0s 7ms/step - loss: 2.9315 - acc: 0.2097\n",
      "Epoch 2/10\n",
      "62/62 [==============================] - 0s 142us/step - loss: 2.5405 - acc: 0.2742\n",
      "Epoch 3/10\n",
      "62/62 [==============================] - 0s 223us/step - loss: 2.3207 - acc: 0.4355\n",
      "Epoch 4/10\n",
      "62/62 [==============================] - 0s 195us/step - loss: 2.2146 - acc: 0.4516\n",
      "Epoch 5/10\n",
      "62/62 [==============================] - 0s 168us/step - loss: 2.0488 - acc: 0.5806\n",
      "Epoch 6/10\n",
      "62/62 [==============================] - 0s 149us/step - loss: 2.0566 - acc: 0.5484\n",
      "Epoch 7/10\n",
      "62/62 [==============================] - 0s 157us/step - loss: 1.8180 - acc: 0.6774\n",
      "Epoch 8/10\n",
      "62/62 [==============================] - 0s 174us/step - loss: 1.8260 - acc: 0.6452\n",
      "Epoch 9/10\n",
      "62/62 [==============================] - 0s 170us/step - loss: 1.6402 - acc: 0.7903\n",
      "Epoch 10/10\n",
      "62/62 [==============================] - 0s 151us/step - loss: 1.6392 - acc: 0.7742\n",
      "31/31 [==============================] - 0s 2ms/step\n",
      "62/62 [==============================] - 0s 105us/step\n",
      "[CV] .................... epochs=10, lr=0.001, nodes=16, total=   1.3s\n",
      "[CV] epochs=10, lr=0.001, nodes=32 ...................................\n",
      "Epoch 1/10\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 2.7702 - acc: 0.1613\n",
      "Epoch 2/10\n",
      "62/62 [==============================] - 0s 250us/step - loss: 2.3011 - acc: 0.3226\n",
      "Epoch 3/10\n",
      "62/62 [==============================] - 0s 280us/step - loss: 1.9680 - acc: 0.6613\n",
      "Epoch 4/10\n",
      "62/62 [==============================] - 0s 229us/step - loss: 1.7221 - acc: 0.7419\n",
      "Epoch 5/10\n",
      "62/62 [==============================] - 0s 224us/step - loss: 1.5850 - acc: 0.7742\n",
      "Epoch 6/10\n",
      "62/62 [==============================] - 0s 206us/step - loss: 1.4229 - acc: 0.8065\n",
      "Epoch 7/10\n",
      "62/62 [==============================] - 0s 208us/step - loss: 1.3653 - acc: 0.7903\n",
      "Epoch 8/10\n",
      "62/62 [==============================] - 0s 190us/step - loss: 1.2041 - acc: 0.8387\n",
      "Epoch 9/10\n",
      "62/62 [==============================] - 0s 184us/step - loss: 1.1736 - acc: 0.8548\n",
      "Epoch 10/10\n",
      "62/62 [==============================] - 0s 207us/step - loss: 1.1082 - acc: 0.8710\n",
      "31/31 [==============================] - 0s 2ms/step\n",
      "62/62 [==============================] - 0s 90us/step\n",
      "[CV] .................... epochs=10, lr=0.001, nodes=32, total=   1.4s\n",
      "[CV] epochs=10, lr=0.001, nodes=32 ...................................\n",
      "Epoch 1/10\n",
      "62/62 [==============================] - 0s 7ms/step - loss: 2.9026 - acc: 0.2419\n",
      "Epoch 2/10\n",
      "62/62 [==============================] - 0s 208us/step - loss: 2.3694 - acc: 0.6129\n",
      "Epoch 3/10\n",
      "62/62 [==============================] - 0s 183us/step - loss: 2.0506 - acc: 0.6290\n",
      "Epoch 4/10\n",
      "62/62 [==============================] - 0s 244us/step - loss: 1.8446 - acc: 0.7742\n",
      "Epoch 5/10\n",
      "62/62 [==============================] - 0s 231us/step - loss: 1.7607 - acc: 0.8387\n",
      "Epoch 6/10\n",
      "62/62 [==============================] - 0s 234us/step - loss: 1.5357 - acc: 0.7903\n",
      "Epoch 7/10\n",
      "62/62 [==============================] - 0s 212us/step - loss: 1.4986 - acc: 0.8387\n",
      "Epoch 8/10\n",
      "62/62 [==============================] - 0s 222us/step - loss: 1.3520 - acc: 0.8065\n",
      "Epoch 9/10\n",
      "62/62 [==============================] - 0s 203us/step - loss: 1.3496 - acc: 0.8226\n",
      "Epoch 10/10\n",
      "62/62 [==============================] - 0s 235us/step - loss: 1.2559 - acc: 0.8871\n",
      "31/31 [==============================] - 0s 3ms/step\n",
      "62/62 [==============================] - 0s 152us/step\n",
      "[CV] .................... epochs=10, lr=0.001, nodes=32, total=   1.6s\n",
      "[CV] epochs=10, lr=0.001, nodes=32 ...................................\n",
      "Epoch 1/10\n",
      "62/62 [==============================] - 0s 7ms/step - loss: 3.0317 - acc: 0.1935\n",
      "Epoch 2/10\n",
      "62/62 [==============================] - 0s 181us/step - loss: 2.2989 - acc: 0.4839\n",
      "Epoch 3/10\n",
      "62/62 [==============================] - 0s 212us/step - loss: 1.9723 - acc: 0.6129\n",
      "Epoch 4/10\n",
      "62/62 [==============================] - 0s 217us/step - loss: 1.8621 - acc: 0.7097\n",
      "Epoch 5/10\n",
      "62/62 [==============================] - 0s 249us/step - loss: 1.6280 - acc: 0.8226\n",
      "Epoch 6/10\n",
      "62/62 [==============================] - 0s 198us/step - loss: 1.5256 - acc: 0.7581\n",
      "Epoch 7/10\n",
      "62/62 [==============================] - 0s 179us/step - loss: 1.4662 - acc: 0.7742\n",
      "Epoch 8/10\n",
      "62/62 [==============================] - 0s 216us/step - loss: 1.2779 - acc: 0.7903\n",
      "Epoch 9/10\n",
      "62/62 [==============================] - 0s 229us/step - loss: 1.2756 - acc: 0.8226\n",
      "Epoch 10/10\n",
      "62/62 [==============================] - 0s 219us/step - loss: 1.2500 - acc: 0.8548\n",
      "31/31 [==============================] - 0s 3ms/step\n",
      "62/62 [==============================] - 0s 97us/step\n",
      "[CV] .................... epochs=10, lr=0.001, nodes=32, total=   1.3s\n",
      "[CV] epochs=10, lr=0.002, nodes=16 ...................................\n",
      "Epoch 1/10\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 2.7975 - acc: 0.1774\n",
      "Epoch 2/10\n",
      "62/62 [==============================] - 0s 176us/step - loss: 2.2482 - acc: 0.4516\n",
      "Epoch 3/10\n",
      "62/62 [==============================] - 0s 166us/step - loss: 1.9970 - acc: 0.5806\n",
      "Epoch 4/10\n",
      "62/62 [==============================] - 0s 210us/step - loss: 1.7686 - acc: 0.5806\n",
      "Epoch 5/10\n",
      "62/62 [==============================] - 0s 191us/step - loss: 1.4982 - acc: 0.7097\n",
      "Epoch 6/10\n",
      "62/62 [==============================] - 0s 205us/step - loss: 1.3759 - acc: 0.6935\n",
      "Epoch 7/10\n",
      "62/62 [==============================] - 0s 165us/step - loss: 1.3661 - acc: 0.7258\n",
      "Epoch 8/10\n",
      "62/62 [==============================] - 0s 181us/step - loss: 1.2596 - acc: 0.7419\n",
      "Epoch 9/10\n",
      "62/62 [==============================] - 0s 199us/step - loss: 1.3658 - acc: 0.8226\n",
      "Epoch 10/10\n",
      "62/62 [==============================] - 0s 187us/step - loss: 1.1246 - acc: 0.7419\n",
      "31/31 [==============================] - 0s 4ms/step\n",
      "62/62 [==============================] - 0s 518us/step\n",
      "[CV] .................... epochs=10, lr=0.002, nodes=16, total=   1.3s\n",
      "[CV] epochs=10, lr=0.002, nodes=16 ...................................\n",
      "Epoch 1/10\n",
      "62/62 [==============================] - 1s 15ms/step - loss: 3.0421 - acc: 0.1774\n",
      "Epoch 2/10\n",
      "62/62 [==============================] - 0s 199us/step - loss: 2.5061 - acc: 0.4516\n",
      "Epoch 3/10\n",
      "62/62 [==============================] - 0s 265us/step - loss: 2.1860 - acc: 0.6129\n",
      "Epoch 4/10\n",
      "62/62 [==============================] - 0s 172us/step - loss: 2.0465 - acc: 0.6613\n",
      "Epoch 5/10\n",
      "62/62 [==============================] - 0s 176us/step - loss: 1.8157 - acc: 0.6452\n",
      "Epoch 6/10\n",
      "62/62 [==============================] - 0s 201us/step - loss: 1.7301 - acc: 0.6613\n",
      "Epoch 7/10\n",
      "62/62 [==============================] - 0s 188us/step - loss: 1.6346 - acc: 0.7258\n",
      "Epoch 8/10\n",
      "62/62 [==============================] - 0s 144us/step - loss: 1.4825 - acc: 0.7258\n",
      "Epoch 9/10\n",
      "62/62 [==============================] - 0s 208us/step - loss: 1.4652 - acc: 0.7903\n",
      "Epoch 10/10\n",
      "62/62 [==============================] - 0s 169us/step - loss: 1.5197 - acc: 0.7258\n",
      "31/31 [==============================] - 0s 4ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "62/62 [==============================] - 0s 78us/step\n",
      "[CV] .................... epochs=10, lr=0.002, nodes=16, total=   2.0s\n",
      "[CV] epochs=10, lr=0.002, nodes=16 ...................................\n",
      "Epoch 1/10\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 3.0735 - acc: 0.0968\n",
      "Epoch 2/10\n",
      "62/62 [==============================] - 0s 155us/step - loss: 2.3322 - acc: 0.4194\n",
      "Epoch 3/10\n",
      "62/62 [==============================] - 0s 151us/step - loss: 2.0783 - acc: 0.6290\n",
      "Epoch 4/10\n",
      "62/62 [==============================] - 0s 213us/step - loss: 1.7985 - acc: 0.6129\n",
      "Epoch 5/10\n",
      "62/62 [==============================] - 0s 188us/step - loss: 1.7331 - acc: 0.6774\n",
      "Epoch 6/10\n",
      "62/62 [==============================] - 0s 170us/step - loss: 1.5673 - acc: 0.7742\n",
      "Epoch 7/10\n",
      "62/62 [==============================] - 0s 160us/step - loss: 1.4043 - acc: 0.8226\n",
      "Epoch 8/10\n",
      "62/62 [==============================] - 0s 195us/step - loss: 1.4939 - acc: 0.7419\n",
      "Epoch 9/10\n",
      "62/62 [==============================] - 0s 199us/step - loss: 1.3993 - acc: 0.8226\n",
      "Epoch 10/10\n",
      "62/62 [==============================] - 0s 138us/step - loss: 1.4299 - acc: 0.7742\n",
      "31/31 [==============================] - 0s 4ms/step\n",
      "62/62 [==============================] - 0s 115us/step\n",
      "[CV] .................... epochs=10, lr=0.002, nodes=16, total=   1.4s\n",
      "[CV] epochs=10, lr=0.002, nodes=32 ...................................\n",
      "Epoch 1/10\n",
      "62/62 [==============================] - 1s 11ms/step - loss: 2.7629 - acc: 0.2097\n",
      "Epoch 2/10\n",
      "62/62 [==============================] - 0s 228us/step - loss: 1.8787 - acc: 0.6290\n",
      "Epoch 3/10\n",
      "62/62 [==============================] - 0s 237us/step - loss: 1.5309 - acc: 0.7903\n",
      "Epoch 4/10\n",
      "62/62 [==============================] - 0s 213us/step - loss: 1.2473 - acc: 0.8387\n",
      "Epoch 5/10\n",
      "62/62 [==============================] - 0s 274us/step - loss: 1.1184 - acc: 0.8065\n",
      "Epoch 6/10\n",
      "62/62 [==============================] - 0s 206us/step - loss: 1.0620 - acc: 0.8226\n",
      "Epoch 7/10\n",
      "62/62 [==============================] - 0s 262us/step - loss: 1.0075 - acc: 0.8871\n",
      "Epoch 8/10\n",
      "62/62 [==============================] - 0s 217us/step - loss: 0.9280 - acc: 0.8226\n",
      "Epoch 9/10\n",
      "62/62 [==============================] - 0s 239us/step - loss: 0.8251 - acc: 0.8387\n",
      "Epoch 10/10\n",
      "62/62 [==============================] - 0s 186us/step - loss: 0.8643 - acc: 0.8387\n",
      "31/31 [==============================] - 0s 5ms/step\n",
      "62/62 [==============================] - 0s 97us/step\n",
      "[CV] .................... epochs=10, lr=0.002, nodes=32, total=   1.7s\n",
      "[CV] epochs=10, lr=0.002, nodes=32 ...................................\n",
      "Epoch 1/10\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 3.1929 - acc: 0.1613\n",
      "Epoch 2/10\n",
      "62/62 [==============================] - 0s 196us/step - loss: 2.1988 - acc: 0.5161\n",
      "Epoch 3/10\n",
      "62/62 [==============================] - 0s 181us/step - loss: 1.8023 - acc: 0.7742\n",
      "Epoch 4/10\n",
      "62/62 [==============================] - 0s 208us/step - loss: 1.5145 - acc: 0.7742\n",
      "Epoch 5/10\n",
      "62/62 [==============================] - 0s 238us/step - loss: 1.3377 - acc: 0.8871\n",
      "Epoch 6/10\n",
      "62/62 [==============================] - 0s 232us/step - loss: 1.1971 - acc: 0.8387\n",
      "Epoch 7/10\n",
      "62/62 [==============================] - 0s 219us/step - loss: 1.1992 - acc: 0.9194\n",
      "Epoch 8/10\n",
      "62/62 [==============================] - 0s 217us/step - loss: 1.2188 - acc: 0.9032\n",
      "Epoch 9/10\n",
      "62/62 [==============================] - 0s 191us/step - loss: 1.0138 - acc: 0.8548\n",
      "Epoch 10/10\n",
      "62/62 [==============================] - 0s 197us/step - loss: 0.9475 - acc: 0.8871\n",
      "31/31 [==============================] - 0s 5ms/step\n",
      "62/62 [==============================] - 0s 130us/step\n",
      "[CV] .................... epochs=10, lr=0.002, nodes=32, total=   1.7s\n",
      "[CV] epochs=10, lr=0.002, nodes=32 ...................................\n",
      "Epoch 1/10\n",
      "62/62 [==============================] - 1s 11ms/step - loss: 2.9994 - acc: 0.1452\n",
      "Epoch 2/10\n",
      "62/62 [==============================] - 0s 235us/step - loss: 1.9661 - acc: 0.6452\n",
      "Epoch 3/10\n",
      "62/62 [==============================] - 0s 205us/step - loss: 1.5704 - acc: 0.7581\n",
      "Epoch 4/10\n",
      "62/62 [==============================] - 0s 242us/step - loss: 1.3663 - acc: 0.8548\n",
      "Epoch 5/10\n",
      "62/62 [==============================] - 0s 185us/step - loss: 1.3107 - acc: 0.8226\n",
      "Epoch 6/10\n",
      "62/62 [==============================] - 0s 183us/step - loss: 1.1302 - acc: 0.7903\n",
      "Epoch 7/10\n",
      "62/62 [==============================] - 0s 212us/step - loss: 1.1043 - acc: 0.8548\n",
      "Epoch 8/10\n",
      "62/62 [==============================] - 0s 259us/step - loss: 1.0503 - acc: 0.7903\n",
      "Epoch 9/10\n",
      "62/62 [==============================] - 0s 214us/step - loss: 0.9183 - acc: 0.8710\n",
      "Epoch 10/10\n",
      "62/62 [==============================] - 0s 208us/step - loss: 0.9478 - acc: 0.8226\n",
      "31/31 [==============================] - 0s 5ms/step\n",
      "62/62 [==============================] - 0s 105us/step\n",
      "[CV] .................... epochs=10, lr=0.002, nodes=32, total=   1.8s\n",
      "[CV] epochs=10, lr=0.003, nodes=16 ...................................\n",
      "Epoch 1/10\n",
      "62/62 [==============================] - 1s 12ms/step - loss: 2.8002 - acc: 0.1290\n",
      "Epoch 2/10\n",
      "62/62 [==============================] - 0s 186us/step - loss: 2.1103 - acc: 0.4355\n",
      "Epoch 3/10\n",
      "62/62 [==============================] - 0s 200us/step - loss: 1.7914 - acc: 0.5645\n",
      "Epoch 4/10\n",
      "62/62 [==============================] - 0s 210us/step - loss: 1.5260 - acc: 0.6129\n",
      "Epoch 5/10\n",
      "62/62 [==============================] - 0s 171us/step - loss: 1.3968 - acc: 0.6452\n",
      "Epoch 6/10\n",
      "62/62 [==============================] - 0s 180us/step - loss: 1.2910 - acc: 0.7419\n",
      "Epoch 7/10\n",
      "62/62 [==============================] - 0s 181us/step - loss: 1.2950 - acc: 0.7742\n",
      "Epoch 8/10\n",
      "62/62 [==============================] - 0s 193us/step - loss: 1.1869 - acc: 0.7258\n",
      "Epoch 9/10\n",
      "62/62 [==============================] - 0s 161us/step - loss: 1.0846 - acc: 0.7419\n",
      "Epoch 10/10\n",
      "62/62 [==============================] - 0s 189us/step - loss: 1.0305 - acc: 0.7419\n",
      "31/31 [==============================] - 0s 6ms/step\n",
      "62/62 [==============================] - 0s 114us/step\n",
      "[CV] .................... epochs=10, lr=0.003, nodes=16, total=   1.9s\n",
      "[CV] epochs=10, lr=0.003, nodes=16 ...................................\n",
      "Epoch 1/10\n",
      "62/62 [==============================] - 1s 12ms/step - loss: 2.9746 - acc: 0.1935\n",
      "Epoch 2/10\n",
      "62/62 [==============================] - 0s 177us/step - loss: 2.2614 - acc: 0.4839\n",
      "Epoch 3/10\n",
      "62/62 [==============================] - 0s 179us/step - loss: 1.9456 - acc: 0.6613\n",
      "Epoch 4/10\n",
      "62/62 [==============================] - 0s 167us/step - loss: 1.6732 - acc: 0.6774\n",
      "Epoch 5/10\n",
      "62/62 [==============================] - 0s 166us/step - loss: 1.5164 - acc: 0.7742\n",
      "Epoch 6/10\n",
      "62/62 [==============================] - 0s 210us/step - loss: 1.4567 - acc: 0.7581\n",
      "Epoch 7/10\n",
      "62/62 [==============================] - 0s 167us/step - loss: 1.4857 - acc: 0.7903\n",
      "Epoch 8/10\n",
      "62/62 [==============================] - 0s 221us/step - loss: 1.4338 - acc: 0.7903\n",
      "Epoch 9/10\n",
      "62/62 [==============================] - 0s 143us/step - loss: 1.2966 - acc: 0.7742\n",
      "Epoch 10/10\n",
      "62/62 [==============================] - 0s 192us/step - loss: 1.3434 - acc: 0.7903\n",
      "31/31 [==============================] - 0s 6ms/step\n",
      "62/62 [==============================] - 0s 99us/step\n",
      "[CV] .................... epochs=10, lr=0.003, nodes=16, total=   1.8s\n",
      "[CV] epochs=10, lr=0.003, nodes=16 ...................................\n",
      "Epoch 1/10\n",
      "62/62 [==============================] - 1s 11ms/step - loss: 3.0160 - acc: 0.1290\n",
      "Epoch 2/10\n",
      "62/62 [==============================] - 0s 158us/step - loss: 2.4253 - acc: 0.3548\n",
      "Epoch 3/10\n",
      "62/62 [==============================] - 0s 177us/step - loss: 2.0521 - acc: 0.4677\n",
      "Epoch 4/10\n",
      "62/62 [==============================] - 0s 199us/step - loss: 1.8234 - acc: 0.6935\n",
      "Epoch 5/10\n",
      "62/62 [==============================] - 0s 151us/step - loss: 1.7094 - acc: 0.6290\n",
      "Epoch 6/10\n",
      "62/62 [==============================] - 0s 210us/step - loss: 1.5268 - acc: 0.7097\n",
      "Epoch 7/10\n",
      "62/62 [==============================] - 0s 190us/step - loss: 1.3769 - acc: 0.7258\n",
      "Epoch 8/10\n",
      "62/62 [==============================] - 0s 211us/step - loss: 1.2286 - acc: 0.8226\n",
      "Epoch 9/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "62/62 [==============================] - 0s 160us/step - loss: 1.2346 - acc: 0.7419\n",
      "Epoch 10/10\n",
      "62/62 [==============================] - 0s 194us/step - loss: 1.2660 - acc: 0.7903\n",
      "31/31 [==============================] - 0s 6ms/step\n",
      "62/62 [==============================] - 0s 86us/step\n",
      "[CV] .................... epochs=10, lr=0.003, nodes=16, total=   1.5s\n",
      "[CV] epochs=10, lr=0.003, nodes=32 ...................................\n",
      "Epoch 1/10\n",
      "62/62 [==============================] - 1s 12ms/step - loss: 2.6763 - acc: 0.2581\n",
      "Epoch 2/10\n",
      "62/62 [==============================] - 0s 206us/step - loss: 1.7943 - acc: 0.6452\n",
      "Epoch 3/10\n",
      "62/62 [==============================] - 0s 189us/step - loss: 1.3349 - acc: 0.8387\n",
      "Epoch 4/10\n",
      "62/62 [==============================] - 0s 202us/step - loss: 1.1084 - acc: 0.8226\n",
      "Epoch 5/10\n",
      "62/62 [==============================] - 0s 218us/step - loss: 0.9498 - acc: 0.9194\n",
      "Epoch 6/10\n",
      "62/62 [==============================] - 0s 212us/step - loss: 0.8252 - acc: 0.8387\n",
      "Epoch 7/10\n",
      "62/62 [==============================] - 0s 221us/step - loss: 0.7712 - acc: 0.9032\n",
      "Epoch 8/10\n",
      "62/62 [==============================] - 0s 206us/step - loss: 0.7435 - acc: 0.8548\n",
      "Epoch 9/10\n",
      "62/62 [==============================] - 0s 190us/step - loss: 0.7333 - acc: 0.9194\n",
      "Epoch 10/10\n",
      "62/62 [==============================] - 0s 218us/step - loss: 0.7835 - acc: 0.8226\n",
      "31/31 [==============================] - 0s 6ms/step\n",
      "62/62 [==============================] - 0s 97us/step\n",
      "[CV] .................... epochs=10, lr=0.003, nodes=32, total=   1.6s\n",
      "[CV] epochs=10, lr=0.003, nodes=32 ...................................\n",
      "Epoch 1/10\n",
      "62/62 [==============================] - 1s 11ms/step - loss: 3.0172 - acc: 0.1290\n",
      "Epoch 2/10\n",
      "62/62 [==============================] - 0s 196us/step - loss: 2.2940 - acc: 0.4839\n",
      "Epoch 3/10\n",
      "62/62 [==============================] - 0s 175us/step - loss: 1.7809 - acc: 0.7258\n",
      "Epoch 4/10\n",
      "62/62 [==============================] - 0s 212us/step - loss: 1.4969 - acc: 0.7097\n",
      "Epoch 5/10\n",
      "62/62 [==============================] - 0s 201us/step - loss: 1.3803 - acc: 0.8387\n",
      "Epoch 6/10\n",
      "62/62 [==============================] - 0s 212us/step - loss: 1.1787 - acc: 0.8710\n",
      "Epoch 7/10\n",
      "62/62 [==============================] - 0s 187us/step - loss: 1.1571 - acc: 0.8226\n",
      "Epoch 8/10\n",
      "62/62 [==============================] - 0s 181us/step - loss: 1.0590 - acc: 0.8387\n",
      "Epoch 9/10\n",
      "62/62 [==============================] - 0s 202us/step - loss: 1.1110 - acc: 0.8548\n",
      "Epoch 10/10\n",
      "62/62 [==============================] - 0s 202us/step - loss: 0.9924 - acc: 0.8548\n",
      "31/31 [==============================] - 0s 6ms/step\n",
      "62/62 [==============================] - 0s 94us/step\n",
      "[CV] .................... epochs=10, lr=0.003, nodes=32, total=   1.6s\n",
      "[CV] epochs=10, lr=0.003, nodes=32 ...................................\n",
      "Epoch 1/10\n",
      "62/62 [==============================] - 1s 12ms/step - loss: 3.0537 - acc: 0.1129\n",
      "Epoch 2/10\n",
      "62/62 [==============================] - 0s 181us/step - loss: 1.9527 - acc: 0.6935\n",
      "Epoch 3/10\n",
      "62/62 [==============================] - 0s 190us/step - loss: 1.5113 - acc: 0.8065\n",
      "Epoch 4/10\n",
      "62/62 [==============================] - 0s 223us/step - loss: 1.4571 - acc: 0.7742\n",
      "Epoch 5/10\n",
      "62/62 [==============================] - 0s 197us/step - loss: 1.2950 - acc: 0.8387\n",
      "Epoch 6/10\n",
      "62/62 [==============================] - 0s 200us/step - loss: 1.2187 - acc: 0.8065\n",
      "Epoch 7/10\n",
      "62/62 [==============================] - 0s 194us/step - loss: 1.0888 - acc: 0.8548\n",
      "Epoch 8/10\n",
      "62/62 [==============================] - 0s 186us/step - loss: 0.9746 - acc: 0.8710\n",
      "Epoch 9/10\n",
      "62/62 [==============================] - 0s 196us/step - loss: 0.9106 - acc: 0.8548\n",
      "Epoch 10/10\n",
      "62/62 [==============================] - 0s 213us/step - loss: 0.9041 - acc: 0.8548\n",
      "31/31 [==============================] - 0s 7ms/step\n",
      "62/62 [==============================] - 0s 102us/step\n",
      "[CV] .................... epochs=10, lr=0.003, nodes=32, total=   1.8s\n",
      "[CV] epochs=20, lr=0.001, nodes=16 ...................................\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 1s 12ms/step - loss: 2.8156 - acc: 0.1613\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 0s 147us/step - loss: 2.4891 - acc: 0.3226\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 0s 184us/step - loss: 2.3180 - acc: 0.3871\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 0s 176us/step - loss: 2.1374 - acc: 0.5968\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 0s 154us/step - loss: 1.9860 - acc: 0.6290\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 0s 175us/step - loss: 1.9091 - acc: 0.5806\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 0s 178us/step - loss: 1.7787 - acc: 0.6774\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 0s 153us/step - loss: 1.7904 - acc: 0.6129\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 0s 177us/step - loss: 1.6359 - acc: 0.6290\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 0s 177us/step - loss: 1.7232 - acc: 0.6452\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 0s 166us/step - loss: 1.5369 - acc: 0.7097\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 0s 143us/step - loss: 1.5340 - acc: 0.7581\n",
      "Epoch 13/20\n",
      "62/62 [==============================] - 0s 190us/step - loss: 1.3529 - acc: 0.7903\n",
      "Epoch 14/20\n",
      "62/62 [==============================] - 0s 188us/step - loss: 1.3823 - acc: 0.7742\n",
      "Epoch 15/20\n",
      "62/62 [==============================] - 0s 151us/step - loss: 1.2516 - acc: 0.7419\n",
      "Epoch 16/20\n",
      "62/62 [==============================] - 0s 168us/step - loss: 1.2931 - acc: 0.7742\n",
      "Epoch 17/20\n",
      "62/62 [==============================] - 0s 186us/step - loss: 1.3067 - acc: 0.7581\n",
      "Epoch 18/20\n",
      "62/62 [==============================] - 0s 133us/step - loss: 1.3098 - acc: 0.7419\n",
      "Epoch 19/20\n",
      "62/62 [==============================] - 0s 212us/step - loss: 1.1801 - acc: 0.7581\n",
      "Epoch 20/20\n",
      "62/62 [==============================] - 0s 175us/step - loss: 1.2946 - acc: 0.7581\n",
      "31/31 [==============================] - 0s 8ms/step\n",
      "62/62 [==============================] - 0s 118us/step\n",
      "[CV] .................... epochs=20, lr=0.001, nodes=16, total=   1.7s\n",
      "[CV] epochs=20, lr=0.001, nodes=16 ...................................\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 3.0510 - acc: 0.1613\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 0s 167us/step - loss: 2.5129 - acc: 0.4032\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 0s 154us/step - loss: 2.4033 - acc: 0.5000\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 0s 160us/step - loss: 2.1838 - acc: 0.5968\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 0s 175us/step - loss: 2.0906 - acc: 0.6290\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 0s 184us/step - loss: 1.9550 - acc: 0.7581\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 0s 141us/step - loss: 1.8814 - acc: 0.7581\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 0s 190us/step - loss: 1.7257 - acc: 0.7742\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 0s 186us/step - loss: 1.6974 - acc: 0.7581\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 0s 147us/step - loss: 1.6384 - acc: 0.7419\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 0s 169us/step - loss: 1.4731 - acc: 0.8710\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 0s 182us/step - loss: 1.4801 - acc: 0.8387\n",
      "Epoch 13/20\n",
      "62/62 [==============================] - 0s 148us/step - loss: 1.4613 - acc: 0.8226\n",
      "Epoch 14/20\n",
      "62/62 [==============================] - 0s 190us/step - loss: 1.4377 - acc: 0.8065\n",
      "Epoch 15/20\n",
      "62/62 [==============================] - 0s 184us/step - loss: 1.4236 - acc: 0.8226\n",
      "Epoch 16/20\n",
      "62/62 [==============================] - 0s 167us/step - loss: 1.2647 - acc: 0.8871\n",
      "Epoch 17/20\n",
      "62/62 [==============================] - 0s 174us/step - loss: 1.3201 - acc: 0.8387\n",
      "Epoch 18/20\n",
      "62/62 [==============================] - 0s 176us/step - loss: 1.2083 - acc: 0.9194\n",
      "Epoch 19/20\n",
      "62/62 [==============================] - 0s 196us/step - loss: 1.2835 - acc: 0.8065\n",
      "Epoch 20/20\n",
      "62/62 [==============================] - 0s 180us/step - loss: 1.2681 - acc: 0.8548\n",
      "31/31 [==============================] - 0s 7ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "62/62 [==============================] - 0s 90us/step\n",
      "[CV] .................... epochs=20, lr=0.001, nodes=16, total=   1.8s\n",
      "[CV] epochs=20, lr=0.001, nodes=16 ...................................\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 3.0237 - acc: 0.0968\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 0s 151us/step - loss: 2.5997 - acc: 0.3065\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 0s 173us/step - loss: 2.3416 - acc: 0.3871\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 0s 147us/step - loss: 2.2177 - acc: 0.5000\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 0s 186us/step - loss: 2.1076 - acc: 0.5806\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 0s 167us/step - loss: 2.0476 - acc: 0.5968\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 0s 167us/step - loss: 1.8815 - acc: 0.5968\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 0s 177us/step - loss: 1.8715 - acc: 0.6613\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 0s 192us/step - loss: 1.7519 - acc: 0.6774\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 0s 141us/step - loss: 1.7935 - acc: 0.6774\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 0s 168us/step - loss: 1.6941 - acc: 0.6452\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 0s 177us/step - loss: 1.5522 - acc: 0.7742\n",
      "Epoch 13/20\n",
      "62/62 [==============================] - 0s 167us/step - loss: 1.5698 - acc: 0.8065\n",
      "Epoch 14/20\n",
      "62/62 [==============================] - 0s 140us/step - loss: 1.5991 - acc: 0.7097\n",
      "Epoch 15/20\n",
      "62/62 [==============================] - 0s 179us/step - loss: 1.5810 - acc: 0.6290\n",
      "Epoch 16/20\n",
      "62/62 [==============================] - 0s 176us/step - loss: 1.4878 - acc: 0.7258\n",
      "Epoch 17/20\n",
      "62/62 [==============================] - 0s 150us/step - loss: 1.4441 - acc: 0.8387\n",
      "Epoch 18/20\n",
      "62/62 [==============================] - 0s 179us/step - loss: 1.3639 - acc: 0.7419\n",
      "Epoch 19/20\n",
      "62/62 [==============================] - 0s 192us/step - loss: 1.3467 - acc: 0.7258\n",
      "Epoch 20/20\n",
      "62/62 [==============================] - 0s 145us/step - loss: 1.4487 - acc: 0.7903\n",
      "31/31 [==============================] - 0s 8ms/step\n",
      "62/62 [==============================] - 0s 99us/step\n",
      "[CV] .................... epochs=20, lr=0.001, nodes=16, total=   1.8s\n",
      "[CV] epochs=20, lr=0.001, nodes=32 ...................................\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 1s 14ms/step - loss: 2.9308 - acc: 0.0484\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 0s 185us/step - loss: 2.3678 - acc: 0.4516\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 0s 200us/step - loss: 2.0590 - acc: 0.6290\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 0s 205us/step - loss: 1.7568 - acc: 0.8226\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 0s 221us/step - loss: 1.6813 - acc: 0.7581\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 0s 215us/step - loss: 1.4224 - acc: 0.8065\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 0s 205us/step - loss: 1.4094 - acc: 0.8065\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 0s 178us/step - loss: 1.2901 - acc: 0.8065\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 0s 185us/step - loss: 1.1498 - acc: 0.8387\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 0s 219us/step - loss: 1.1075 - acc: 0.8387\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 0s 199us/step - loss: 1.0586 - acc: 0.8065\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 0s 227us/step - loss: 1.0197 - acc: 0.9355\n",
      "Epoch 13/20\n",
      "62/62 [==============================] - 0s 211us/step - loss: 0.9872 - acc: 0.8387\n",
      "Epoch 14/20\n",
      "62/62 [==============================] - 0s 174us/step - loss: 0.9449 - acc: 0.8871\n",
      "Epoch 15/20\n",
      "62/62 [==============================] - 0s 211us/step - loss: 0.8815 - acc: 0.8065\n",
      "Epoch 16/20\n",
      "62/62 [==============================] - 0s 215us/step - loss: 0.8953 - acc: 0.8387\n",
      "Epoch 17/20\n",
      "62/62 [==============================] - 0s 192us/step - loss: 0.8277 - acc: 0.8548\n",
      "Epoch 18/20\n",
      "62/62 [==============================] - 0s 201us/step - loss: 0.8303 - acc: 0.8871\n",
      "Epoch 19/20\n",
      "62/62 [==============================] - 0s 171us/step - loss: 0.7556 - acc: 0.8548\n",
      "Epoch 20/20\n",
      "62/62 [==============================] - 0s 213us/step - loss: 0.8023 - acc: 0.9032\n",
      "31/31 [==============================] - 0s 8ms/step\n",
      "62/62 [==============================] - 0s 106us/step\n",
      "[CV] .................... epochs=20, lr=0.001, nodes=32, total=   2.0s\n",
      "[CV] epochs=20, lr=0.001, nodes=32 ...................................\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 1s 15ms/step - loss: 3.1380 - acc: 0.0645\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 0s 218us/step - loss: 2.4346 - acc: 0.5323\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 0s 206us/step - loss: 2.1937 - acc: 0.6613\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 0s 211us/step - loss: 1.9075 - acc: 0.7742\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 0s 234us/step - loss: 1.7845 - acc: 0.7419\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 0s 195us/step - loss: 1.5976 - acc: 0.7742\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 0s 204us/step - loss: 1.5827 - acc: 0.8065\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 0s 189us/step - loss: 1.5189 - acc: 0.7903\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 0s 208us/step - loss: 1.4458 - acc: 0.8710\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 0s 202us/step - loss: 1.2840 - acc: 0.8226\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 0s 190us/step - loss: 1.3069 - acc: 0.8387\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 0s 229us/step - loss: 1.2983 - acc: 0.8710\n",
      "Epoch 13/20\n",
      "62/62 [==============================] - 0s 161us/step - loss: 1.1610 - acc: 0.8710\n",
      "Epoch 14/20\n",
      "62/62 [==============================] - 0s 203us/step - loss: 1.0891 - acc: 0.8387\n",
      "Epoch 15/20\n",
      "62/62 [==============================] - 0s 207us/step - loss: 1.1114 - acc: 0.9194\n",
      "Epoch 16/20\n",
      "62/62 [==============================] - 0s 175us/step - loss: 1.0868 - acc: 0.8871\n",
      "Epoch 17/20\n",
      "62/62 [==============================] - 0s 182us/step - loss: 1.0587 - acc: 0.8387\n",
      "Epoch 18/20\n",
      "62/62 [==============================] - 0s 201us/step - loss: 0.9573 - acc: 0.8710\n",
      "Epoch 19/20\n",
      "62/62 [==============================] - 0s 191us/step - loss: 0.8893 - acc: 0.9032\n",
      "Epoch 20/20\n",
      "62/62 [==============================] - 0s 207us/step - loss: 0.9088 - acc: 0.8387\n",
      "31/31 [==============================] - 0s 9ms/step\n",
      "62/62 [==============================] - 0s 141us/step\n",
      "[CV] .................... epochs=20, lr=0.001, nodes=32, total=   2.2s\n",
      "[CV] epochs=20, lr=0.001, nodes=32 ...................................\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 1s 17ms/step - loss: 3.1264 - acc: 0.0806\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 0s 188us/step - loss: 2.4426 - acc: 0.4516\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 0s 239us/step - loss: 2.0962 - acc: 0.6452\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 0s 185us/step - loss: 1.8571 - acc: 0.7581\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 0s 184us/step - loss: 1.6787 - acc: 0.7258\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 0s 210us/step - loss: 1.5512 - acc: 0.7742\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 0s 208us/step - loss: 1.4839 - acc: 0.8065\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 0s 205us/step - loss: 1.3947 - acc: 0.8710\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 0s 207us/step - loss: 1.3027 - acc: 0.8710\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 0s 179us/step - loss: 1.2156 - acc: 0.7903\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 0s 214us/step - loss: 1.2513 - acc: 0.8226\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 0s 213us/step - loss: 1.1346 - acc: 0.8710\n",
      "Epoch 13/20\n",
      "62/62 [==============================] - 0s 207us/step - loss: 1.1132 - acc: 0.8226\n",
      "Epoch 14/20\n",
      "62/62 [==============================] - 0s 192us/step - loss: 1.0309 - acc: 0.8065\n",
      "Epoch 15/20\n",
      "62/62 [==============================] - 0s 186us/step - loss: 1.0098 - acc: 0.8871\n",
      "Epoch 16/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "62/62 [==============================] - 0s 190us/step - loss: 0.9550 - acc: 0.8871\n",
      "Epoch 17/20\n",
      "62/62 [==============================] - 0s 251us/step - loss: 0.9478 - acc: 0.8387\n",
      "Epoch 18/20\n",
      "62/62 [==============================] - 0s 255us/step - loss: 0.8710 - acc: 0.8710\n",
      "Epoch 19/20\n",
      "62/62 [==============================] - 0s 341us/step - loss: 0.9742 - acc: 0.8548\n",
      "Epoch 20/20\n",
      "62/62 [==============================] - 0s 194us/step - loss: 0.9939 - acc: 0.8548\n",
      "31/31 [==============================] - 0s 10ms/step\n",
      "62/62 [==============================] - 0s 148us/step\n",
      "[CV] .................... epochs=20, lr=0.001, nodes=32, total=   2.7s\n",
      "[CV] epochs=20, lr=0.002, nodes=16 ...................................\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 1s 16ms/step - loss: 2.8451 - acc: 0.1613\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 0s 173us/step - loss: 2.3240 - acc: 0.4032\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 0s 167us/step - loss: 2.0314 - acc: 0.5968\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 0s 184us/step - loss: 1.7435 - acc: 0.6129\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 0s 188us/step - loss: 1.5724 - acc: 0.6613\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 0s 170us/step - loss: 1.4879 - acc: 0.6774\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 0s 170us/step - loss: 1.3033 - acc: 0.6935\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 0s 193us/step - loss: 1.3695 - acc: 0.7419\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 0s 184us/step - loss: 1.2005 - acc: 0.7903\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 0s 176us/step - loss: 1.1481 - acc: 0.7581\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 0s 169us/step - loss: 1.0376 - acc: 0.8226\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 0s 217us/step - loss: 0.9653 - acc: 0.7419\n",
      "Epoch 13/20\n",
      "62/62 [==============================] - 0s 231us/step - loss: 1.0075 - acc: 0.8065\n",
      "Epoch 14/20\n",
      "62/62 [==============================] - 0s 195us/step - loss: 0.9348 - acc: 0.8065\n",
      "Epoch 15/20\n",
      "62/62 [==============================] - 0s 225us/step - loss: 0.9286 - acc: 0.8871\n",
      "Epoch 16/20\n",
      "62/62 [==============================] - 0s 208us/step - loss: 0.9548 - acc: 0.7258\n",
      "Epoch 17/20\n",
      "62/62 [==============================] - 0s 197us/step - loss: 0.8782 - acc: 0.8065\n",
      "Epoch 18/20\n",
      "62/62 [==============================] - 0s 219us/step - loss: 1.0312 - acc: 0.8871\n",
      "Epoch 19/20\n",
      "62/62 [==============================] - 0s 190us/step - loss: 0.8325 - acc: 0.8226\n",
      "Epoch 20/20\n",
      "62/62 [==============================] - 0s 217us/step - loss: 1.0391 - acc: 0.7258\n",
      "31/31 [==============================] - 0s 10ms/step\n",
      "62/62 [==============================] - 0s 106us/step\n",
      "[CV] .................... epochs=20, lr=0.002, nodes=16, total=   2.2s\n",
      "[CV] epochs=20, lr=0.002, nodes=16 ...................................\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 1s 15ms/step - loss: 2.9327 - acc: 0.1129\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 0s 155us/step - loss: 2.4588 - acc: 0.3548\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 0s 201us/step - loss: 2.2000 - acc: 0.4516\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 0s 158us/step - loss: 2.1268 - acc: 0.4355\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 0s 188us/step - loss: 1.8959 - acc: 0.5484\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 0s 173us/step - loss: 1.8146 - acc: 0.6129\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 0s 181us/step - loss: 1.6628 - acc: 0.7258\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 0s 149us/step - loss: 1.5280 - acc: 0.8065\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 0s 197us/step - loss: 1.4617 - acc: 0.6935\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 0s 191us/step - loss: 1.5166 - acc: 0.7258\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 0s 156us/step - loss: 1.3246 - acc: 0.8548\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 0s 181us/step - loss: 1.2885 - acc: 0.8548\n",
      "Epoch 13/20\n",
      "62/62 [==============================] - 0s 200us/step - loss: 1.2021 - acc: 0.7581\n",
      "Epoch 14/20\n",
      "62/62 [==============================] - 0s 191us/step - loss: 1.2288 - acc: 0.7742\n",
      "Epoch 15/20\n",
      "62/62 [==============================] - 0s 166us/step - loss: 1.2119 - acc: 0.8387\n",
      "Epoch 16/20\n",
      "62/62 [==============================] - 0s 163us/step - loss: 1.1785 - acc: 0.8548\n",
      "Epoch 17/20\n",
      "62/62 [==============================] - 0s 198us/step - loss: 1.1100 - acc: 0.8710\n",
      "Epoch 18/20\n",
      "62/62 [==============================] - 0s 181us/step - loss: 1.2073 - acc: 0.8226\n",
      "Epoch 19/20\n",
      "62/62 [==============================] - 0s 173us/step - loss: 1.1244 - acc: 0.8548\n",
      "Epoch 20/20\n",
      "62/62 [==============================] - 0s 183us/step - loss: 1.1086 - acc: 0.7581\n",
      "31/31 [==============================] - 0s 9ms/step\n",
      "62/62 [==============================] - 0s 88us/step\n",
      "[CV] .................... epochs=20, lr=0.002, nodes=16, total=   2.0s\n",
      "[CV] epochs=20, lr=0.002, nodes=16 ...................................\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 1s 15ms/step - loss: 2.8958 - acc: 0.1290\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 0s 172us/step - loss: 2.4224 - acc: 0.3065\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 0s 188us/step - loss: 2.2114 - acc: 0.5161\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 0s 153us/step - loss: 2.0112 - acc: 0.5806\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 0s 171us/step - loss: 1.7116 - acc: 0.7258\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 0s 185us/step - loss: 1.6517 - acc: 0.7097\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 0s 172us/step - loss: 1.5031 - acc: 0.7581\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 0s 156us/step - loss: 1.4171 - acc: 0.6935\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 0s 184us/step - loss: 1.3400 - acc: 0.7742\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 0s 183us/step - loss: 1.3959 - acc: 0.7903\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 0s 151us/step - loss: 1.1586 - acc: 0.8065\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 0s 204us/step - loss: 1.1630 - acc: 0.8226\n",
      "Epoch 13/20\n",
      "62/62 [==============================] - 0s 199us/step - loss: 1.3205 - acc: 0.7258\n",
      "Epoch 14/20\n",
      "62/62 [==============================] - 0s 198us/step - loss: 1.1109 - acc: 0.8710\n",
      "Epoch 15/20\n",
      "62/62 [==============================] - 0s 147us/step - loss: 1.2287 - acc: 0.7742\n",
      "Epoch 16/20\n",
      "62/62 [==============================] - 0s 183us/step - loss: 1.1550 - acc: 0.7419\n",
      "Epoch 17/20\n",
      "62/62 [==============================] - 0s 157us/step - loss: 1.0426 - acc: 0.8387\n",
      "Epoch 18/20\n",
      "62/62 [==============================] - 0s 180us/step - loss: 1.0965 - acc: 0.7581\n",
      "Epoch 19/20\n",
      "62/62 [==============================] - 0s 181us/step - loss: 0.9979 - acc: 0.8387\n",
      "Epoch 20/20\n",
      "62/62 [==============================] - 0s 181us/step - loss: 1.0863 - acc: 0.7742\n",
      "31/31 [==============================] - 0s 10ms/step\n",
      "62/62 [==============================] - 0s 92us/step\n",
      "[CV] .................... epochs=20, lr=0.002, nodes=16, total=   2.0s\n",
      "[CV] epochs=20, lr=0.002, nodes=32 ...................................\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 1s 16ms/step - loss: 2.8215 - acc: 0.1774\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 0s 189us/step - loss: 1.9866 - acc: 0.5323\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 0s 189us/step - loss: 1.6185 - acc: 0.7097\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 0s 179us/step - loss: 1.3029 - acc: 0.8387\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 0s 205us/step - loss: 1.2001 - acc: 0.8548\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 0s 194us/step - loss: 1.0563 - acc: 0.8548\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 0s 228us/step - loss: 1.0648 - acc: 0.8226\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 0s 214us/step - loss: 0.9004 - acc: 0.8710\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 0s 208us/step - loss: 0.8641 - acc: 0.8871\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 0s 217us/step - loss: 0.7927 - acc: 0.9032\n",
      "Epoch 11/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "62/62 [==============================] - 0s 205us/step - loss: 0.7467 - acc: 0.9194\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 0s 212us/step - loss: 0.7941 - acc: 0.8065\n",
      "Epoch 13/20\n",
      "62/62 [==============================] - 0s 220us/step - loss: 0.7012 - acc: 0.8871\n",
      "Epoch 14/20\n",
      "62/62 [==============================] - 0s 244us/step - loss: 0.6328 - acc: 0.9194\n",
      "Epoch 15/20\n",
      "62/62 [==============================] - 0s 227us/step - loss: 0.6951 - acc: 0.8548\n",
      "Epoch 16/20\n",
      "62/62 [==============================] - 0s 244us/step - loss: 0.6223 - acc: 0.8387\n",
      "Epoch 17/20\n",
      "62/62 [==============================] - 0s 246us/step - loss: 0.6816 - acc: 0.8710\n",
      "Epoch 18/20\n",
      "62/62 [==============================] - 0s 227us/step - loss: 0.6251 - acc: 0.8548\n",
      "Epoch 19/20\n",
      "62/62 [==============================] - 0s 223us/step - loss: 0.5840 - acc: 0.8871\n",
      "Epoch 20/20\n",
      "62/62 [==============================] - 0s 230us/step - loss: 0.5923 - acc: 0.9032\n",
      "31/31 [==============================] - 0s 10ms/step\n",
      "62/62 [==============================] - 0s 108us/step\n",
      "[CV] .................... epochs=20, lr=0.002, nodes=32, total=   2.1s\n",
      "[CV] epochs=20, lr=0.002, nodes=32 ...................................\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 1s 16ms/step - loss: 3.0500 - acc: 0.1452\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 0s 223us/step - loss: 2.2259 - acc: 0.6452\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 0s 184us/step - loss: 1.8689 - acc: 0.7581\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 0s 206us/step - loss: 1.6017 - acc: 0.8065\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 0s 195us/step - loss: 1.5147 - acc: 0.8226\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 0s 202us/step - loss: 1.2961 - acc: 0.8387\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 0s 221us/step - loss: 1.2564 - acc: 0.9032\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 0s 208us/step - loss: 1.0978 - acc: 0.8871\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 0s 199us/step - loss: 1.1264 - acc: 0.8871\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 0s 201us/step - loss: 1.1227 - acc: 0.8710\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 0s 181us/step - loss: 1.1286 - acc: 0.9032\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 0s 210us/step - loss: 0.9890 - acc: 0.8710\n",
      "Epoch 13/20\n",
      "62/62 [==============================] - 0s 175us/step - loss: 1.0143 - acc: 0.8710\n",
      "Epoch 14/20\n",
      "62/62 [==============================] - 0s 217us/step - loss: 0.9393 - acc: 0.9355\n",
      "Epoch 15/20\n",
      "62/62 [==============================] - 0s 205us/step - loss: 0.9471 - acc: 0.9032\n",
      "Epoch 16/20\n",
      "62/62 [==============================] - 0s 245us/step - loss: 0.9789 - acc: 0.9032\n",
      "Epoch 17/20\n",
      "62/62 [==============================] - 0s 212us/step - loss: 0.9287 - acc: 0.8548\n",
      "Epoch 18/20\n",
      "62/62 [==============================] - 0s 177us/step - loss: 0.7937 - acc: 0.8548\n",
      "Epoch 19/20\n",
      "62/62 [==============================] - 0s 186us/step - loss: 0.8893 - acc: 0.8710\n",
      "Epoch 20/20\n",
      "62/62 [==============================] - 0s 189us/step - loss: 0.8267 - acc: 0.8710\n",
      "31/31 [==============================] - 0s 10ms/step\n",
      "62/62 [==============================] - 0s 97us/step\n",
      "[CV] .................... epochs=20, lr=0.002, nodes=32, total=   2.1s\n",
      "[CV] epochs=20, lr=0.002, nodes=32 ...................................\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 1s 16ms/step - loss: 3.0281 - acc: 0.1290\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 0s 182us/step - loss: 2.1628 - acc: 0.5968\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 0s 221us/step - loss: 1.7955 - acc: 0.7903\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 0s 211us/step - loss: 1.5821 - acc: 0.7258\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 0s 208us/step - loss: 1.4128 - acc: 0.7419\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 0s 243us/step - loss: 1.3008 - acc: 0.8387\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 0s 208us/step - loss: 1.1885 - acc: 0.7903\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 0s 183us/step - loss: 1.2623 - acc: 0.8226\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 0s 215us/step - loss: 1.0931 - acc: 0.8226\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 0s 170us/step - loss: 1.0170 - acc: 0.8871\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 0s 187us/step - loss: 0.9537 - acc: 0.8710\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 0s 191us/step - loss: 0.9329 - acc: 0.8710\n",
      "Epoch 13/20\n",
      "62/62 [==============================] - 0s 215us/step - loss: 0.8506 - acc: 0.8871\n",
      "Epoch 14/20\n",
      "62/62 [==============================] - 0s 210us/step - loss: 0.8853 - acc: 0.9032\n",
      "Epoch 15/20\n",
      "62/62 [==============================] - 0s 207us/step - loss: 0.7651 - acc: 0.8548\n",
      "Epoch 16/20\n",
      "62/62 [==============================] - 0s 235us/step - loss: 0.8019 - acc: 0.9194\n",
      "Epoch 17/20\n",
      "62/62 [==============================] - 0s 225us/step - loss: 0.8206 - acc: 0.8387\n",
      "Epoch 18/20\n",
      "62/62 [==============================] - 0s 198us/step - loss: 0.7929 - acc: 0.9194\n",
      "Epoch 19/20\n",
      "62/62 [==============================] - 0s 180us/step - loss: 0.8592 - acc: 0.9032\n",
      "Epoch 20/20\n",
      "62/62 [==============================] - 0s 181us/step - loss: 0.8007 - acc: 0.8871\n",
      "31/31 [==============================] - 0s 11ms/step\n",
      "62/62 [==============================] - 0s 138us/step\n",
      "[CV] .................... epochs=20, lr=0.002, nodes=32, total=   2.2s\n",
      "[CV] epochs=20, lr=0.003, nodes=16 ...................................\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 1s 17ms/step - loss: 2.8881 - acc: 0.0968\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 0s 225us/step - loss: 2.2373 - acc: 0.4032\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 0s 166us/step - loss: 1.9918 - acc: 0.4516\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 0s 233us/step - loss: 1.7758 - acc: 0.5161\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 0s 178us/step - loss: 1.5959 - acc: 0.6290\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 0s 182us/step - loss: 1.3211 - acc: 0.7419\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 0s 166us/step - loss: 1.2754 - acc: 0.8226\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 0s 199us/step - loss: 1.2170 - acc: 0.8387\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 0s 165us/step - loss: 1.1742 - acc: 0.7419\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 0s 171us/step - loss: 1.0534 - acc: 0.7581\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 0s 167us/step - loss: 1.1202 - acc: 0.7903\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 0s 171us/step - loss: 0.9479 - acc: 0.8871\n",
      "Epoch 13/20\n",
      "62/62 [==============================] - 0s 176us/step - loss: 0.9741 - acc: 0.8065\n",
      "Epoch 14/20\n",
      "62/62 [==============================] - 0s 175us/step - loss: 0.8966 - acc: 0.8871\n",
      "Epoch 15/20\n",
      "62/62 [==============================] - 0s 180us/step - loss: 0.9127 - acc: 0.8871\n",
      "Epoch 16/20\n",
      "62/62 [==============================] - 0s 159us/step - loss: 0.9879 - acc: 0.7903\n",
      "Epoch 17/20\n",
      "62/62 [==============================] - 0s 185us/step - loss: 0.8680 - acc: 0.9194\n",
      "Epoch 18/20\n",
      "62/62 [==============================] - 0s 172us/step - loss: 0.8208 - acc: 0.8548\n",
      "Epoch 19/20\n",
      "62/62 [==============================] - 0s 208us/step - loss: 0.8046 - acc: 0.8548\n",
      "Epoch 20/20\n",
      "62/62 [==============================] - 0s 187us/step - loss: 0.8002 - acc: 0.8710\n",
      "31/31 [==============================] - 0s 12ms/step\n",
      "62/62 [==============================] - 0s 110us/step\n",
      "[CV] .................... epochs=20, lr=0.003, nodes=16, total=   2.6s\n",
      "[CV] epochs=20, lr=0.003, nodes=16 ...................................\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 1s 17ms/step - loss: 3.0891 - acc: 0.0645\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 0s 187us/step - loss: 2.4537 - acc: 0.3871\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 0s 191us/step - loss: 2.1008 - acc: 0.6129\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 0s 187us/step - loss: 1.9134 - acc: 0.5806\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 0s 198us/step - loss: 1.6901 - acc: 0.7419\n",
      "Epoch 6/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "62/62 [==============================] - 0s 230us/step - loss: 1.6065 - acc: 0.7581\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 0s 228us/step - loss: 1.4382 - acc: 0.7581\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 0s 221us/step - loss: 1.4867 - acc: 0.6774\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 0s 198us/step - loss: 1.3493 - acc: 0.8387\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 0s 229us/step - loss: 1.2174 - acc: 0.7742\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 0s 227us/step - loss: 1.3326 - acc: 0.6935\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 0s 209us/step - loss: 1.1198 - acc: 0.8387\n",
      "Epoch 13/20\n",
      "62/62 [==============================] - 0s 239us/step - loss: 1.1467 - acc: 0.7903\n",
      "Epoch 14/20\n",
      "62/62 [==============================] - 0s 167us/step - loss: 1.1005 - acc: 0.8548\n",
      "Epoch 15/20\n",
      "62/62 [==============================] - 0s 168us/step - loss: 1.0752 - acc: 0.8065\n",
      "Epoch 16/20\n",
      "62/62 [==============================] - 0s 187us/step - loss: 1.1784 - acc: 0.7742\n",
      "Epoch 17/20\n",
      "62/62 [==============================] - 0s 268us/step - loss: 0.9515 - acc: 0.8548\n",
      "Epoch 18/20\n",
      "62/62 [==============================] - 0s 252us/step - loss: 0.9730 - acc: 0.9032\n",
      "Epoch 19/20\n",
      "62/62 [==============================] - 0s 219us/step - loss: 0.9825 - acc: 0.8548\n",
      "Epoch 20/20\n",
      "62/62 [==============================] - 0s 234us/step - loss: 0.9025 - acc: 0.8548\n",
      "31/31 [==============================] - 0s 13ms/step\n",
      "62/62 [==============================] - 0s 97us/step\n",
      "[CV] .................... epochs=20, lr=0.003, nodes=16, total=   2.3s\n",
      "[CV] epochs=20, lr=0.003, nodes=16 ...................................\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 1s 18ms/step - loss: 2.9255 - acc: 0.2258\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 0s 210us/step - loss: 2.2728 - acc: 0.5645\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 0s 171us/step - loss: 1.8928 - acc: 0.6613\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 0s 195us/step - loss: 1.5971 - acc: 0.7097\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 0s 200us/step - loss: 1.5414 - acc: 0.6613\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 0s 229us/step - loss: 1.4847 - acc: 0.6613\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 0s 187us/step - loss: 1.5216 - acc: 0.8387\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 0s 172us/step - loss: 1.3459 - acc: 0.6935\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 0s 162us/step - loss: 1.2261 - acc: 0.7581\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 0s 178us/step - loss: 1.2780 - acc: 0.7903\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 0s 199us/step - loss: 1.2731 - acc: 0.7581\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 0s 179us/step - loss: 1.1306 - acc: 0.8065\n",
      "Epoch 13/20\n",
      "62/62 [==============================] - 0s 163us/step - loss: 1.1989 - acc: 0.8226\n",
      "Epoch 14/20\n",
      "62/62 [==============================] - 0s 252us/step - loss: 1.1028 - acc: 0.8065\n",
      "Epoch 15/20\n",
      "62/62 [==============================] - 0s 183us/step - loss: 1.1159 - acc: 0.8065\n",
      "Epoch 16/20\n",
      "62/62 [==============================] - 0s 190us/step - loss: 1.0328 - acc: 0.8065\n",
      "Epoch 17/20\n",
      "62/62 [==============================] - 0s 171us/step - loss: 1.0734 - acc: 0.8710\n",
      "Epoch 18/20\n",
      "62/62 [==============================] - 0s 163us/step - loss: 1.0958 - acc: 0.7419\n",
      "Epoch 19/20\n",
      "62/62 [==============================] - 0s 205us/step - loss: 1.0500 - acc: 0.8710\n",
      "Epoch 20/20\n",
      "62/62 [==============================] - 0s 170us/step - loss: 0.9931 - acc: 0.7742\n",
      "31/31 [==============================] - 0s 12ms/step\n",
      "62/62 [==============================] - 0s 100us/step\n",
      "[CV] .................... epochs=20, lr=0.003, nodes=16, total=   2.4s\n",
      "[CV] epochs=20, lr=0.003, nodes=32 ...................................\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 1s 18ms/step - loss: 2.7018 - acc: 0.1613\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 0s 226us/step - loss: 1.7481 - acc: 0.6129\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 0s 181us/step - loss: 1.3505 - acc: 0.8226\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 0s 205us/step - loss: 1.0177 - acc: 0.8226\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 0s 201us/step - loss: 0.9023 - acc: 0.9032\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 0s 211us/step - loss: 0.7801 - acc: 0.8387\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 0s 220us/step - loss: 0.8529 - acc: 0.9032\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 0s 197us/step - loss: 0.7864 - acc: 0.8548\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 0s 185us/step - loss: 0.7273 - acc: 0.9032\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 0s 205us/step - loss: 0.8072 - acc: 0.8065\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 0s 216us/step - loss: 0.6049 - acc: 0.9355\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 0s 211us/step - loss: 0.6143 - acc: 0.8387\n",
      "Epoch 13/20\n",
      "62/62 [==============================] - 0s 181us/step - loss: 0.6251 - acc: 0.9194\n",
      "Epoch 14/20\n",
      "62/62 [==============================] - 0s 221us/step - loss: 0.6133 - acc: 0.8871\n",
      "Epoch 15/20\n",
      "62/62 [==============================] - 0s 214us/step - loss: 0.6174 - acc: 0.8871\n",
      "Epoch 16/20\n",
      "62/62 [==============================] - 0s 222us/step - loss: 0.6549 - acc: 0.9032\n",
      "Epoch 17/20\n",
      "62/62 [==============================] - 0s 167us/step - loss: 0.5332 - acc: 0.8387\n",
      "Epoch 18/20\n",
      "62/62 [==============================] - 0s 189us/step - loss: 0.5476 - acc: 0.9194\n",
      "Epoch 19/20\n",
      "62/62 [==============================] - 0s 195us/step - loss: 0.5513 - acc: 0.9032\n",
      "Epoch 20/20\n",
      "62/62 [==============================] - 0s 179us/step - loss: 0.5871 - acc: 0.8710\n",
      "31/31 [==============================] - 0s 12ms/step\n",
      "62/62 [==============================] - 0s 116us/step\n",
      "[CV] .................... epochs=20, lr=0.003, nodes=32, total=   2.3s\n",
      "[CV] epochs=20, lr=0.003, nodes=32 ...................................\n",
      "Epoch 1/20\n",
      "62/62 [==============================] - 1s 18ms/step - loss: 3.0306 - acc: 0.1935\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 0s 260us/step - loss: 2.0045 - acc: 0.6290\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 0s 187us/step - loss: 1.6119 - acc: 0.9032\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 0s 228us/step - loss: 1.3799 - acc: 0.8065\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 0s 233us/step - loss: 1.1434 - acc: 0.8065\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 0s 187us/step - loss: 1.0928 - acc: 0.8387\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 0s 222us/step - loss: 0.9588 - acc: 0.8710\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 0s 200us/step - loss: 0.9818 - acc: 0.8710\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 0s 194us/step - loss: 0.9019 - acc: 0.8710\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 0s 175us/step - loss: 0.8773 - acc: 0.8710\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 0s 172us/step - loss: 0.8322 - acc: 0.8548\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 0s 213us/step - loss: 0.7990 - acc: 0.8871\n",
      "Epoch 13/20\n",
      "62/62 [==============================] - 0s 172us/step - loss: 0.8799 - acc: 0.8387\n",
      "Epoch 14/20\n",
      "62/62 [==============================] - 0s 188us/step - loss: 0.8296 - acc: 0.9032\n",
      "Epoch 15/20\n",
      "62/62 [==============================] - 0s 221us/step - loss: 0.7654 - acc: 0.8387\n",
      "Epoch 16/20\n",
      "62/62 [==============================] - 0s 238us/step - loss: 0.8408 - acc: 0.8710\n",
      "Epoch 17/20\n",
      "62/62 [==============================] - 0s 193us/step - loss: 0.8238 - acc: 0.9194\n",
      "Epoch 18/20\n",
      "62/62 [==============================] - 0s 256us/step - loss: 0.8017 - acc: 0.9516\n",
      "Epoch 19/20\n",
      "62/62 [==============================] - 0s 258us/step - loss: 0.7395 - acc: 0.8710\n",
      "Epoch 20/20\n",
      "62/62 [==============================] - 0s 267us/step - loss: 0.8233 - acc: 0.8871\n",
      "31/31 [==============================] - 0s 14ms/step\n",
      "62/62 [==============================] - 0s 96us/step\n",
      "[CV] .................... epochs=20, lr=0.003, nodes=32, total=   2.4s\n",
      "[CV] epochs=20, lr=0.003, nodes=32 ...................................\n",
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "62/62 [==============================] - 1s 23ms/step - loss: 2.8999 - acc: 0.2097\n",
      "Epoch 2/20\n",
      "62/62 [==============================] - 0s 243us/step - loss: 1.9887 - acc: 0.6774\n",
      "Epoch 3/20\n",
      "62/62 [==============================] - 0s 255us/step - loss: 1.5484 - acc: 0.7903\n",
      "Epoch 4/20\n",
      "62/62 [==============================] - 0s 254us/step - loss: 1.2624 - acc: 0.8226\n",
      "Epoch 5/20\n",
      "62/62 [==============================] - 0s 266us/step - loss: 1.2816 - acc: 0.8226\n",
      "Epoch 6/20\n",
      "62/62 [==============================] - 0s 193us/step - loss: 1.0405 - acc: 0.8548\n",
      "Epoch 7/20\n",
      "62/62 [==============================] - 0s 215us/step - loss: 1.0940 - acc: 0.9032\n",
      "Epoch 8/20\n",
      "62/62 [==============================] - 0s 271us/step - loss: 1.0110 - acc: 0.8871\n",
      "Epoch 9/20\n",
      "62/62 [==============================] - 0s 227us/step - loss: 0.9793 - acc: 0.8548\n",
      "Epoch 10/20\n",
      "62/62 [==============================] - 0s 271us/step - loss: 0.9255 - acc: 0.8710\n",
      "Epoch 11/20\n",
      "62/62 [==============================] - 0s 234us/step - loss: 0.9034 - acc: 0.8226\n",
      "Epoch 12/20\n",
      "62/62 [==============================] - 0s 228us/step - loss: 1.0117 - acc: 0.8871\n",
      "Epoch 13/20\n",
      "62/62 [==============================] - 0s 270us/step - loss: 0.8847 - acc: 0.8871\n",
      "Epoch 14/20\n",
      "62/62 [==============================] - 0s 273us/step - loss: 0.8055 - acc: 0.8548\n",
      "Epoch 15/20\n",
      "62/62 [==============================] - 0s 217us/step - loss: 0.8073 - acc: 0.8710\n",
      "Epoch 16/20\n",
      "62/62 [==============================] - 0s 259us/step - loss: 0.7525 - acc: 0.9032\n",
      "Epoch 17/20\n",
      "62/62 [==============================] - 0s 350us/step - loss: 0.8878 - acc: 0.8226\n",
      "Epoch 18/20\n",
      "62/62 [==============================] - 0s 213us/step - loss: 0.8532 - acc: 0.9032\n",
      "Epoch 19/20\n",
      "62/62 [==============================] - 0s 199us/step - loss: 0.7601 - acc: 0.8226\n",
      "Epoch 20/20\n",
      "62/62 [==============================] - 0s 217us/step - loss: 0.7491 - acc: 0.8871\n",
      "31/31 [==============================] - 0s 15ms/step\n",
      "62/62 [==============================] - 0s 118us/step\n",
      "[CV] .................... epochs=20, lr=0.003, nodes=32, total=   2.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  36 out of  36 | elapsed:  1.1min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "93/93 [==============================] - 1s 14ms/step - loss: 2.8799 - acc: 0.1828\n",
      "Epoch 2/20\n",
      "93/93 [==============================] - 0s 197us/step - loss: 1.8002 - acc: 0.7312\n",
      "Epoch 3/20\n",
      "93/93 [==============================] - 0s 204us/step - loss: 1.4384 - acc: 0.7957\n",
      "Epoch 4/20\n",
      "93/93 [==============================] - 0s 183us/step - loss: 1.2348 - acc: 0.8710\n",
      "Epoch 5/20\n",
      "93/93 [==============================] - 0s 187us/step - loss: 1.0703 - acc: 0.8817\n",
      "Epoch 6/20\n",
      "93/93 [==============================] - 0s 206us/step - loss: 1.0318 - acc: 0.9032\n",
      "Epoch 7/20\n",
      "93/93 [==============================] - 0s 188us/step - loss: 1.0733 - acc: 0.8172\n",
      "Epoch 8/20\n",
      "93/93 [==============================] - 0s 188us/step - loss: 0.8294 - acc: 0.9032\n",
      "Epoch 9/20\n",
      "93/93 [==============================] - 0s 178us/step - loss: 0.8980 - acc: 0.8925\n",
      "Epoch 10/20\n",
      "93/93 [==============================] - 0s 207us/step - loss: 0.8122 - acc: 0.8495\n",
      "Epoch 11/20\n",
      "93/93 [==============================] - 0s 196us/step - loss: 0.8058 - acc: 0.8817\n",
      "Epoch 12/20\n",
      "93/93 [==============================] - 0s 225us/step - loss: 0.9136 - acc: 0.8602\n",
      "Epoch 13/20\n",
      "93/93 [==============================] - 0s 216us/step - loss: 0.7753 - acc: 0.9140\n",
      "Epoch 14/20\n",
      "93/93 [==============================] - 0s 223us/step - loss: 0.8310 - acc: 0.8387\n",
      "Epoch 15/20\n",
      "93/93 [==============================] - 0s 198us/step - loss: 0.7800 - acc: 0.8925\n",
      "Epoch 16/20\n",
      "93/93 [==============================] - 0s 227us/step - loss: 0.7164 - acc: 0.8602\n",
      "Epoch 17/20\n",
      "93/93 [==============================] - 0s 172us/step - loss: 0.7401 - acc: 0.8387\n",
      "Epoch 18/20\n",
      "93/93 [==============================] - 0s 189us/step - loss: 0.6496 - acc: 0.9140\n",
      "Epoch 19/20\n",
      "93/93 [==============================] - 0s 192us/step - loss: 0.7148 - acc: 0.8710\n",
      "Epoch 20/20\n",
      "93/93 [==============================] - 0s 192us/step - loss: 0.8083 - acc: 0.8817\n"
     ]
    }
   ],
   "source": [
    "#start fitting process\n",
    "param_grid = dict(epochs=epochs,nodes=nodes, lr=lrs)\n",
    "grid = GridSearchCV(estimator=model, param_grid=param_grid, n_jobs=1,refit=True,verbose=2)\n",
    "grid_result = grid.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GridSearchCV(cv=None, error_score='raise',\n",
      "       estimator=<keras.wrappers.scikit_learn.KerasClassifier object at 0x12127f9e8>,\n",
      "       fit_params=None, iid=True, n_jobs=1,\n",
      "       param_grid={'epochs': [10, 20], 'nodes': [16, 32], 'lr': [0.001, 0.002, 0.003]},\n",
      "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
      "       scoring=None, verbose=2)\n"
     ]
    }
   ],
   "source": [
    "print(grid_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best estimator : <keras.wrappers.scikit_learn.KerasClassifier object at 0x12fa67c50>\n",
      "Best score : 0.5913978318373362\n",
      "Best params : {'epochs': 20, 'lr': 0.003, 'nodes': 32}\n"
     ]
    }
   ],
   "source": [
    "print('Best estimator : {}'.format (grid.best_estimator_))\n",
    "print('Best score : {}'.format(grid.best_score_))\n",
    "print('Best params : {}'.format(grid.best_params_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'mean_fit_time': array([1.12686626, 1.32934705, 1.43799671, 1.58056506, 1.53587   ,\n",
      "       1.4668692 , 1.5470717 , 2.01947061, 1.76525911, 1.8040688 ,\n",
      "       2.0206933 , 2.09377607]), 'std_fit_time': array([0.07802286, 0.12160029, 0.28345727, 0.04639525, 0.16476943,\n",
      "       0.11955106, 0.0375942 , 0.2656819 , 0.0665599 , 0.00420706,\n",
      "       0.13384008, 0.21353067]), 'mean_score_time': array([0.05572613, 0.08539796, 0.12109661, 0.1554571 , 0.19532315,\n",
      "       0.20208009, 0.23397613, 0.28385003, 0.30201435, 0.33309857,\n",
      "       0.38207833, 0.4315606 ]), 'std_score_time': array([0.01351843, 0.01207502, 0.00710894, 0.00420446, 0.00346427,\n",
      "       0.01010583, 0.00482757, 0.02724011, 0.004572  , 0.01791464,\n",
      "       0.00959762, 0.04105926]), 'param_epochs': masked_array(data=[10, 10, 10, 10, 10, 10, 20, 20, 20, 20, 20, 20],\n",
      "             mask=[False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False],\n",
      "       fill_value='?',\n",
      "            dtype=object), 'param_lr': masked_array(data=[0.001, 0.001, 0.002, 0.002, 0.003, 0.003, 0.001, 0.001,\n",
      "                   0.002, 0.002, 0.003, 0.003],\n",
      "             mask=[False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False],\n",
      "       fill_value='?',\n",
      "            dtype=object), 'param_nodes': masked_array(data=[16, 32, 16, 32, 16, 32, 16, 32, 16, 32, 16, 32],\n",
      "             mask=[False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False],\n",
      "       fill_value='?',\n",
      "            dtype=object), 'params': [{'epochs': 10, 'lr': 0.001, 'nodes': 16}, {'epochs': 10, 'lr': 0.001, 'nodes': 32}, {'epochs': 10, 'lr': 0.002, 'nodes': 16}, {'epochs': 10, 'lr': 0.002, 'nodes': 32}, {'epochs': 10, 'lr': 0.003, 'nodes': 16}, {'epochs': 10, 'lr': 0.003, 'nodes': 32}, {'epochs': 20, 'lr': 0.001, 'nodes': 16}, {'epochs': 20, 'lr': 0.001, 'nodes': 32}, {'epochs': 20, 'lr': 0.002, 'nodes': 16}, {'epochs': 20, 'lr': 0.002, 'nodes': 32}, {'epochs': 20, 'lr': 0.003, 'nodes': 16}, {'epochs': 20, 'lr': 0.003, 'nodes': 32}], 'split0_test_score': array([0.51612902, 0.48387095, 0.61290324, 0.58064514, 0.7096774 ,\n",
      "       0.58064514, 0.58064514, 0.67741936, 0.58064514, 0.67741936,\n",
      "       0.67741936, 0.7096774 ]), 'split1_test_score': array([0.32258064, 0.48387095, 0.3548387 , 0.3548387 , 0.32258064,\n",
      "       0.41935483, 0.32258064, 0.41935483, 0.61290324, 0.48387095,\n",
      "       0.48387095, 0.48387095]), 'split2_test_score': array([0.41935483, 0.45161289, 0.41935483, 0.41935483, 0.58064514,\n",
      "       0.51612902, 0.51612902, 0.48387095, 0.51612902, 0.54838711,\n",
      "       0.51612902, 0.58064514]), 'mean_test_score': array([0.41935483, 0.47311827, 0.46236559, 0.45161289, 0.53763439,\n",
      "       0.50537633, 0.47311827, 0.52688171, 0.56989247, 0.56989248,\n",
      "       0.55913978, 0.59139783]), 'std_test_score': array([0.0790158 , 0.0152066 , 0.10965634, 0.09496517, 0.1609315 ,\n",
      "       0.06628402, 0.10965633, 0.10965634, 0.04023288, 0.08046576,\n",
      "       0.08466676, 0.09249812]), 'rank_test_score': array([12,  8, 10, 11,  5,  7,  8,  6,  3,  2,  4,  1], dtype=int32), 'split0_train_score': array([0.88709676, 0.87096773, 0.88709676, 0.91935484, 0.88709676,\n",
      "       0.88709678, 0.88709678, 0.87096775, 0.96774192, 0.8548387 ,\n",
      "       0.88709676, 0.88709676]), 'split1_train_score': array([0.79032257, 0.88709678, 0.91935484, 0.91935483, 0.91935484,\n",
      "       0.88709678, 0.91935484, 0.91935484, 0.90322581, 0.90322579,\n",
      "       0.90322581, 0.8548387 ]), 'split2_train_score': array([0.8064516 , 0.8548387 , 0.87096775, 0.90322579, 0.85483871,\n",
      "       0.88709676, 0.87096775, 0.82258064, 0.93548386, 0.85483871,\n",
      "       0.90322581, 0.88709678]), 'mean_train_score': array([0.82795698, 0.87096774, 0.89247312, 0.91397849, 0.88709677,\n",
      "       0.88709677, 0.89247312, 0.87096774, 0.93548386, 0.87096774,\n",
      "       0.89784946, 0.87634408]), 'std_train_score': array([4.23333748e-02, 1.31693044e-02, 2.01164381e-02, 7.60330189e-03,\n",
      "       2.63385986e-02, 6.34468689e-09, 2.01164362e-02, 3.95079038e-02,\n",
      "       2.63385931e-02, 2.28098925e-02, 7.60330507e-03, 1.52066006e-02])}\n"
     ]
    }
   ],
   "source": [
    "print(grid.cv_results_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "#predictions\n",
    "predictions = grid.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(31, 9)\n"
     ]
    }
   ],
   "source": [
    "#predictions\n",
    "predict = grid.predict_proba(X_test)\n",
    "print(predict.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Log_loss : 1.9261731131372206\n",
      "Hamming_loss : 7.526881720430108\n",
      "Accuracy : 51.61290322580645\n"
     ]
    }
   ],
   "source": [
    "#calculate score\n",
    "loss = log_loss(Y_test,predict)\n",
    "print(\"Log_loss : {}\".format(loss))\n",
    "predict = np.round(predict)\n",
    "loss = hamming_loss(Y_test,predict)\n",
    "print(\"Hamming_loss : {}\".format(loss*100))\n",
    "accuracy = accuracy_score(Y_test,predict)\n",
    "print(\"Accuracy : {}\".format(accuracy*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Free Form Visualisation \n",
    "# We will finalise this part after selecting the models that we want to keep!\n",
    "Let us have a plot showing the **hamming-loss** and **log-loss** of different models, which we selected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import matplotlib.cm as cm\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "x = ['BR-MultNB','BR-GausNB','BR-SVC','CC-MultNB','LP-MultNB','BP-MLL-ini','BP-MLL-fin']\n",
    "y = [3.27,20.74,4.26,3.56,3.17,13.96,15.158]\n",
    "colors = itertools.cycle(['b', 'g', 'r', 'c', 'm', 'y', 'k'])\n",
    "plt.ylabel('Hamming-Loss')\n",
    "plt.xlabel('Model-details')\n",
    "plt.xticks(rotation=90)\n",
    "for i in range(len(y)):\n",
    "    plt.bar(x[i], y[i], color=next(colors))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "x = ['BR-MultNB','BR-GausNB','BR-SVC','CC-MultNB','LP-MultNB','BP-MLL-ini','BP-MLL-fin']\n",
    "y = [1.92,1.422,0.46,1.5,1.47,0.36,0.35]\n",
    "colors = itertools.cycle(['b', 'g', 'r', 'c', 'm', 'y', 'k'])\n",
    "plt.ylabel('Log-Loss')\n",
    "plt.xlabel('Model-details')\n",
    "plt.xticks(rotation=90)\n",
    "for i in range(len(y)):\n",
    "    plt.bar(x[i], y[i], color=next(colors))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- While showing among the best problem transformation method models, hamming-loss was considered (this is because for BP-MLL neural network we had to round the final results to get the hamming-loss because of the output being multivalued probabilities)\n",
    "- But while chosing among the best Adaptation Algorithm model, log loss was preferred."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
